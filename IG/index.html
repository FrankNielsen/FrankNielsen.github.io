<html>
  <head>
    <title>Frank Nielsen | Information Geometry, divergences, and diversities</title>
  </head>
  <body bgcolor=white>  
  
<h1>Information geometry and divergences</h1>

<p> <!-- style="background-color:#ffccee;"> -->
Historically, <b>Information Geometry</b> (IG) aimed at unravelling the geometric structures 
of families of probability distributions called the <b>statistical models</b>.<BR>
A statistical model can either be
<ul>
<li> parametric (eg., family of normal distributions), 
<li>semi-parametric 
(eg., family of Gaussian mixture models) or 
<li>non-parametric (family of mutually absolutely continuous smooth densities).
</ul>
</p>
<p style="background-color:#ffccee;"> 
The <b>Fisher-Rao manifold</b> of a statistical parametric model is a Riemannian manifold equipped
 with the <b>Fisher information metric</b>.
 The geodesic length on a Fisher-Rao manifold is called <b>Rao's distance</b> [Hotelling 1930][Rao 1945].
More generally, Amari proposed the <b>dualistic structure</b> of IG which consists 
of a pair of torsion-free affine connections coupled to the Fisher metric [Amari 1980's].
Given a dualistic structure, we can build generically a one-parameter family of
 dualistic information-geometric structures, 
called the <b>α-geometry</b>.
When both connections are flat, the space is said <b>dually flat</b>: 
For example, the Amari's ±1-structures of <b>exponential families</b> and <b>mixture families</b> 
are examples of dually flat spaces.
In differential geometry, geodesics are defined as autoparallel curves with respect to a connection.
When using the default Levi-Civita metric connection derived from the Fisher metric on Fisher-Rao manifolds, 
we get locally Rao's distance minimizing geodesics.
Eguchi showed how to build from a smooth distortion (originally called a contrast function) 
a dualistic structure: The <b>information geometry of divergences</b> [Eguchi 1982].
The information geometry of <b>Bregman divergences</b> yields dually flat spaces, special cases of <b>Hessian manifolds</b> 
(equipped with a metric tensor being a Hessian metric).
Since geometric structures shape spaces independently of applications, 
these pure information-geometric Fisher-Rao/α-structures can also be used in 
non-statistical contexts too: For example, for analyzing interior point methods with barrier functions in optimization, or for studying time-series models, etc.
</p>

<p style="background-color: #f2e6ff;">
<b>Statistical divergences</b> between parametric statistical models amount to 
<b>parameter divergences</b> on which we can use the Eguchi's divergence information geometry 
to get a dualistic structure.
A <b>projective divergence</b> is a divergence which is invariant by independent rescaling of its parameters.
A statistical projective divergence is thus useful for estimating computationally intractable statistical models (eg., gamma divergences or singly-sided projective Hyvärinen divergence).
A <b>conformal divergence</b> is a divergence scaled by a conformal factor which may depend on one or two of its arguments.
The metric tensor obtained from Eguchi's information divergence of a conformal divergence 
is a <b>conformal metric</b> of the metric obtained from the divergence, hence its name.
By analogy to total least squares vs least squares, a
 <b>total divergence</b> is a divergence which is invariant wrt. to rotations (eg., total Bregman divergences).
 An important property of divergences on the probability simplex is to be <b>monotone</b> by coarse-graining.
 That is, merging bins and considering reduced histograms should give a distance less or equal than the distance on the full resolution histograms.
 This <b>information monotonicity<b> property holds for f-divergences, 
 Hilbert log cross-ratio distance, or Aitchison distance for example.
 Some statistical divergences are upper <b>bounded</b> (eg., Jensen-Shannon divergences) while others are not (eg., Jeffreys' divergence).
</p>


<h2><u>Information geometry: Tutorials and surveys</u></h2>

<ul>
<li><IMG SRC="new.png"><A HREF="https://www.ams.org/journals/notices/202201/rnoti-p36.pdf" target="_blank">The Many Faces of Information Geometry</A>, AMS Notices (9 pages), 2022.
<p style="background-color:powderblue;">A gentle short introduction to information geometry</p>

<li><A HREF="https://www.mdpi.com/1099-4300/22/10/1100" target="_blank">An Elementary Introduction to Information Geometry</A>, Entropy (61 pages), 2020.
<p>A self-contained introduction to classic parametric information geometry with applications and basics of differential geometry</p>

<li><A HREF="https://www.ams.org/journals/notices/201803/rnoti-p321.pdf" target="_blank">What is an information projection?</A>, AMS Notices, (65) 3 (4 pages), 2018.  
<p>Information projections are the workhorses of algorithms using the framework of information geometry.
A projection is defined according to geodesics (wrt a connection) and orthogonality (wrt a metric tensor).
In dually flat spaces, information projections can be interpreted as minimum Bregman divergences (Bregman projections).
Unicity theorems for exponential families and mixture families.</p>


<li><A HREF="https://arxiv.org/abs/1910.03935" target="_blank">On Geodesic Triangles with Right Angles in a Dually Flat Space</a>, Chapter in edited book "Progress in Information Geometry", Springer, 2021.
<p>A self-contained introduction to dually flat spaces which we call Bregman manifolds. The generalized Pythagorean theorem is derived from the 3-parameter Bregman identity. 
The 4-parameter Bregman identity is also explained</p> 

<li><A HREF="https://arxiv.org/abs/1301.3578" target="_blank">Cramér-Rao Lower Bound and Information Geometry</A>, Connected at Infinity II: On the work of Indian mathematicians (R. Bhatia and C.S. Rajan, Eds.), special volume of Texts and Readings In Mathematics (TRIM), Hindustan Book Agency, 2013
<p>A description of the pathbreaking paper of Calyampudi Radhakrishna Rao (1945): "Information and the accuracy attainable in the estimation of statistical parameters", 1945.</p>
</ul>


<h2><u>Fisher-Rao manifolds</u></h2>
<ul>
<li><A HREF="https://hal.archives-ouvertes.fr/hal-00560187/document" target="_blank">On Approximating the Riemannian 1-Center
</A>,  Computational Geometry, 2013.
<p>Approximating the smallest enclosing Riemannian ball by a simple iterative algorithm which proves the existence of coresets. Applications to Hadamard manifolds (hyperbolic geometry and Riemannian manifold of symmetric positive-definite matrices equipped with the trace metric.</p>

</ul>

<h2><u>Finsler manifolds</u></h2>
Finsler manifolds are proposed to model irregular parametric statistical models (where Fisher information can be infinite)
<ul>
<li>
<A HREF="https://hal.archives-ouvertes.fr/hal-00560187/document" target="_blank">
Medians and means in Finsler geometry</A>, LMS Journal of Computation and Mathematics 15 (2012): 23-37.
</ul>


<h2><u>Bregman manifolds/Hessian manifolds</u></h2>
 
<ul>
<li><A HREF="https://hal.archives-ouvertes.fr/hal-00488441/document" target="_blank">
Bregman Voronoi diagrams</A>
<p>
Bregman Voronoi diagrams (or VDs in dually flat spaces) are affine diagrams which can be built from equivalent power diagrams (Laguerre geometry).
Generalize the paraboloid lifting transform of Euclidean geometry to potentials functions induced 
by the convex Bregman generators.
</p>

<li><A HREF="https://hal.archives-ouvertes.fr/hal-00488441/document" target="_blank">
https://www.researchgate.net/publication/221112384_Fitting_the_Smallest_Enclosing_Bregman_Ball</A>, ECML 2005

<li><A HREF="https://www.researchgate.net/publication/224576849_Bregman_Vantage_Point_Trees_for_Efficient_Nearest_Neighbor_Queries" target="_blank">
Bregman Vantage Point Trees for Efficient Nearest Neighbor Queries</A>, ICME 2009.

<li><A HREF="https://www.researchgate.net/publication/29605999_Tailored_Bregman_Ball_Trees_for_Effective_Nearest_Neighbors" target="_blank">
Tailored Bregman Ball Trees for Effective Nearest Neighbors</A>, Euro CG 2010.

<li><A HREF="https://www.researchgate.net/publication/266542408_Mining_Matrix_Data_with_Bregman_Matrix_Divergences_for_Portfolio_Selection" target="_blank">
Mining Matrix Data with Bregman Matrix Divergences for Portfolio Selection</A>

</ul>

<h2><u>Exponential families</u></h2>
Continuous or discrete exponential families
<ul>
<li><IMG SRC="new.png"><A HREF="https://arxiv.org/abs/2109.14920" target="_blank">
On the Kullback-Leibler divergence between discrete normal distributions</A><BR>
to appear as "The Kullback-Leibler divergence between lattice Gaussian distributions", Journal of the Indian Institute of Science, 2022.


<li><A HREF="https://arxiv.org/abs/2104.10548" target="_blank">
A note on some information-theoretic divergences between Zeta distributions</A>

<li><A HREF="https://www.researchgate.net/publication/314884662_Online_k-MLE_for_Mixture_Modeling_with_Exponential_Families" target="_blank">
Online k-MLE for Mixture Modeling with Exponential Families</A>

<li><A HREF="https://arxiv.org/abs/1203.5181" target="_blank">
k-MLE: A fast algorithm for learning statistical mixture models</A>, IEEE ICASSP 2012

<li><A HREF="https://www.researchgate.net/publication/223932258_Simplification_and_hierarchical_representations_of_mixtures_of_exponential_families" target="_blank">
Simplification and hierarchical representations of mixtures of exponential families</A>,
Signal Process. 90(12): 3197-3212 (2010)
</ul>


<h2><u>Mixture families</u></h2>

<ul>
<li><IMG SRC="new.png"><A HREF="https://arxiv.org/abs/2104.13801" target="_blank">
The analytic dually flat space of the statistical mixture family of two prescribed distinct Cauchy components</A>

<li><A HREF="https://arxiv.org/abs/1708.00568" target="_blank">
On the Geometry of Mixtures of Prescribed Distributions</A>, IEEE ICASSP 2018
</ul>



<h2><u>Information geometry of singular statistical models</u></h2>

<li><IMG SRC="new.png"><A HREF="https://arxiv.org/abs/2111.15090" target="_blank">
A Geometric Modeling of Occam's Razor in Deep Learning</A>

<li><IMG SRC="new.png"><A HREF="https://arxiv.org/abs/2112.03734" target="_blank">
Towards Modeling and Resolving Singular Parameter Spaces using Stratifolds</A>, Neurips OPT workshop 2021

 
</ul>


<h2><u>Geometry of time series and correlations/dependences</u></h2>

<ul>
<li><A HREF="https://arxiv.org/abs/2107.10606" target="_blank">
cCorrGAN: Conditional Correlation GAN for Learning Empirical Conditional Distributions in the Elliptope</A>

<li><A HREF="https://arxiv.org/abs/1509.08144" target="_blank">
Optimal copula transport for clustering multivariate time series</A>

<li><A HREF="http://proceedings.mlr.press/v55/marti16.html" target="_blank">
Exploring and measuring non-linear correlations: Copulas, Lightspeed Transportation and Clustering</A>, 
Time Series Workshop at NeurIPS 2016

<li><A HREF="https://arxiv.org/abs/1604.08634" target="_blank">
Optimal transport vs. Fisher-Rao distance between copulas for clustering multivariate time series</A>, IEEE SSP, 2016.

</ul>


<h2><u>Hilbert geometry</u></h2>
Hilbert geometry are induced by a bounded convex open domain.
Hilbert geometry generalize the Klein model of hyperbolic geometry and the Cayley-Klein geometry
Beware that Hilbert geometry are never Hilbert spaces! 
<ul>
<li><A HREF="https://arxiv.org/abs/1704.00454" target="_blank">Clustering in Hilbert simplex geometry</A>

<li><A HREF="https://www.researchgate.net/publication/307516299_Classification_with_mixtures_of_curved_mahalanobis_metrics" target="_blank">Classification with mixtures of curved mahalanobis metrics</A>, IEEE ICIP 2016

<li><A HREF="hhttps://drops.dagstuhl.de/opus/volltexte/2017/7244/" target="_blank">On Balls in a Hilbert Polygonal Geometry</A>, SoCG 2017.
</ul>

 
<h2><u>Hyperbolic geometry and geometry of Siegel domains</u></h2>
<ul>

<li><A HREF="https://www.mdpi.com/1099-4300/22/9/1019" target="_blank">
The Siegel–Klein Disk: Hilbert Geometry of the Siegel Disk Domain</A>, Entropy 2020

<li><A HREF="https://www.researchgate.net/publication/353241332_Classification_in_the_Siegel_Space_for_Vectorial_Autoregressive_Data target="_blank">
Classification in the Siegel Space for Vectorial Autoregressive Data</A>, GSI 2021.

<li><A HREF="https://www.researchgate.net/publication/24165620_Hyperbolic_Voronoi_Diagrams_Made_Easy" target="_blank">
 Hyperbolic Voronoi Diagrams Made Easy</A>, ICCSA 2010

<li><A HREF="https://www.researchgate.net/publication/317299570_Approximating_Covering_and_Minimum_Enclosing_Balls_in_Hyperbolic_Geometry
" target="_blank">
Approximating Covering and Minimum Enclosing Balls in Hyperbolic Geometry
</A>

</ul>

<h1>Some applications of information geometry</h1>


<h2><u>Natural gradient</u></h2>

<ul>
<li><A HREF="https://proceedings.mlr.press/v139/lin21e.html" target="_blank">
Tractable structured natural-gradient descent using local parameterizations</A>, ICML 2021

<li><A HREF="https://proceedings.mlr.press/v70/sun17b.html" target="_blank">
Relative Fisher Information and Natural Gradient for Learning Large Modular Models</A>, ICML 2017

</ul>

<h2><u>Centers and clustering</u></h2>

<ul>
<li><A HREF="https://arxiv.org/abs/1311.5125" target="_blank">
On conformal divergences and their population minimizers</A>, IEEE Transactions Information Theory, 62.1 (2015): 527-538


<li><A HREF="https://arxiv.org/abs/1004.5049" target="_blank">
The Burbea-Rao and Bhattacharyya centroids</A>, IEEE Transactions on Information Theory, 57(8), 5455-5466 (2011)

<li><A HREF="https://arxiv.org/abs/1004.5049" target="_blank">
https://www.researchgate.net/publication/224460161_Sided_and_Symmetrized_Bregman_Centroids</A>, IEEE transactions on Information Theory 55.6 (2009): 2882-2904

<li><A HREF="https://arxiv.org/abs/1403.2485" target="_blank">
Optimal Interval Clustering: Application to Bregman Clustering and Statistical Mixture Learning</A>, IEEE SPL 2014


<li><A HREF="https://www.mdpi.com/1099-4300/16/6/3273" target="_blank">
https://www.mdpi.com/1099-4300/16/6/3273</A>, Entropy 2014

</ul>

<h2><u>Miscellaneous applications</u></h2>

<ul>
<li><A HREF="https://proceedings.mlr.press/v161/masrani21a.html" target="_blank">
q-Paths: Generalizing the geometric annealing path using power means</A>, UAI 2021


<li><A HREF="https://www.researchgate.net/publication/258791961_An_Information-Geometric_Characterization_of_Chernoff_Information" target="_blank">
An Information-Geometric Characterization of Chernoff Information
</A>, IEEE SPL 2013

</ul>

 

<h1>Dissimilarities, distances, divergences and diversities</h1>

<h2><u>Jensen-Shannon divergence</u></h2>

<ul>

<li><A HREF="https://www.mdpi.com/1099-4300/23/4/464" target="_blank">
On a Variational Definition for the Jensen-Shannon Symmetrization of Distances Based on the Information Radius</A>, Entropy 2021.


<li><A HREF="https://www.mdpi.com/1099-4300/22/2/221" target="_blank">
On a Generalization of the Jensen-Shannon Divergence and the Jensen–Shannon Centroid</A>, Entropy 2020

<li><A HREF="https://www.mdpi.com/1099-4300/21/5/485" target="_blank">
On the Jensen-Shannon Symmetrization of Distances Relying on Abstract Means</A>, Entropy 2019

</ul>

<h2><u>f-divergences</u></h2>

<ul>
<li><A HREF="https://arxiv.org/abs/2101.12459" target="_blank">
On f-divergences between Cauchy distributions</A>

<li><A HREF="https://arxiv.org/abs/1309.3029" target="_blank">
On the Chi square and higher-order Chi distances for approximating f-divergences</A>
</ul>
  
<h2>Conformal divergences</h2>
<ul>
<li><A HREF="https://arxiv.org/abs/1311.5125" target="_blank">
On conformal divergences and their population minimizers</A>, IEEE Transactions Information Theory, 62.1 (2015): 527-538

<li><A HREF="https://arxiv.org/abs/1309.7109" target="_blank">
Total Jensen divergences: Definition, Properties and k-Means++ Clustering</A>, IEEE ICASSP 2015

<li><A HREF="https://www.researchgate.net/publication/257205113_Total_Bregman_Divergence_and_its_Applications_to_Shape_Retrieval" target="_blank">
Total Bregman Divergence and its Applications to Shape Retrieval</A>, CVPR 2010

<li><A HREF="https://www.researchgate.net/publication/47449618_Total_Bregman_Divergence_and_Its_Applications_to_DTI_Analysis" target="_blank">
Total Bregman divergence and its applications to DTI analysis</A>, IEEE Transactions on Medical Imaging 30(2):475-83, 2011

</ul>

<h2><u>Projective divergences</u></h2>
<ul>
<li><A HREF="https://www.mdpi.com/1099-4300/19/3/122" target="_blank">
On Hölder Projective Divergences</A>, Entropy 2017, 19(3), 122

<li><A HREF="https://www.researchgate.net/publication/312697428_Patch_Matching_with_Polynomial_Exponential_Families_and_Projective_Divergences" target="_blank">
Patch Matching with Polynomial Exponential Families and Projective Divergences</A>, SISAP 2016
(projective <b>gamma divergence</b>)

</ul>

<h2><u>Optimal transport/Wasserstein distances</u></h2>
Earth mover distances (EMD), Wasserstein distances

<ul>
<li><A HREF="https://arxiv.org/abs/1812.08113" target="_blank">
On The Chain Rule Optimal Transport Distance</A>


<li><A HREF="https://arxiv.org/abs/1609.04495" target="_blank">
Tsallis Regularized Optimal Transport and Ecological Inference</A>, AAAI 2017

<li><A HREF="https://arxiv.org/abs/1509.08144" target="_blank">
Optimal copula transport for clustering multivariate time series</A>

<li><A HREF="http://proceedings.mlr.press/v55/marti16.html" target="_blank">
Exploring and measuring non-linear correlations: Copulas, Lightspeed Transportation and Clustering</A>, 
Time Series Workshop at NeurIPS 2016

<li><A HREF="https://www.researchgate.net/publication/224200406_Earth_Mover_Distance_on_superpixels" target="_blank">
Earth Mover Distance on superpixels</A>, IEEE ICIP 2010

</ul>

<h2><u>Shannon, Rényi, Tsallis, Sharmal-Mittal entropies, cross-entropies and divergences</u></h2>

<ul>

<li><A HREF="https://arxiv.org/abs/1112.4221" target="_blank">
A closed-form expression for the Sharma-Mittal entropy of exponential families</A>,
Journal of Physics A: Mathematical and Theoretical 45.3 (2011).


<li><A HREF="https://arxiv.org/abs/1105.3259" target="_blank">
On Rényi and Tsallis entropies and divergences for exponential families</A>

<li><A HREF="https://www.researchgate.net/publication/221126408_Entropies_and_cross-entropies_of_exponential_families" target="_blank">
Entropies and cross-entropies of exponential families</A>, IEEE ICIP 2010
</li>

</ul>

<h2><u>Chernoff information</u></h2>


<ul>

<li><A HREF="https://www.researchgate.net/publication/259804301_Generalized_Bhattacharyya_and_Chernoff_upper_bounds_on_Bayes_error_using_quasi-arithmetic_means" target="_blank">
Generalized Bhattacharyya and Chernoff upper bounds on Bayes error using quasi-arithmetic means
</A>, Pattern Recognition Letters 42(1), 2014


<li><A HREF="https://www.researchgate.net/publication/258791961_An_Information-Geometric_Characterization_of_Chernoff_Information" target="_blank">
An Information-Geometric Characterization of Chernoff Information
</A>, IEEE SPL 2013

<li><A HREF="https://www.researchgate.net/publication/268998068_Hypothesis_Testing_Information_Divergence_and_Computational_Geometry" target="_blank">
Hypothesis Testing, Information Divergence and Computational Geometry
</A>, GSI 2013

</ul>
 

<h2><u>Divergences between mixtures</u></h2>
 
<ul>

<li><A HREF="https://www.mdpi.com/1099-4300/23/11/1417" target="_blank">
Fast Approximations of the Jeffreys Divergence between Univariate Gaussian Mixtures 
via Mixture Conversions to Exponential-Polynomial Distributions</A>, 
Entropy 2021, 23(11), 1417

<li><A HREF="https://arxiv.org/abs/1901.03732" target="_blank">
The Statistical Minkowski Distances: Closed-Form Formula for Gaussian Mixture Models</A>

<li><A HREF="https://arxiv.org/abs/1806.11311" target="_blank">
Guaranteed Deterministic Bounds on the total variation Distance between univariate mixtures</A>

<li><A HREF="https://www.researchgate.net/publication/304372111_Comix_Joint_estimation_and_lightspeed_comparison_of_mixture_models" target="_blank">
Comix: Joint estimation and lightspeed comparison of mixture models
</A>

<li><A HREF="https://www.mdpi.com/1099-4300/18/12/442" target="_blank">
Guaranteed Bounds on Information-Theoretic Measures of Univariate Mixtures Using Piecewise Log-Sum-Exp Inequalities
</a>, Entropy 2016, 18(12), 442


<li><A HREF="https://www.researchgate.net/publication/317724631_Combinatorial_bounds_on_the_a-divergence_of_univariate_mixture_models" target="_blank">
Combinatorial bounds on the α-divergence of univariate mixture models</A>, ICASSP 2017

<li><A HREF="https://www.researchgate.net/publication/332141712_Closed-Form_Information-Theoretic_Divergences_for_Statistical_Mixtures" target="_blank">
Closed-form information-theoretic divergences for statistical mixtures</A>, ICPR 2012




</ul>

  
<hr>
<h1>Edited books and proceedings</h1>

 	<ul>
   <li><A HREF="https://www.springer.com/us/book/9783030025199" target="_blank">Geometric Structures of Information</A>, Springer 2019
   <li><A HREF="https://www.springer.com/fr/book/9783319470566" target="_blank">Computational Information Geometry
For Image and Signal Processing</A>, Springer 2017
<li><A HREF="https://www.mdpi.com/journal/entropy/special_issues/entropy-statistics" target="_blank">Differential Geometrical Theory of Statistics</A>, MDPI Entropy, Special issue,  2017
   <li><A HREF="https://www.springer.com/la/book/9783319053165" target="_blank">Geometric Theory of Information</A>, Springer 2014
   <li><A HREF="https://www.springer.com/la/book/9783642302312" target="_blank">Matrix Information Geometry</A>, Springer 2013
   
  
 <li>Proceedings: <A HREF="https://www.springer.com/la/book/9783642008252" target="_blank">ETVC 2008</A>
  <A HREF="https://www.springer.com/la/book/9783642400193" target="_blank">GSI'13</A>
   <A HREF="https://www.springer.com/us/book/9783319250397" target="_blank">GSI'15</A>
    <A HREF="https://www.springer.com/jp/book/9783319684444" target="_blank">GSI'17</A>
  <A HREF="https://www.springer.com/jp/book/9783030269791" target="_blank">GSI'19</A>
  
   </ul>
<hr>
Home page of <A HREF="https://franknielsen.github.io/GSI/" target="_blank">Geometric Science of Information</A>
<hr>
December 2021.
    </body>
</html>

  