<html>
  <head>
    <title>Frank Nielsen | Information Geometry, divergences, and diversities | Geometric Science of Information</title>
  </head>
  <body bgcolor=white>  
  
<h1>Information geometry and divergences</h1>

<p> <!-- style="background-color:#ffccee;"> -->
Historically, <b>Information Geometry</b> (IG, <A HREF="#tutorials" target="_blank">tutorials</A>) aimed at unravelling the geometric structures 
of families of probability distributions called the <b>statistical models</b>.<BR>
A statistical model can either be
<ul>
<li> parametric (eg., family of normal distributions), 
<li>semi-parametric 
(eg., family of Gaussian mixture models) or 
<li>non-parametric (family of mutually absolutely continuous smooth densities).
</ul>
A parametric statistical model is said <b>regular</b> when the Fisher information matrix is positive-definite (and well-defined).
Otherwise, the statistical model is irregular (eg., infinite Fisher information and semi-positive definite Fisher information when the model is not identifiable).
</p>
<p style="background-color:#ffccee;"> 
The <b><a href="#FisherRao" target="_blank">Fisher-Rao manifold</a></b> of a statistical parametric model is a Riemannian manifold equipped
 with the <b>Fisher information metric</b>.
 The geodesic length on a Fisher-Rao manifold is called <b>Rao's distance</b> [Hotelling 1930][Rao 1945].
More generally, Amari proposed the <b>dualistic structure</b> of IG which consists 
of a pair of torsion-free affine connections coupled to the Fisher metric [Amari 1980's].
Given a dualistic structure, we can build generically a one-parameter family of
 dualistic information-geometric structures, 
called the <b>α-geometry</b>.
When both connections are flat, the information-geometric space is said <b>dually flat</b>: 
For example, the Amari's ±1-structures of <b>exponential families</b> and <b>mixture families</b> 
are famous examples of dually flat spaces in information geometry.
In differential geometry, <b>geodesics</b> are defined as autoparallel curves with respect to a connection.
When using the default Levi-Civita metric connection derived from the Fisher metric on Fisher-Rao manifolds, 
we get  Rao's distance which are locally minimizing geodesics.
Eguchi showed how to build from any smooth distortion (originally called a contrast function) 
a dualistic structure: The <b>information geometry of divergences</b> [Eguchi 1982].
The information geometry of <b><A HREF="#HessianMfd" target="_blank">Bregman divergences</A></b> yields dually flat spaces:
It is a special cases of <b>Hessian manifolds</b> which are differentiable manifolds 
equipped with a metric tensor being a Hessian metric and a flat connection [Shima 2007].
Since geometric structures scaffold spaces independently of any applications, 
these pure information-geometric Fisher-Rao structure and α-structures of statistical models 
can also be used in  non-statistical contexts too: 
For example, for analyzing interior point methods with barrier functions in optimization, or for studying time-series models, etc.
</p>

<p style="background-color: #f2e6ff;">
<b><A HREF="#dissimilarity" target="_blank">Statistical divergences</a></b> between parametric statistical models amount to 
<b>parameter divergences</b> on which we can use the Eguchi's divergence information geometry 
to get a dualistic structure.
A <b><A HREF="#projDiv" target="_blank">projective divergence</a></b> is a divergence which is invariant by independent rescaling of its parameters.
A statistical projective divergence is thus useful for estimating computationally 
intractable statistical models (eg., gamma divergences, Cauchy-Schwarz divergence and Hölder divergences, or singly-sided projective Hyvärinen divergence).
A <b><A HREF="#confDiv" target="_blank">conformal divergence</a></b> is a divergence scaled by a conformal factor which may depend on one or two of its arguments.
The metric tensor obtained from Eguchi's information divergence of a conformal divergence 
is a <b>conformal metric</b> of the metric obtained from the divergence, hence its name.
By analogy to total least squares vs least squares, a
 <b>total divergence</b> is a divergence which is invariant wrt. to rotations (eg., total Bregman divergences).
 An important property of divergences on the probability simplex is to be <b>monotone</b> by coarse-graining.
 That is, merging bins and considering reduced histograms should give a distance less or equal than the distance on the full resolution histograms.
 This <b>information monotonicity</b> property holds for <a href="#fdiv" target="_blank">f-divergences</A> (called invariant divergences in information geometry), 
 Hilbert log cross-ratio distance, or Aitchison distance for example.
 Some statistical divergences are upper <b>bounded</b>
 (eg., <a href="#JSD" target="_blank">Jensen-Shannon divergence</A>) while others are not (eg., Jeffreys' divergence).
<b><A HREF="#OT" target="_blank">Optimal transport</a></b> distances require a <b>ground base distance</b> on the sample space.
A <b><A HREF="#JD" target="_blank">diversity index</a></b> generalizes a <b>two-point distance</b> to a family of parameters/distributions.
It usually measures the dispersion around a center point (eg., like variance measures 
the dispersion around the <a href="#clustering" target="_blank">centroid</A>).
</p>


<p>
Browsing geometric structures:
[<a href="#tutorials" target="_blank">tutorials</A>]
[<a href="#FisherRao" target="_blank">Fisher-Rao manifolds</A>]
[<a href="#cone" target="_blank">Cones</A>]
[<a href="#Finsler" target="_blank">Finsler manifolds</A>]
[<a href="#HessianMfd" target="_blank">Hessian manifolds</A>]
[<a href="#EFMF" target="_blank">Exponential families and mixture families</A>]
[<a href="#ProbaSimplex" target="_blank">Categorical distributions/probability simplex</A>]
[<a href="#geoTS" target="_blank">Time series</A>]
[<a href="#geoHilbert" target="_blank">Hilbert geometry</A>]
[<a href="#hyperbolic" target="_blank">Hyperbolic geometry and Siegel spaces</A>]
[<a href="#applications" target="_blank">Applications</A>]
[<a href="#natgrad" target="_blank">Natural gradient</A>]
[<a href="#clustering" target="_blank">centroids and clustering</A>]
[<a href="#miscapp" target="_blank">Miscellaneous applications</A>] 
</p>

<p>
Browsing [<a href="#dissimilarity" target="_blank">Dissimilarities</A>]:
[<a href="#JSD" target="_blank">Jensen-Shannon divergence</A>]
[<a href="#fdiv" target="_blank">f-divergences</A>]
[<a href="#JD" target="_blank">Bregman divergences</A>]
[<a href="#BD" target="_blank">Jensen divergences</A>]
[<a href="#confDiv" target="_blank">conformal divergences</A>]
[<a href="#projDiv" target="_blank">projective divergences</A>]
[<a href="#OT" target="_blank">optimal transport</A>]
[<a href="#entropy" target="_blank">entropies</A>]
[<a href="#Chernoff" target="_blank">Chernoff information</A>]
</p>

<h2 id="tutorials"><u>Information geometry: Tutorials and surveys</u></h2>

<ul>
<li><IMG SRC="new.png"><A HREF="https://www.ams.org/journals/notices/202201/rnoti-p36.pdf" target="_blank">The Many Faces of Information Geometry</A>, AMS Notices (9 pages), 2022.
<p style="background-color:powderblue;">A gentle short introduction to information geometry</p>

<center>
<A HREF="Fig-GenesisIG-Portraits.pdf" target="_blank"><IMG SRC="GenesisDualIG.png" width="15%" border="3"></A>
</center>

<li><A HREF="https://www.mdpi.com/1099-4300/22/10/1100" target="_blank">An Elementary Introduction to Information Geometry</A>, Entropy (61 pages), 2020.
<p>A self-contained introduction to classic parametric information geometry with applications and basics of differential geometry</p>

<center>
<A HREF="https://www.mdpi.com/1099-4300/22/10/1100" target="_blank"><IMG SRC="entropy-22-01100-ag.png"
 width="25%" border="3"></A>
</center>
 


<li><A HREF="https://www.ams.org/journals/notices/201803/rnoti-p321.pdf" target="_blank">What is an information projection?</A>, AMS Notices, (65) 3 (4 pages), 2018.  
<p>Information projections are the workhorses of algorithms using the framework of information geometry.
A projection is defined according to geodesics (wrt a connection) and orthogonality (wrt a metric tensor).
In dually flat spaces, information projections can be interpreted as minimum Bregman divergences (Bregman projections).
Unicity theorems for exponential families and mixture families.</p>

<center>
<A HREF="https://www.ams.org/journals/notices/201803/rnoti-p321.pdf" target="_blank"><IMG SRC="Card-WhatIsInformationProjection.png"
 width="25%" border="3"></A>
</center>



<li><A HREF="https://arxiv.org/abs/1910.03935" target="_blank">On Geodesic Triangles with Right Angles in a Dually Flat Space</a>, Chapter in edited book "Progress in Information Geometry", Springer, 2021.
<p>A self-contained introduction to dually flat spaces which we call Bregman manifolds. The generalized Pythagorean theorem is derived from the 3-parameter Bregman identity. 
The 4-parameter Bregman identity is also explained</p> 

<center>
<A HREF="https://arxiv.org/abs/1910.03935" target="_blank"><IMG 
SRC="Card-DFSDualPythagorasTriangles.png"
 width="25%" border="3"></A>
</center>


<li><A HREF="https://arxiv.org/abs/1301.3578" target="_blank">Cramér-Rao Lower Bound and Information Geometry</A>, Connected at Infinity II: On the work of Indian mathematicians (R. Bhatia and C.S. Rajan, Eds.), special volume of Texts and Readings In Mathematics (TRIM), Hindustan Book Agency, 2013
<p>A description of the pathbreaking paper of Calyampudi Radhakrishna Rao (1945): "Information and the accuracy attainable in the estimation of statistical parameters", 1945.</p>

 
 

<center>
<A HREF="https://arxiv.org/abs/1301.3578" target="_blank"><IMG SRC="ConnectedInfinityII.jpg" 
height="200" border="3"></A>
<IMG SRC="VisualizingCramerRaoLowerBound.gif" height="200">
</center>

<li><A HREF="https://arxiv.org/abs/0911.4863" target="_blank">
Statistical exponential families: A digest with flash cards</A>, 2009

<center>
<A HREF="https://arxiv.org/abs/0911.4863" target="_blank"><IMG SRC="Card-EFCArds.png" 
width="25%" border="3"></A>
</center>



<li><A HREF="https://www.researchgate.net/publication/262236656_Pattern_Learning_and_Recognition_on_Statistical_Manifolds_An_Information-Geometric_Review" target="_blank">
Pattern Learning and Recognition on Statistical Manifolds: An Information-Geometric Review</A>, SIMBAD 2013

<center>
<A HREF="https://www.researchgate.net/publication/262236656_Pattern_Learning_and_Recognition_on_Statistical_Manifolds_An_Information-Geometric_Review" target="_blank"><IMG 
SRC="CARD-SIMBAD2013.png"
 width="25%" border="3"></A>
</center>



<li><A HREF="Note-LegendreTransformation.pdf" target="_blank">Legendre transformation and information geometry</A>, memo, 2010


</ul>


<h2 id="FisherRao"><u>Fisher-Rao manifolds</u> (Riemannian manifolds and Hamadard manifolds)</h2>
<ul>

<li>Fisher-Rao manifold of the categorical distributions

<p>Fisher-Rao manifold of the categorical distributions can be isometrically embedded on the positive orthant of the sphere of radius 2 in 
Euclidean space. Rao distance   thus corresponds to the length of great circle arc, and relaxing the embedded distributions to positive measures, we get twice the Hellinger divergence.
 (<A HREF="https://arxiv.org/abs/2104.13801" target="_blank">explanation</A>)
</p>

<li><A HREF="https://proceedings.mlr.press/v70/sun17b.html" target="_blank">
Relative Fisher Information and Natural Gradient for Learning Large Modular Models</A>, ICML 2017
<p>Dynamic geometry with relative Fisher information metric</p>
<ul>
<li><A HREF="https://vimeo.com/240781939" target="_blank">talk video</A> (17 min.)
<li>[<A HREF="https://franknielsen.github.io/RFIM/index.html" target="_blank">Project</A>]

<center>
<A HREF="https://proceedings.mlr.press/v70/sun17b.html" target="_blank"><IMG 
SRC="Visual-RFIM.png"
 width="25%" border="3"></A>
</center>

<li>Voronoi diagrams on Fisher-Rao manifolds of location-scale families amount to hyperbolic Voronoi diagrams.
<A HREF="https://arxiv.org/abs/0903.3287" target="_blank">Hyperbolic Voronoi diagrams made easy</A> (ICCSA 2010)
<center>
<A HREF="https://proceedings.mlr.press/v70/sun17b.html" target="_blank"><IMG 
SRC="PoincareVorHyperbolicDelaunayComplex.gif"
 width="25%" border="3"></A>
</center>
</ul>


<li><IMG SRC="new.png"><A HREF="https://arxiv.org/abs/2111.15090" target="_blank">
A Geometric Modeling of Occam's Razor in Deep Learning</A>
<p>Degenerates metric and lightlike Fisher-Rao manifolds</p>
<center>
<A HREF="https://arxiv.org/abs/2111.15090" target="_blank"><IMG 
SRC="NCard-LightlikeManifoldFIM.png"
 width="25%" border="3"></A>
</center>



<li><A HREF="https://hal.archives-ouvertes.fr/hal-00560187/document" target="_blank">On Approximating the Riemannian 1-Center
</A>,  Computational Geometry, 2013.
<p>Approximating the smallest enclosing Riemannian ball by a simple iterative algorithm which proves the existence of coresets. Applications to Hadamard manifolds (hyperbolic geometry and Riemannian manifold of symmetric positive-definite matrices equipped with the trace metric.</p>


<li><A HREF="https://www.researchgate.net/publication/322997672_GLSR-VAE_Geodesic_latent_space_regularization_for_variational_autoencoder_architectures" target="_blank">
GLSR-VAE: Geodesic latent space regularization for variational autoencoder architectures 
</A>, IEEE SSCI 2017.

<center>
<A HREF="https://www.researchgate.net/publication/322997672_GLSR-VAE_Geodesic_latent_space_regularization_for_variational_autoencoder_architectures" target="_blank"><IMG 
SRC="Visual-GLSR-VAE.png"
 width="25%" border="3"></A>
</center>


</ul>

<h2 id ="cone"><u>Cones</u></h2>

<ul>
<li>
<A HREF="https://arxiv.org/abs/1604.01592" target="_blank">
Fast (1+ε)-approximation of the Löwner extremal matrices of high-dimensional symmetric matrices
</A>
</li>

</ul>


<h2 id="Finsler"><u>Finsler manifolds</u></h2>
Finsler manifolds are proposed to model irregular parametric statistical models (where Fisher information can be infinite)
<ul>
<li>
<A HREF="https://hal.archives-ouvertes.fr/hal-00560187/document" target="_blank">
Medians and means in Finsler geometry</A>, LMS Journal of Computation and Mathematics 15 (2012): 23-37.
</ul>


<h2 id="HessianMfd"><u>Bregman manifolds/Hessian manifolds</u></h2>
 
<ul>
<li><A HREF="https://hal.archives-ouvertes.fr/hal-00488441/document" target="_blank">
Bregman Voronoi diagrams</A>
<p>
Bregman Voronoi diagrams (or VDs in dually flat spaces) are affine diagrams which can be built from equivalent power diagrams (Laguerre geometry).
Generalize the paraboloid lifting transform of Euclidean geometry to potentials functions induced 
by the convex Bregman generators.

<center>
<IMG SRC="DualBregmanVoronoi.gif" height="200">
</center>
</p>

<li><A HREF="https://www.researchgate.net/publication/220983330_Visualizing_bregman_voronoi_diagrams" target="_blank">
Visualizing Bregman Voronoi diagrams</A>, SoCG 2007: 121-122


<li><A HREF="https://www.researchgate.net/publication/335159741_Geometry_and_Fixed-Rate_Quantization_in_Riemannian_Metric_Spaces_Induced_by_Separable_Bregman_Divergences" target="_blank">
Geometry and Fixed-Rate Quantization in Riemannian Metric Spaces Induced by Separable Bregman Divergences
</A>, GSI 2019

<li><A HREF="https://hal.archives-ouvertes.fr/hal-00488441/document" target="_blank">
https://www.researchgate.net/publication/221112384_Fitting_the_Smallest_Enclosing_Bregman_Ball</A>, ECML 2005

<li>Bregman proximity data-structures and queries 
[<A HREF="https://franknielsen.github.io/BregmanProximity/" target="_blank">web page</A>]:

<ul>
<li><A HREF="https://www.researchgate.net/publication/224576849_Bregman_Vantage_Point_Trees_for_Efficient_Nearest_Neighbor_Queries" target="_blank">
Bregman Vantage Point Trees for Efficient Nearest Neighbor Queries</A>, ICME 2009.

<li><A HREF="https://www.researchgate.net/publication/29605999_Tailored_Bregman_Ball_Trees_for_Effective_Nearest_Neighbors" target="_blank">
Tailored Bregman Ball Trees for Effective Nearest Neighbors</A>, Euro CG 2010.
</ul>

<li><A HREF="https://www.researchgate.net/publication/266542408_Mining_Matrix_Data_with_Bregman_Matrix_Divergences_for_Portfolio_Selection" target="_blank">
Mining Matrix Data with Bregman Matrix Divergences for Portfolio Selection</A>

<li><A HREF="https://www.researchgate.net/publication/222403585_On_the_smallest_enclosing_information_disk" target="_blank">
On the smallest enclosing information disk</A>,
 Inf. Process. Lett. 105(3): 93-97 (2008)
<center>
<IMG SRC="eKLcircle-animation.gif" height="200">
<IMG SRC="ItakuraSaitoCircle-MovingPoints.gif" height="200">
</center>


</ul>

<h2 id="EFMF"><u>Exponential families</u> and <u>Mixture families</u></h2>
Continuous or discrete exponential families



<ul>
  
<li><A HREF="https://link.springer.com/article/10.1007/s41745-021-00279-5" target="_blank">The 
Kullback–Leibler Divergence Between Lattice Gaussian Distributions</A>,
Journal of the Indian Institute of Science (2022)
<BR>
<A HREF="https://arxiv.org/abs/2109.14920" target="_blank">arXiv:2109.14920</A>
[<A HREF="../LatticeGaussian/LatticeGaussian.html" target="_blank">project page</A>]


<center>
<A HREF="https://link.springer.com/article/10.1007/s41745-021-00279-5" target="_blank"><IMG 
SRC="NCard-PublishedLatticeGaussianDivergences.png"
 width="25%" border="3"></A>
</center>
<center>
<IMG SRC="DiscreteIsotropicNormal2D.gif" width="200">
</center>

<li><A HREF="https://arxiv.org/abs/0911.4863" target="_blank">
Statistical exponential families: A digest with flash cards</A>, 2009
 

<li><A HREF="https://arxiv.org/abs/2104.10548" target="_blank">
A note on some information-theoretic divergences between Zeta distributions</A>

<li><A HREF="https://www.researchgate.net/publication/329073090_Monte_Carlo_Information-Geometric_Structures" target="_blank">
Monte Carlo Information-Geometric Structures</A>, Geometric Structures of Information, Springer 2019

<center>
<IMG SRC="VorMixN128Increase.gif" width="250">
</center>


<li>k-MLE:
</ul>

<li><A HREF="https://www.researchgate.net/publication/314884662_Online_k-MLE_for_Mixture_Modeling_with_Exponential_Families" target="_blank">
Online k-MLE for Mixture Modeling with Exponential Families</A>, GSI 2015

<li><A HREF="https://arxiv.org/abs/1203.5181" target="_blank">
k-MLE: A fast algorithm for learning statistical mixture models</A>, IEEE ICASSP 2012

<li><A HREF="https://www.researchgate.net/publication/261845618_Fast_Learning_of_Gamma_Mixture_Models_with_k-MLE" target="_blank">
Fast Learning of Gamma Mixture Models with k-MLE</A>, SIMBAD 2013: 235-249

<li><A HREF="https://www.researchgate.net/publication/261342740_K-MLE_for_mixtures_of_generalized_Gaussians" target="_blank">
k-MLE for mixtures of generalized Gaussians</A>,
 ICPR 2012: 2825-2828

</ul>

<li><A HREF="https://www.researchgate.net/publication/223932258_Simplification_and_hierarchical_representations_of_mixtures_of_exponential_families" target="_blank">
Simplification and hierarchical representations of mixtures of exponential families</A>,
Signal Process. 90(12): 3197-3212 (2010)
 
<li><IMG SRC="new.png"><A HREF="https://arxiv.org/abs/2104.13801" target="_blank">
The analytic dually flat space of the statistical mixture family of two prescribed distinct Cauchy components</A>

<li><A HREF="https://arxiv.org/abs/1708.00568" target="_blank">
On the Geometry of Mixtures of Prescribed Distributions</A>, IEEE ICASSP 2018
</ul>

<h2><u>Information geometry of deformed exponential families</u></h2>
<p>q-deformed exponential families, q-Gaussians, etc.</p>

<ul>
<li><A HREF="https://www.mdpi.com/1099-4300/22/7/713" target="_blank">
On Voronoi Diagrams on the Information-Geometric Cauchy Manifolds</A>, Entropy 2020, 22(7), 713
</ul>


<h2 id="ProbaSimplex"><u>Information geometry of the probability simplex</u></h2>

<u>

<li><A HREF="https://arxiv.org/abs/1704.00454" target="_blank">Clustering in Hilbert simplex geometry</A>
[<A HREF="https://franknielsen.github.io/HSG/" target="_blank">project page</A>]


<li><A HREF="Geometry of the probability simplex and its connection to 
the maximum entropy method" target="_blank">Geometry of the probability simplex and
 its connection to the maximum entropy method</A>,
Journal of Applied Mathematics, Statistics and Informatics 16(1):25-35, 2020<BR>
Bruhat-Tits space<BR>
<A HREF="https://sciendo.com/article/10.2478/jamsi-2020-0003#" target="_blank">open access</a> (publisher)


</u>

<h2 id="SingularModel"><u>Information geometry of singular statistical models</u></h2>

<li><IMG SRC="new.png"><A HREF="https://arxiv.org/abs/2111.15090" target="_blank">
A Geometric Modeling of Occam's Razor in Deep Learning</A>

<li><IMG SRC="new.png"><A HREF="https://arxiv.org/abs/2112.03734" target="_blank">
Towards Modeling and Resolving Singular Parameter Spaces using Stratifolds</A>, Neurips OPT workshop 2021

 
</ul>


<h2 id="GeoTS"><u>Geometry of time series and correlations/dependences</u></h2>

<ul>



 

<li><A HREF="https://arxiv.org/abs/1703.00485" target="_blank">
A review of two decades of correlations, hierarchies, networks and clustering in financial markets</A>


<li><A HREF="https://arxiv.org/abs/2107.10606" target="_blank">
cCorrGAN: Conditional Correlation GAN for Learning Empirical Conditional Distributions in the Elliptope</A>

<li><A HREF="https://arxiv.org/abs/1509.08144" target="_blank">
Optimal copula transport for clustering multivariate time series</A>

<li><A HREF="http://proceedings.mlr.press/v55/marti16.html" target="_blank">
Exploring and measuring non-linear correlations: Copulas, Lightspeed Transportation and Clustering</A>, 
Time Series Workshop at NeurIPS 2016

<li><A HREF="https://arxiv.org/abs/1604.08634" target="_blank">
Optimal transport vs. Fisher-Rao distance between copulas for clustering multivariate time series</A>, IEEE SSP, 2016.

<li><A HREF="https://www.ijcai.org/Proceedings/16/Papers/367.pdf" target="_blank">
Clustering Financial Time Series: How Long Is Enough?</A>,
 IJCAI 2016: 2583-2589<BR>
 <A HREF="https://arxiv.org/abs/1603.04017" target="_blank">1603.04017</A>


</ul>


<h2 id="GeoHilbert"><u>Hilbert geometry</u></h2>
Hilbert geometry are induced by a bounded convex open domain.
Hilbert geometry generalize the Klein model of hyperbolic geometry and the Cayley-Klein geometry
Beware that Hilbert geometry are never Hilbert spaces! 
<ul>

<li><A HREF="https://arxiv.org/abs/1704.00454" target="_blank">Clustering in Hilbert simplex geometry</A>
[<A HREF="https://franknielsen.github.io/HSG/" target="_blank">project page</A>]
<center>
<IMG SRC="HilbertSimplexHexagonalVoronoi-n16.gif" width="300">
</center>

<li><A HREF="https://www.researchgate.net/publication/307516299_Classification_with_mixtures_of_curved_mahalanobis_metrics" target="_blank">Classification with mixtures of curved mahalanobis metrics</A>, IEEE ICIP 2016

<li><A HREF="hhttps://drops.dagstuhl.de/opus/volltexte/2017/7244/" target="_blank">On Balls in a Hilbert Polygonal Geometry</A>, SoCG 2017.
</ul>

 
<h2 id="hyperbolic"><u>Hyperbolic geometry and geometry of Siegel domains</u></h2>
<ul>

<li><A HREF="https://www.mdpi.com/1099-4300/22/9/1019" target="_blank">
The Siegel–Klein Disk: Hilbert Geometry of the Siegel Disk Domain</A>, Entropy 2020

<li><A HREF="GSI2021-SiegelLogExpClassification.pdf" target="_blank">
Classification in the Siegel Space for Vectorial Autoregressive Data</A>, GSI 2021.

<li><A HREF="https://www.researchgate.net/publication/24165620_Hyperbolic_Voronoi_Diagrams_Made_Easy" target="_blank">
 Hyperbolic Voronoi Diagrams Made Easy</A>, ICCSA 2010
 
 <center>
 
 
  <IMG SRC="BisectorKleinPoincare.gif" height="200"> &nbsp;
 <IMG SRC="HyperbolicVoronoiDiagram.gif" height="200"> &nbsp;
 <IMG SRC="ConstantSpeedKleinGeodesics.gif" height="200">&nbsp;
 <IMG SRC="korderVorPoincare.gif" height="200">
 
 </center>
 
 <li><A HREF="https://www.researchgate.net/publication/261118968_Model_centroids_for_the_simplification_of_Kernel_Density_estimators" target="_blank">
 Model centroids for the simplification of Kernel Density estimators</A>,
 ICASSP 2012: 737-740
 
 
 <li><A HREF="https://www.researchgate.net/publication/266656391_Visualizing_hyperbolic_Voronoi_diagrams" target="_blank">
 Visualizing hyperbolic Voronoi diagrams</A>,
 SoCG 2014: 90


<li><A HREF="https://www.researchgate.net/publication/317299570_Approximating_Covering_and_Minimum_Enclosing_Balls_in_Hyperbolic_Geometry
" target="_blank">
Approximating Covering and Minimum Enclosing Balls in Hyperbolic Geometry
</A>

</ul>

<h1 id="applications">Some applications of information geometry</h1>


<h2 id="natgrad"><u>Natural gradient</u></h2>

<ul>
<li><A HREF="https://proceedings.mlr.press/v139/lin21e.html" target="_blank">
Tractable structured natural-gradient descent using local parameterizations</A>, ICML 2021

<li><A HREF="https://proceedings.mlr.press/v70/sun17b.html" target="_blank">
Relative Fisher Information and Natural Gradient for Learning Large Modular Models</A>, ICML 2017

</ul>

<h2 id="clustering"><u>Centers and clustering</u></h2>

<ul>
<li><A HREF="https://arxiv.org/abs/1311.5125" target="_blank">
On conformal divergences and their population minimizers</A>, IEEE Transactions Information Theory, 62.1 (2015): 527-538


<li><A HREF="https://arxiv.org/abs/1004.5049" target="_blank">
The Burbea-Rao and Bhattacharyya centroids</A>, IEEE Transactions on Information Theory, 57(8), 5455-5466 (2011)

<BR>
<center>
<IMG SRC="Visualizing Jensen Divergence and Jensen Diversity.gif" height="200">
</center><BR>



<li><A HREF="https://arxiv.org/abs/1004.5049" target="_blank">
Sided and Symmetrized Bregman Centroids</A>, IEEE transactions on Information Theory 55.6 (2009): 2882-2904
<A HREF="../CorrigendumAddendumSymmetrizedBregmanCentroid.pdf">Corrigendum and addendum on "Sided and Symmetrized Bregman Centroids"</A>

<li><A HREF="https://arxiv.org/abs/1403.2485" target="_blank">
Optimal Interval Clustering: Application to Bregman Clustering and Statistical Mixture Learning</A>, IEEE SPL 2014

<li><A HREF="https://www.researchgate.net/publication/258792133_Jeffreys_Centroids_A_Closed-Form_Expression_for_Positive_Histograms_and_a_Guaranteed_Tight_Approximation_for_Frequency_Histograms" target="_blank">
Jeffreys Centroids: A Closed-Form Expression for Positive Histograms and a Guaranteed 
Tight Approximation for Frequency Histograms
</A>, IEEE Signal Process. Lett. 20(7): 657-660 (2013)


<li><A HREF="https://www.mdpi.com/1099-4300/16/6/3273" target="_blank">
On Clustering Histograms with k-Means by Using Mixed α-Divergences</A>, Entropy 2014

</ul>

<h2 id="miscapp"><u>Miscellaneous applications</u></h2>

<ul>
<li><A HREF="https://proceedings.mlr.press/v161/masrani21a.html" target="_blank">
q-Paths: Generalizing the geometric annealing path using power means</A>, UAI 2021


<li><A HREF="https://www.researchgate.net/publication/258791961_An_Information-Geometric_Characterization_of_Chernoff_Information" target="_blank">
An Information-Geometric Characterization of Chernoff Information
</A>, IEEE SPL 2013

<li><A HREF="https://www.mdpi.com/1099-4300/20/3/203" target="_blank">
Computational Information Geometry for Binary Classification of High-Dimensional Random Tensors</A>,  Entropy 20(3): 203 (2018)


<li>
<A HREF="https://www.researchgate.net/publication/317722830_Information_geometry_metric_for_random_signal_detection_in_large_random_sensing_systems" target="_blank">
Information geometry metric for random signal detection in large random sensing systems
</A>,
ICASSP 2017: 4471-4475

<li><A HREF="https://www.researchgate.net/publication/262321274_Information-geometric_lenses_for_multiple_focicontexts_interfaces" target="_blank">
Information-geometric lenses for multiple foci+contexts interfaces</A>,
 SIGGRAPH ASIA Technical Briefs 2013: 18:1-18:4



</ul>

 

<h1 id="dissimilarity">Dissimilarities, distances, divergences and diversities</h1>

<h2 id="JSD"><u>Jensen-Shannon divergence</u></h2>

<ul>

<li><A HREF="https://www.mdpi.com/1099-4300/23/4/464" target="_blank">
On a Variational Definition for the Jensen-Shannon Symmetrization of Distances Based on the Information Radius</A>, Entropy 2021.


<li><A HREF="https://www.mdpi.com/1099-4300/22/2/221" target="_blank">
On a Generalization of the Jensen-Shannon Divergence and the Jensen–Shannon Centroid</A>, Entropy 2020

<li><A HREF="https://www.mdpi.com/1099-4300/21/5/485" target="_blank">
On the Jensen-Shannon Symmetrization of Distances Relying on Abstract Means</A>, Entropy 2019

<li><A HREF="https://www.researchgate.net/publication/46586313_A_family_of_statistical_symmetric_divergences_based_on_Jensen%27sinequality" target="_blank">
A family of statistical symmetric divergences based on Jensen's inequality</A>,
 2010. 


</ul>

<h2 id="fdiv"><u>f-divergences</u></h2>

<ul>
<li><A HREF="https://arxiv.org/abs/2101.12459" target="_blank">
On f-divergences between Cauchy distributions</A>

<li><A HREF="https://arxiv.org/abs/1309.3029" target="_blank">
On the Chi square and higher-order Chi distances for approximating f-divergences</A>

<li>α-divergences:
<ul>
<li><A HREF="https://arxiv.org/abs/2001.09660" target="_blank">
A generalization of the α-divergences based on comparable and distinct weighted means</A>

<li><A HREF="https://www.researchgate.net/publication/224246055_Non-flat_clustering_with_alpha-divergences" target="_blank">Non-flat clustering with alpha-divergences</A>,
ICASSP 2011: 2100-2103


</ul>
</ul>


<h2 id="BD"><u>Bregman divergences and some generalizations</u></h2>
  <ul>
<li><A HREF="https://www.researchgate.net/publication/353240484_Computing_Statistical_Divergences_with_Sigma_Points" target="_blank">
Computing Statistical Divergences with Sigma Points</A>, GSI 2021


<li><A HREF="https://www.researchgate.net/publication/352775033_Quasiconvex_Jensen_Divergences_and_Quasiconvex_Bregman_Divergences"
 target="_blank">
Quasiconvex Jensen Divergences and Quasiconvex Bregman Divergences</A>, SPIGL 2021

<li><A HREF="https://www.researchgate.net/publication/317352866_Generalizing_Skew_Jensen_Divergences_and_Bregman_Divergences_With_Comparative_Convexity"
 target="_blank">
Generalizing Skew Jensen Divergences and Bregman Divergences With Comparative Convexity</A>,  IEEE Signal Process. Lett. 24(8): 1123-1127 (2017)


<li><A HREF="https://www.researchgate.net/publication/221415886_Reranking_with_Contextual_Dissimilarity_Measures_from_Representational_Bregman_k-Means" target="_blank">
Reranking with Contextual Dissimilarity Measures from Representational Bregman k-Means</A>,
 VISAPP (1) 2010: 118-123

<li><A HREF="https://www.researchgate.net/publication/26820510_Bregman_Divergences_and_Surrogates_for_Learning" target="_blank">
Bregman Divergences and Surrogates for Learning</A>,
 IEEE Trans. Pattern Anal. Mach. Intell. 31(11): 2048-2059 (2009)

<li><A HREF="https://www.researchgate.net/publication/220939537_The_Dual_Voronoi_Diagrams_with_Respect_to_Representational_Bregman_Divergences" target="_blank">
The Dual Voronoi Diagrams with Respect to Representational Bregman Divergences</A>,
ISVD 2009: 71-78

</ul>
  
  <h2 id="JD"><u>Jensen divergences and some generalizations</u></h2>
  
  
  <ul>
<li><A HREF="https://www.researchgate.net/publication/325653707_The_Chord_Gap_Divergence_and_a_Generalization_of_the_Bhattacharyya_Distance" target="_blank">
  The Chord Gap Divergence and a Generalization of the Bhattacharyya Distance</A>, IEEE  ICASSP 2018
  
  <center>
  <IMG SRC="ChordGapDivergence.gif" width="200">
  </center>
  
  <li><A HREF="https://www.researchgate.net/publication/220110288_Skew_Jensen-Bregman_Voronoi_Diagrams" target="_blank">
  Skew Jensen-Bregman Voronoi Diagrams</A>,
  Trans. Comput. Sci. 14: 102-128 (2011)

<li><A HREF="https://www.researchgate.net/publication/220939617_Jensen-Bregman_Voronoi_Diagrams_and_Centroidal_Tessellations" target="_blank">
Jensen-Bregman Voronoi Diagrams and Centroidal Tessellations</A>,
 ISVD 2010: 56-65


  </ul>
  
  
<h2 id="confDiv">Conformal divergences</h2>
<ul>
<li><A HREF="https://arxiv.org/abs/1311.5125" target="_blank">
On conformal divergences and their population minimizers</A>, IEEE Transactions Information Theory, 62.1 (2015): 527-538

<li><A HREF="https://arxiv.org/abs/1309.7109" target="_blank">
Total Jensen divergences: Definition, Properties and k-Means++ Clustering</A>, IEEE ICASSP 2015

<li><A HREF="https://www.researchgate.net/publication/257205113_Total_Bregman_Divergence_and_its_Applications_to_Shape_Retrieval" target="_blank">
Total Bregman Divergence and its Applications to Shape Retrieval</A>, CVPR 2010

<li><A HREF="https://www.researchgate.net/publication/47449618_Total_Bregman_Divergence_and_Its_Applications_to_DTI_Analysis" target="_blank">
Total Bregman divergence and its applications to DTI analysis</A>, IEEE Transactions on Medical Imaging 30(2):475-83, 2011

<li><A HREF="https://www.researchgate.net/publication/221830074_Shape_Retrieval_Using_Hierarchical_Total_Bregman_Soft_Clustering" target="_blank">
Shape Retrieval Using Hierarchical Total Bregman Soft Clustering</A>,
IEEE Trans. Pattern Anal. Mach. Intell. 34(12): 2407-2419 (2012)


</ul>

<h2 id="projDiv"><u>Projective divergences</u></h2>
<ul>
<li><A HREF="https://www.mdpi.com/1099-4300/19/3/122" target="_blank">
On Hölder Projective Divergences</A>, Entropy 2017, 19(3), 122

<li><A HREF="https://www.researchgate.net/publication/312697428_Patch_Matching_with_Polynomial_Exponential_Families_and_Projective_Divergences" target="_blank">
Patch Matching with Polynomial Exponential Families and Projective Divergences</A>, SISAP 2016
(projective <b>gamma divergence</b>)

</ul>

<h2 id="OT"><u>Optimal transport/Wasserstein distances/Sinkhorn distances</u></h2>
Earth mover distances (EMD), Wasserstein distances

<ul>

<li><A HREF="https://www.researchgate.net/publication/328040454_Sinkhorn_AutoEncoders" target="_blank">
Sinkhorn AutoEncoders</A>, UAI 2019


<li><A HREF="https://arxiv.org/abs/1812.08113" target="_blank">
On The Chain Rule Optimal Transport Distance</A>


<li><A HREF="https://arxiv.org/abs/1609.04495" target="_blank">
Tsallis Regularized Optimal Transport and Ecological Inference</A>, AAAI 2017

<li><A HREF="https://www.researchgate.net/publication/350102151_Clustering_Patterns_Connecting_COVID-19_Dynamics_and_Human_Mobility_Using_Optimal_Transport
" target="_blank">
Clustering Patterns Connecting COVID-19 Dynamics and Human Mobility Using Optimal Transport</A>, March 2021, Sankhya B 83(S1)

<li><A HREF="https://arxiv.org/abs/1509.08144" target="_blank">
Optimal copula transport for clustering multivariate time series</A>

<li><A HREF="http://proceedings.mlr.press/v55/marti16.html" target="_blank">
Exploring and measuring non-linear correlations: Copulas, Lightspeed Transportation and Clustering</A>, 
Time Series Workshop at NeurIPS 2016

<li><A HREF="https://www.researchgate.net/publication/224200406_Earth_Mover_Distance_on_superpixels" target="_blank">
Earth Mover Distance on superpixels</A>, IEEE ICIP 2010

</ul>

<h2 id="entropy"><u>Shannon, Rényi, Tsallis, Sharmal-Mittal entropies, cross-entropies and divergences</u></h2>

<ul>

<li><A HREF="https://www.researchgate.net/publication/313541109_MaxEnt_Upper_Bounds_for_the_Differential_Entropy_of_Univariate_Continuous_Distributions" target="_blank">
MaxEnt Upper Bounds for the Differential Entropy of Univariate Continuous Distributions</A>,
 IEEE Signal Process. Lett. 24(4): 402-406 (2017)


<li><A HREF="https://arxiv.org/abs/1112.4221" target="_blank">
A closed-form expression for the Sharma-Mittal entropy of exponential families</A>,
Journal of Physics A: Mathematical and Theoretical 45.3 (2011).


<li><A HREF="https://arxiv.org/abs/1105.3259" target="_blank">
On Rényi and Tsallis entropies and divergences for exponential families</A>

<li><A HREF="https://www.researchgate.net/publication/221126408_Entropies_and_cross-entropies_of_exponential_families" target="_blank">
Entropies and cross-entropies of exponential families</A>, IEEE ICIP 2010
</li>

<li><A HREF="https://www.researchgate.net/publication/221304784_Texture_Regimes_for_Entropy-Based_Multiscale_Image_Analysis" target="_blank">
Texture Regimes for Entropy-Based Multiscale Image Analysis</A>, ECCV (3) 2010: 692-705



</ul>

<h2 id="Chernoff"><u>Chernoff information</u></h2>


<ul>

<li><A HREF="https://www.researchgate.net/publication/259804301_Generalized_Bhattacharyya_and_Chernoff_upper_bounds_on_Bayes_error_using_quasi-arithmetic_means" target="_blank">
Generalized Bhattacharyya and Chernoff upper bounds on Bayes error using quasi-arithmetic means
</A>, Pattern Recognition Letters 42(1), 2014


<li><A HREF="https://www.researchgate.net/publication/258791961_An_Information-Geometric_Characterization_of_Chernoff_Information" target="_blank">
An Information-Geometric Characterization of Chernoff Information
</A>, IEEE SPL 2013

<li><A HREF="https://www.researchgate.net/publication/268998068_Hypothesis_Testing_Information_Divergence_and_Computational_Geometry" target="_blank">
Hypothesis Testing, Information Divergence and Computational Geometry
</A>, GSI 2013

</ul>

<h2 id="miscDiv"><u>Other dissimilarities</u></h2>

<ul>

<li><A HREF="https://arxiv.org/abs/2003.13199" target="_blank">
A note on Onicescu's informational energy and correlation coefficient in exponential families
</A>

<li><A HREF="https://arxiv.org/abs/1709.00740" target="_blank">
Deep rank-based transposition-invariant distances on musical sequences
</A>

<li><A HREF="https://www.researchgate.net/publication/313074448_Quantifying_the_Invariance_and_Robustness_of_Permutation-Based_Indexing_Schemes" target="_blank">
Quantifying the Invariance and Robustness of Permutation-Based Indexing Schemes
</A>, SISAP 2016: 79-92


 </ul>
 
 
 
 <h2 id="lossScore"><u>Loss functions and proper scoring rules</u></h2>
 
<ul>
<li><A HREF="https://proceedings.mlr.press/v48/patrini16.html" target="_blank">
Loss factorization, weakly supervised learning and label noise robustness</a>, ICML 2016: 708-717



<li><A HREF="https://www.researchgate.net/publication/269846855_Gentle_Nearest_Neighbors_Boosting_over_Proper_Scoring_Rules" target="_blank">
Gentle Nearest Neighbors Boosting over Proper Scoring Rules</A>,
 IEEE Trans. Pattern Anal. Mach. Intell. 37(1): 80-93 (2015)



</ul> 



<h2 id="divStatMix"><u>Divergences between statistical mixtures</u></h2>
 
<ul>

<li><A HREF="https://www.mdpi.com/1099-4300/23/11/1417" target="_blank">
Fast Approximations of the Jeffreys Divergence between Univariate Gaussian Mixtures 
via Mixture Conversions to Exponential-Polynomial Distributions</A>, 
Entropy 2021, 23(11), 1417

<li><A HREF="https://arxiv.org/abs/1901.03732" target="_blank">
The Statistical Minkowski Distances: Closed-Form Formula for Gaussian Mixture Models</A>

<li><A HREF="https://arxiv.org/abs/1806.11311" target="_blank">
Guaranteed Deterministic Bounds on the total variation Distance between univariate mixtures</A>

<li><A HREF="https://www.researchgate.net/publication/304372111_Comix_Joint_estimation_and_lightspeed_comparison_of_mixture_models" target="_blank">
Comix: Joint estimation and lightspeed comparison of mixture models
</A>

<li><A HREF="Bag-of-Components: An Online Algorithm for Batch Learning of Mixture Models" target="_blank">
Bag-of-Components: An Online Algorithm for Batch Learning of Mixture Models</A>,
 GSI 2015


<li><A HREF="https://www.mdpi.com/1099-4300/18/12/442" target="_blank">
Guaranteed Bounds on Information-Theoretic Measures of Univariate Mixtures Using Piecewise Log-Sum-Exp Inequalities
</a>, Entropy 2016, 18(12), 442


<li><A HREF="https://www.researchgate.net/publication/317724631_Combinatorial_bounds_on_the_a-divergence_of_univariate_mixture_models" target="_blank">
Combinatorial bounds on the α-divergence of univariate mixture models</A>, ICASSP 2017

<li><A HREF="https://www.researchgate.net/publication/332141712_Closed-Form_Information-Theoretic_Divergences_for_Statistical_Mixtures" target="_blank">
Closed-form information-theoretic divergences for statistical mixtures</A>, ICPR 2012




</ul>






  
<hr>
<h1>Edited books and proceedings</h1>

 	<ul>
	
	<li><A HREF="https://www.elsevier.com/books/geometry-and-statistics/nielsen/978-0-323-91345-4" target="_blank">
Handbook of Geometry and Statistics</A>, Elsevier 2022
	
	
	<li>
	<A HREF="https://link.springer.com/book/10.1007/978-3-030-65459-7" target="_blank">
	Progress in Information Geometry: Theory and Applications
</A>, Springer 2021
  
  
  
   <li><A HREF="https://www.springer.com/us/book/9783030025199" target="_blank">Geometric Structures of Information</A>, Springer 2019
   <li><A HREF="https://www.springer.com/fr/book/9783319470566" target="_blank">Computational Information Geometry
For Image and Signal Processing</A>, Springer 2017
<li><A HREF="https://www.mdpi.com/journal/entropy/special_issues/entropy-statistics" target="_blank">Differential Geometrical Theory of Statistics</A>, MDPI Entropy, Special issue,  2017
   <li><A HREF="https://www.springer.com/la/book/9783319053165" target="_blank">Geometric Theory of Information</A>, Springer 2014
   <li><A HREF="https://www.springer.com/la/book/9783642302312" target="_blank">Matrix Information Geometry</A>, Springer 2013
   
  
 <li>Proceedings: <A HREF="https://www.springer.com/la/book/9783642008252" target="_blank">ETVC 2008</A>
  <A HREF="https://www.springer.com/la/book/9783642400193" target="_blank">GSI'13</A>
   <A HREF="https://www.springer.com/us/book/9783319250397" target="_blank">GSI'15</A>
    <A HREF="https://www.springer.com/jp/book/9783319684444" target="_blank">GSI'17</A>
  <A HREF="https://www.springer.com/jp/book/9783030269791" target="_blank">GSI'19</A>
  
   </ul>
<hr>
Home page of <A HREF="https://franknielsen.github.io/GSI/" target="_blank">Geometric Science of Information</A>
<hr>
January 2022.
    </body>
</html>

  