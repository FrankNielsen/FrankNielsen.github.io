% This is LLNCS.DEM the demonstration file of
% the LaTeX macro package from Springer-Verlag
% for Lecture Notes in Computer Science,
% version 2.4 for LaTeX2e as of 16. April 2010
%
\documentclass{llncs}
%
\usepackage{makeidx}  % allows for indexgeneration

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  Packages Stummer
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{mbboard}
\usepackage{calrsfs}
\usepackage{bbm}
\usepackage{yhmath}
\usepackage{harpoon}
\usepackage{mathabx}
\pagestyle{plain}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
%   settings   Stummer
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\olint}{{\overline{\int}}}
\newcommand{\olsum}{{\overline{\sum}}}
\newcommand{\wideint}{{\wideparen{\int}}}
\newtheorem{assumptionnew}[theorem]{Assumption}
\newtheorem{subsetup}[example]{Subsetup}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\arginf}{arginf}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argsup}{argsup}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
%   end of settings   Stummer
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{document}

%
%\mainmatter              % start of the contributions
%
\title{
Some Universal Insights on
Divergences for Statistics, Machine Learning and Artificial Intelligence
\\[-0.4cm]
}
%
\titlerunning{Some Subtleties}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%
\author{Michel Broniatowski \inst{1} \and Wolfgang Stummer \inst{2}}
%
\authorrunning{Broniatowski and Stummer} % abbreviated author list (for running head)
%
%%%% list of authors for the TOC (use if author list has to be modified)
\tocauthor{Broniatowski and Stummer}
%
\institute{
Sorbonne Universite Pierre et Marie Curie, LPSM,
4 place Jussieu, 75252 Paris, 
%Cedex 05, 
France. \email{michel.broniatowski@sorbonne-universite.fr}
\\[0.0cm]
\and
Department of Mathematics, University of Erlangen--N\"{u}rnberg,
Cauerstrasse $11$, 91058 Erlangen, Germany, 
%\\ 
as well as Affiliated Faculty Member of the School of Business and Economics,
University of Erlangen--N\"{u}rnberg,
Lange Gasse 20, 90403 N\"{u}rnberg, Germany. \ 
Corresponding Author.
\email{stummer@math.fau.de}
}


\maketitle              % typeset the title of the contribution

\allowdisplaybreaks

\vspace{-0.7cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%

\begin{abstract}
Dissimilarity quantifiers such as divergences (e.g. Kullback-Leibler information, relative entropy) 
and distances between \textit{probability distributions} 
are widely used in statistics, machine learning,
information theory and 
adjacent artificial intelligence. 
Within these fields, in contrast, some applications deal with
divergences between \textit{other-type} real-valued functions and vectors.
For a broad readership, we present a correspondingly unifying 
framework 
which -- by its nature as a ``structure on structures'' --
also qualifies as a basis for similarity-based 
multistage AI 
and more humanlike (robustly generalizing) machine learning.  
Furthermore, we discuss some 
specificalities, subtleties as well as pitfalls
when e.g. one ``moves away'' from the probability context.
Several subcases and examples are given,
including a new approach to 
obtain parameter estimators 
in continuous models which is based on noisy divergence minimization.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\vspace{-1.0cm}

\section{
Outline
}
\label{sec.1newa}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.3cm}

\enlargethispage{2.4cm}

The goals formulated in the abstract are achieved in the following
way and order: to address a wide audience,
throughout the paper 
(with a few connection-indicative exceptions) 
we 
entirely formulate and investigate divergences 
and  
distances between functions, 
even for the probability context. 
In Section \ref{sec.1newb}, we provide some 
non-technical background and overview of some of their principally 
possible usabilities   
for tasks in data analytics such as statistics, machine learning, and AI.
Furthermore, we indicate some connections with geometry and information. 
Thereafter, in Section \ref{sec.2new}
we introduce a new \textit{structured} framework 
(toolkit) of divergences between functions, and discuss
their building-blocks, boundary behaviour, as well as their identifiability properties.
Several subcases, running examples, technical subtleties of practical importance, etc. 
are illuminated, too. Finally, we study divergences between ``entirely different functions''
which e.g. appear in the frequent situation when for data-derived \textit{discrete} functions 
one wants to find a closest possible continuous-function model (cf. Section \ref{sec.4anew});
several corresponding noisy minimum-divergence procedures are compared 
-- for the first time within a unifying framework --
and new methods are derived too.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.3cm}

\section{Some general motivations and uses of divergences}
\label{sec.1newb}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.2cm}

\subsection{Quantification of proximity
}
\label{subsec.1newb.1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.2cm}

As a starting motivation, it is basic knowledge that there are 
numerous ways of 
evaluating 
the proximity $d(p,q)$ of two real numbers
$p$ and $q$ of primary  
interest. For instance, to quantify that $p$ and $q$ nearly coincide 
one could use the difference $d^{(1)}(p,q) := p-q \approx 0$ or 
the fraction $d^{(2)}(p,q) := \frac{p}{q} \approx 1$,
scaled (e.g. magnifying, zooming-in) versions $d_{m}^{(3)}(p,q) := m \cdot (p-q) \approx 0$
or $d_{m}^{(4)}(p,q) := m \cdot \frac{p}{q} \approx 1$
with ``scale'' $m$ of secondary (auxiliary) interest,
as well as flexibilizing hybrids $d_{m_{1},m_{2},m_{3}}^{(5)}(p,q) := m_{3} \cdot 
\big(\frac{p}{m_{1}} - \frac{q}{m_{2}}\big) \approx 0$
where $m_{i}$ may also take one of the values $p$,$q$.  
All these ``dissimilarities'' $d^{(j)}(\cdot,\cdot)$ can principally take any sign 
and they are asymmetric which is consistent
with the -- in many applications required -- desire that one of the two primary-interest numbers (say
$p$) plays a distinct role; moreover, the involved divisions cause technical care
if one principally allows for (convergence to) zero-valued numbers. 
A more sophisticated, nonlinear alternative to 
$d^{(1)}(\cdot,\cdot)$ is given by 
the dissimilarity $d_{\phi}^{(6)}(p,q) := \phi(p) - (\phi(q) + \phi^{\prime}(q) \cdot (p-q))$ 
where $\phi(\cdot)$ is a strictly convex, differentiable function
and thus $d_{\phi}^{(6)}(p,q)$ quantifies the difference between
$\phi(p)$ and the value at $p$ of the tangent line taken at $\phi(q)$.
Notice that $d_{\phi}^{(6)}(\cdot,\cdot)$ is generally still asymmetric but always stays nonnegative
independently of the possible signs of the ``generator'' $\phi$ and the signs of $p$,$q$.
In contrast, as a nonlinear alternative to $d_{m}^{(4)}(\cdot,\cdot)$
one can construct from 
$\phi$
the dissimilarity $d_{\phi}^{(7)}(p,q) := q \cdot \phi\big(\frac{p}{q}\big)$ (where $m=q$)
which is also asymmetric but can become negative depending on the signs of $p$, $q$, $\phi$. 
More generally,
one often wants to work with dissimilarities $d(\cdot,\cdot)$ having the properties
\begin{enumerate}

\item[(D1)] $d(p,q) \geq 0$ \quad for all $p$, $q$ \hspace{1.4cm} (nonnegativity),
\item[(D2)] $d(p,q) = 0$ \ if and only if \ $p=q$ \quad (reflexivity),

\end{enumerate}
and such $d(\cdot,\cdot)$ is then called a \textit{divergence}. Loosely speaking,  
the divergence $d(p,q)$ of $p$ and $q$ can be interpreted as a kind of ``directed distance
from $p$ to $q$''
\footnote{alternatively, one can think of
$d(p,q)$ as degree of proximity from $p$ to $q$
}. As already indicated above, the underlying directness turns out 
to be 
especially useful in contexts
where the first component (point), say $p$, is always/principally of ``more importance'' 
or of ``higher attention''
than the second component, say $q$; this is nothing unusual, since 
after all, one of our most fundamental 
daily-life
constituents -- namely time --
is directed (and therefore also time-dependent quantities)!
Moreover, as a further analogue consider the 
``way/path-length'' $d(p,q)$ 
a taxi would travel from point  
$p$ to point $q$
in parts of a city with 
at least one
one-way street. 
Along the latter, there automatically exist 
points $p \ne q$
such that $d(p,q) \ne d(q,p)$; this non-equality may even hold for all $p \ne q$
if the street pattern 
is irregular enough; 
the same holds on similar systems of connected
``one-way loops'', directed graphs, etc.
However, sometimes the application context demands for
the usage of
a dissimilarity $d(\cdot,\cdot)$ satisfying (D1), (D2) and
\begin{enumerate}
\item[(D3)] $d(p,q) = d(q,p)$ \quad for all $p$, $q$ \quad (symmetry),
\end{enumerate}
and such $d(\cdot,\cdot)$ is denoted as a \textit{distance};
notice that we don't assume that the triangle inequality holds. 
Hence, we regard a distance as a symmetric divergence.
Moreover,
a distance $d(\cdot,\cdot)$ can be 
constructed 
from a divergence $\widetilde{d}(\cdot,\cdot)$
e.g. by means of either the three ``symmetrizing operations'' 
$d(p,q) := \widetilde{d}(p,q) + \widetilde{d}(q,p)$,
$d(p,q) := \min \{\widetilde{d}(p,q), \widetilde{d}(q,p)\}$,
$d(p,q) := \max \{\widetilde{d}(p,q), \widetilde{d}(q,p)\}$
for all $p$ and $q$.

\vspace{0.2cm}
\noindent
In many real-life applications, the numbers $p$, $q$ of primary interest
as well as the scaling numbers $m_{i}$ of secondary interest 
are typically replaced by 
real-valued functions 
$x \rightarrow p(x)$, $x \rightarrow q(x)$, $x \rightarrow m_{i}(x)$, 
where $x \in \mathcal{X}$ is taken from some underlying set $\mathcal{X}$.
To address the entire functions as objects
we write 
abbreviatingly $P := \big\{p(x)\big\}_{x \in \mathcal{X}}$,
$Q := \big\{q(x)\big\}_{x \in \mathcal{X}}$,
$M_{i} := \big\{m_{i}(x)\big\}_{x \in \mathcal{X}}$,
and alternatively sometimes also $p(\cdot)$, $q(\cdot)$,
$m_{i}(\cdot)$.
This is conform
with the 
high-level data processing paradigms
in ``functional programming''
and ``symbolic computation'',
where functions are basically treated as
whole entities, too. 

\vspace{0.15cm}
\noindent
Depending on the nature of the 
data-analytical task, the function $P$ of primary interest
may stem either from a hypothetical model, 
or its analogue derived from observed/measured data,
or its analogue derived from artificial computer-generated (simulated) data;
the same holds for $Q$ where ``cross-over constellations'' (w.r.t. to the origin of $P$)
are possible.

\enlargethispage{0.8cm}

\vspace{0.15cm}
\noindent
The basic underlying set (space) $\mathcal{X}$
respectively the function argument $x$ can play
different roles, depending on the application context.
For instance, if $\mathcal{X} \subset \mathbb{N}$ is a subset
of the integers $\mathbb{N}$ then $x \in \mathcal{X}$ 
may be an index and $p(x)$ may describe the $x-$th
real-valued data-point. Accordingly, $P$ is then a $s-$dimensional
vector where $s$ is the total number of elements in $\mathcal{X}$
with eventually allowing for $s=\infty$. In other
situations, $x$ itself may be a data point of
arbitrary nature (i.e. $\mathcal{X}$ can be any set)
and $p(x)$ a real value attributed to $x$;
this $p(x)$ may be of direct or of
indirect use. The latter holds for instance in
cases where $p(\cdot)$ is a density function (on $\mathcal{X}$)
which roughly serves as a ``basis'' for the operationalized
calculation of the ``local aggregations over all
\footnote{measurable}
$A \subset \mathcal{X}$'' 
in the sense of 
$A \rightarrow \sum_{x \in A} p(x)$
or $A \rightarrow  \int_{A} p(x) \, \mathrm{d}\widetilde{\lambda}(x)$
subject to some ``integrator'' 
$\widetilde{\lambda}(\cdot)$ (including classical Riemann integrals 
$\mathrm{d}\widetilde{\lambda}(x) = \mathrm{d}x$);
as examples for nonnegative densities $p(\cdot) \geq 0$
one can take ``classical'' (volumetric, weights-concerning) 
inertial-mass densities,
population densities, probability densities, 
whereas 
densities $p(\cdot) $ with possible negative values can occur
in electromagnetism
(charge densities, polarization densities), 
in other fields of contemporary physics 
(negative inertial-mass respectively gravitational-mass densities)
as well as in the field of acoustic metamaterials (effective density),
to name but a few.

\vspace{0.15cm}
\noindent
Especially when used as a set of possible states/data configurations 
(rather than indices), 
$\mathcal{X}$ can be of arbitrary complexity.
For instance, each $x$ itself may be a real-valued continuous function on a time 
interval $[0,T]$ (i.e. $x:[0,T] \rightarrow ]-\infty, \infty[$)
which describes the scenario of the overall time-evolution of a 
quantity of interest (e.g. of a time-varying quantity 
in an deterministic production process of one machine, 
of the return on a stock, of a neural spike train).
Accordingly, one can take e.g. $\mathcal{X} =C\big([0,T] , ]-\infty, \infty[\big)$
to be the set of all such continuous functions,
and e.g. $p(\cdot)$ a density thereupon (which 
is then a function on functions). Other kinds of
functional data analytics can be covered in an
analogous fashion.

\vspace{0.15cm}
\noindent
To proceed with the proximity-quantification of the primary-interest functions 
$P := \big\{p(x)\big\}_{x \in \mathcal{X}}$,
$Q := \big\{q(x)\big\}_{x \in \mathcal{X}}$, 
in accordance with the above-mentioned investigations one can deal with the pointwise 
dissimilarities/divergences\\
$d_{\phi}^{(j)}(p(x),q(x))$, 
$d_{m_{1}(x),m_{2}(x),m_{3}(x)}^{(5)}(p(x),q(x))$
for fixed $x \in \mathcal{X}$,
but in many contexts it is crucial to take
``summarizing''
dissimilarities/divergences\\  
$D_{\phi}^{(j)}(P,Q)
:=
\sum_{x \in \mathcal{X}} d_{\phi}^{(j)}(p(x),q(x)) \cdot \lambda(x)$ or 
$D_{\phi}^{(j)}(P,Q) := \int_{\mathcal{X}} d_{\phi}^{(j)}(p(x),q(x)) \, \mathrm{d}\lambda(x)$
subject to some weight-type ``summator''/``integrator'' 
$\lambda(\cdot)$ (including classical Riemann integrals);  
analogously, one can deal with\\
$D_{\phi, M_{1}, M_{2}, M_{3}}^{(5)}(P,Q)
:=
\sum_{x \in \mathcal{X}} d_{m_{1}(x),m_{2}(x),m_{3}(x)}^{(5)}(p(x),q(x)) \cdot \lambda(x)$
or \\
$D_{\phi, M_{1}, M_{2}, M_{3}}^{(5)}(P,Q) := \int_{\mathcal{X}} 
d_{m_{1}(x),m_{2}(x),m_{3}(x)}^{(5)}(p(x),q(x)) \, \mathrm{d}\lambda(x)$.
Notice that 
the requirements (D1), (D2) respectively (D3) carry 
pricipally over 
in a straightforward manner also to these pointwise and
aggregated dissimilarities between the functions (rather than real points),
and accordingly one calls them (pointwise/aggregated) divergences  
respectively distances, too.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.4cm}

\subsection{Divergences and geometry}
\label{subsec.1newb.2}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\enlargethispage{0.5cm}

\vspace{-0.1cm}

There are several ways how pointwise dissimilarities $d(\cdot, \cdot)$ 
respectively aggregated dissimilarities $D(\cdot, \cdot)$ between functions 
$P := \big\{p(x)\big\}_{x \in \mathcal{X}}$ and
$Q := \big\{q(x)\big\}_{x \in \mathcal{X}}$ can be connected
with geometric issues. To start with an ``all-encompassing view'', 
following the lines of e.g. Birkhoff~\cite{Bir:32}
and Millmann \& Parker~\cite{Mil:91},
one can build 
from 
any set $\mathcal{S}$, 
whose elements can be interpreted as ``points'',
together with a collection $\mathcal{L}$ of non-empty subsets
of $\mathcal{S}$, interpreted as ``lines'' (as a manifestation of a 
principle sort
of structural connectivity
between points), 
and an arbitrary \textit{distance} 
$\mathfrak{d}(\cdot,\cdot)$
on $\mathcal{S} \times \mathcal{S}$,
an axiomatic constructive framework of geometry which can be
of far-reaching nature; therein, $\mathfrak{d}(\cdot,\cdot)$ plays basically
the role of a marked ruler. Accordingly, each triplet $(\mathcal{S}, \mathcal{L},
\mathfrak{d}(\cdot,\cdot))$ forms a distinct ``quantitative geometric system'';
the most prominent classical case is certainly 
$\mathcal{S} = \mathbb{R}^2$ with $\mathcal{L}$
as the collection of all vertical and non-vertical lines, equipped 
with the Euclidean distance $\mathfrak{d}(\cdot,\cdot)$, 
hence generating the usual Euclidean geometry in the two-dimensional space.
In the case that $\mathfrak{d}(\cdot,\cdot)$ is only an \textit{asymmetric divergence}
but not a distance anymore, 
we propose that some of the outcoming geometric building blocks
have to be interpreted in a direction-based way
(e.g. the use of $\mathfrak{d}(\cdot,\cdot)$ as a marked directed ruler,
the construction of points of equal divergence from a center viewed as distorted directed spheres,
etc.). For $d(\cdot, \cdot)$ one takes $\mathcal{S} \subset \mathbb{R}$
whereas for $D(\cdot, \cdot)$ one has to work with $\mathcal{S}$
being a family of real-valued functions on $\mathcal{X}$.

Secondly, from any \textit{distance} $\mathfrak{d}(\cdot,\cdot)$ on a ``sufficiently rich''
set $\mathcal{S}$  
and a finite number of (fixed or adaptively flexible) distinct ``reference points''
$s_{i}$ ($i=1, \ldots, n$) one can construct the corresponding
Voronoi cells $V(s_i)$ by
\vspace{-0.23cm}
$$
V(s_i) := \{ z \in \mathcal{S} : \ \mathfrak{d}(z,s_i) \leq \mathfrak{d}(z,s_j) 
\ \textrm{for all $j=1, \ldots, n$} \, \} .
$$

\vspace{-0.23cm}
\noindent
This produces a tesselation (tiling) of $\mathcal{S}$ which is very useful
for classification purposes. Of course, the geometric shape of these tesselations
is of fundamental 
importance.
In the case that $\mathfrak{d}(\cdot,\cdot)$ is only an \textit{asymmetric divergence}
but not a distance anymore, then $V(s_i)$ has to be interpreted
as a directed Voronoi cell and then there is also the ``reversely directed'' alternative
\vspace{-0.23cm}
$$
\widetilde{V}(s_i) := \{ z \in \mathcal{S} : \ \mathfrak{d}(s_i,z) \leq \mathfrak{d}(s_j,z) 
\ \textrm{for all $j=1, \ldots, n$} \, \} .
$$ 

\vspace{-0.23cm}
\noindent  
Recent applications where $\mathcal{S} \subset \mathbb{R}^d$ and $\mathfrak{d}(\cdot,\cdot)$ is a Bregman divergence 
or a more general conformal divergence,
can be found e.g. in Boissonnat et. al~\cite{Boi:10},
Nock et al.~\cite{Noc:16b} (and the 
references therein),
where they also deal with the corresponding adaption of
k-nearest neighbour classification methods. 


\vspace{0.1cm}
\noindent
Thirdly, consider a ``specific framework'' where the functions $P:= \widetilde{P}_{\theta_{1}} := 
\big\{\widetilde{p}_{\theta_{1}}(x)\big\}_{x \in \mathcal{X}}$ and
$Q:= \widetilde{P}_{\theta_{2}} := \big\{\widetilde{p}_{\theta_{2}}(x)\big\}_{x \in \mathcal{X}}$
depend on some parameters $\theta_1 \in \Theta$,
 $\theta_2 \in \Theta$,
which reflect the strive for a complexity-reducing representation 
of ``otherwise intrinsically complicated'' functions $P$, $Q$.
The way of dependence of the function (say) $\widetilde{p}_{\theta}(\cdot)$ 
on the underlying parameter $\theta$ from an appropriate space $\Theta$ of e.g. manifold type,
may show up  
directly e.g. via its operation/functioning as a relevant system-indicator,
or it may be manifested implicitly e.g. such that $\widetilde{p}_{\theta}(\cdot)$ is the
solution of an optimization problem with $\theta-$involving constraints.
In such a framework,
one can induce divergences $D(\widetilde{P}_{\theta_{1}},\widetilde{P}_{\theta_{2}}) =: f(\theta_{1},\theta_{2})$
and -- under sufficiently smooth dependence --
study their corresponding differential-geometric behaviour of $f(\cdot,\cdot)$ on 
$\Theta$. 
An example is provided by the Kullback-Leibler divergence
between two distributions of the same exponential family of distributions,
which defines a Bregman divergence on the parameter space.
This and related issues are subsumed in the research field of 
``information geometry''; for comprehensive overviews
see e.g.
Amari~\cite{Ama:00}, Amari~\cite{Ama:16}, Ay et al.~\cite{Ay:17}.


\vspace{0.1cm}
\noindent 
Further relations of divergences with other approaches to geometry 
can be over\-viewed e.g. from
the wide-range-covering research-article collections in 
Nielsen \& Bhatia~\cite{Nie:13b}, 
Nielsen \& Barbaresco~\cite{Nie:13a},~\cite{Nie:15a}~\cite{Nie:17a}.
Finally, geometry also enters as a tool for visualizing
quantitative effects on divergences.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.5cm}

\subsection{Divergences
and uncertainty in data}
\label{subsec.1newb.3}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\enlargethispage{0.5cm}

\vspace{-0.1cm}

In general, data-uncertainty 
(including ``deficiencies'' like data incompleteness, 
fakery, unreliability, faultiness, vagueness, etc.)
can enter the framework in various  
different ways. For instance, in situations where  
$x \in \mathcal{X}$ plays the role of an index (e.g. $\mathcal{X} = \{1, 2, \ldots, s\}$) 
and $p(x)$ describes the $x-$th real-valued data-point,
the uncertainty is typically
\footnote{in a probabilistic approach rather than a chaos-theoretic approach}
incorporated by adding a random
argument $\omega \in \Omega$ to end up with the 
``vectors''
$P(\omega) := \big\{p(x,\omega)\big\}_{x \in \mathcal{X}}$,
$Q(\omega) := \big\{q(x, \omega)\big\}_{x \in \mathcal{X}}$
of random data points. 
Accordingly, one ends up with random-variable-type
pointwise
divergences
$\omega \rightarrow d_{\phi}^{(j)}(p(x,\omega),q(x,\omega)), \  
\omega \rightarrow d_{m_{1}(x),m_{2}(x),m_{3}(x)}^{(5)}(p(x,\omega),q(x,\omega))$\ 
($x \in \mathcal{X}$)
as well as with the random-variable-type
``summarizing''
divergences\\
$\omega \rightarrow D_{\phi}^{(j)}(P(\omega),Q(\omega))
:=
\sum_{x \in \mathcal{X}} d_{\phi}^{(j)}(p(x,\omega),q(x,\omega)) \cdot \lambda(x)$ respectively\\
$\omega \rightarrow D_{\phi}^{(j)}(P(\omega),Q(\omega)) := 
\int_{\mathcal{X}} d_{\phi}^{(j)}(p(x,\omega),q(x,\omega)) \, \mathrm{d}\lambda(x)$,
as well as with\\
$\omega \rightarrow D_{\phi, M_{1}, M_{2}, M_{3}}^{(5)}(P(\omega),Q(\omega))
:=
\sum_{x \in \mathcal{X}} { d_{m_{1}(x),m_{2}(x),m_{3}(x)}^{(5)}(p(x,\omega),q(x,\omega)) \cdot \lambda(x) }$,\\
resp.\
$\omega \rightarrow D_{\phi, M_{1}, M_{2}, M_{3}}^{(5)}(P(\omega),Q(\omega)) := \int_{\mathcal{X}} 
d_{m_{1}(x),m_{2}(x),m_{3}(x)}^{(5)}(p(x,\omega),q(x,\omega)) \, \mathrm{d}\lambda(x)$.
More generally, one can allow for random scales $m_{1}(x,\omega)$, $m_{2}(x,\omega)$, $m_{3}(x,\omega)$.

\vspace{0.15cm}
\noindent
In other
situations with finitely-many-elements carrying $\mathcal{X}$,
the state $x$ may e.g. describe a possible outcome $Y(\omega)$
of an uncertainty-prone observation 
of a quantity $Y$ of interest and $p(x)$, $q(x)$ represent the corresponding 
probability mass functions (``discrete density functions'')
at $x$ under two alternative probability mechanisms $Pr$, $\widetilde{Pr}$ 
(i.e. $p(x) = Pr[\{\omega \in \Omega: Y(\omega)=x\}]$,
$q(x) = \widetilde{Pr}[\{\omega \in \Omega: Y(\omega)=x\}]$);
as already indicated above, $P := \big\{p(x)\big\}_{x \in \mathcal{X}}$ respectively
$Q := \big\{q(x)\big\}_{x \in \mathcal{X}}$ serve then as a kind of  
``basis'' for the computation of the probabilities 
$\sum_{x \in A} p(x)$ respectively
$\sum_{x \in A} q(x)$
that an arbitrary event $\{\omega \in \Omega: Y(\omega) \in A \}$ 
($A \subset \mathcal{X}$) occurs.
Accordingly, the pointwise divergences 
$d_{\phi}^{(j)}(p(x),q(x))$, 
$d_{m_{1}(x),m_{2}(x),m_{3}(x)}^{(5)}(p(x),q(x))$
($x \in \mathcal{X}$), 
and the aggregated divergences  
$D_{\phi}^{(j)}(P,Q)
:=
\sum_{x \in \mathcal{X}} d_{\phi}^{(j)}(p(x),q(x))$,
$D_{\phi, M_{1}, M_{2}, M_{3}}^{(5)}(P,Q)
:=
\sum_{x \in \mathcal{X}} d_{m_{1}(x),m_{2}(x),m_{3}(x)}^{(5)}(p(x),q(x))$,
$D_{\phi, M_{1}, M_{2}, M_{3}}^{(5)}(P,Q) := \int_{\mathcal{X}} 
d_{m_{1}(x),m_{2}(x),m_{3}(x)}^{(5)}(p(x),q(x)) \, \mathrm{d}\lambda(x)$
can then be regarded as (nonnegative, reflexive) 
dissimilarities between the two alternative  
uncertainty-quantification-bases $P$ and $Q$.
Analogously, when e.g. $\mathcal{X}= \mathbb{R}^n$ is the $n-$dimensional Euclidean
space and $P$, $Q$ are classical probability density functions
interpreted roughly via 
$p(x) \mathrm{d}x = Pr[\{\omega \in \Omega: Y(\omega) \in [x,x + \mathrm{d}x[ \}$,
$q(x) \mathrm{d}x = \widetilde{Pr}[\{\omega \in \Omega: Y(\omega) \in [x,x + \mathrm{d}x[ \}$,
then $d_{\phi}^{(j)}(p(x),q(x))$, 
$d_{m_{1}(x),m_{2}(x),m_{3}(x)}^{(5)}(p(x),q(x))$
($x \in \mathcal{X}$),  
$D_{\phi}^{(j)}(P,Q) := \int_{\mathcal{X}} d_{\phi}^{(j)}(p(x),q(x)) \, \mathrm{d}x$,\\
$D_{\phi, M_{1}, M_{2}, M_{3}}^{(5)}(P,Q) := \int_{\mathcal{X}} 
d_{m_{1}(x),m_{2}(x),m_{3}(x)}^{(5)}(p(x),q(x)) \, \mathrm{d}x$
serve as dissimilarities between the two alternative
uncertainty-quantification-bases $P$, $Q$.

\vspace{0.15cm}
Let us finally mention that in concrete applications, 
the ``degree'' of intrinsic data-uncertainty may be zero (deterministic),
low (e.g. small random data contamination and small random deviations from 
a ``basically'' deterministic system, slightly noisy data, measurement errors)
or high (forecast of the price of a stock in one year from now).
Furthermore, the data may contain ``high unusualnesses'' 
(``surprising observations'') 
such as outliers and inliers.
All this should be taken into account when choosing or even designing the
right type of divergence which have different sensitivity to such issues
(see e.g. Ki{\ss}linger \& Stummer~\cite{Kis:16}
and the references therein).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.4cm}

\subsection{Divergences, information and model uncertainty}
\label{subsec.1newb.4}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\enlargethispage{0.5cm}

\vspace{-0.1cm}

In the main spirit of this book on geometric structures of
information, let us also connect the latter with dissimilarities
in a wide sense which is appropriate enough for our ambitions of universal modeling.
In correspondingly adapting some conception e.g. of Buckland~\cite{Buc:91}
to our above-mentioned investigations,
in the following we regard a density function (say) $p(\cdot)$
as a fundamental basis of information
understood as 
quantified real -- respectively hypothetical -- 
knowledge which can be communicated 
about
some particular 
(family of) subjects or (family of) events;
according to this information-as-knowledge point of view, 
pointwise dissimilarities/divergences/distances 
$d(p(x),q(x))$ ($x \in \mathcal{X}$)
respectively aggregated dissimilarities/divergences/distances $D(P,Q)$
quantify the proximity 
between the two information-bases $P := \big\{p(x)\big\}_{x \in \mathcal{X}}$
and $Q := \big\{q(x)\big\}_{x \in \mathcal{X}}$
in a directed/nonnegative directed/nonnegative symmetric way.
Hence, $d(\cdot,\cdot)$ respectively $D(\cdot,\cdot)$ themselves can be seen as 
a higher-level information
on pairs of information bases.

\vspace{0.2cm}
\noindent
Divergences can be used for the quantification 
of information-concerning issues for model uncertainty (model risk)
and exploratory model search in various different ways.
For instance, suppose that 
we search for (respectively learn to understand) a true unknown density function 
$Q^{true} := \big\{q^{true}(x)\big\}_{x \in \mathcal{X}}$
of an underlying 
data-generating mechanism of interest, 
which is often supposed to be a member 
of a prefixed class $\mathcal{P}$ of 
``hypothetical model-candidate density functions'';
frequently, this task is
(e.g. for the sake of fast tractability) simplified to a
setup of finding the true unknown parameter $\theta=\theta_{0}$
-- and hence $Q^{true} = Q_{\theta_{0}}$ --
within a parametric family  
$\mathcal{P} := \{ Q_{\theta} \}_{\theta \in \Theta}$. 
Let us first consider the case where the data-generating mechanism of interest
$Q^{true}$ is purely deterministic  
and hence also all the candidates $Q \in \mathcal{P}$ are 
(taken to be) \textit{not} of probability-density-function type.
Although one has no intrinsic data-uncertainty, 
one faces another type of knowledge-lack called model-uncertainty. 
Then, one standard goal is to ``track down'' 
(respectively learn to understand) this true unknown $Q^{true}$ respectively $Q_{\theta_0}$
by collecting and purpose-appropriately postprocessing some
corresponding data observations.
Accordingly, one attempts to design
a density-function-construction rule (mechanism,algorithm) 
$data \rightarrow P^{data} := \big\{p^{data}(x)\big\}_{x \in \mathcal{X}}$
to produce data-derived information-basis-type replica of 
a ``comparable principal form'' as the anticipated $Q^{true}$.
This rule should theoretically guarantee that $P^{data}$
converges -- 
with reasonable 
``operational'' speed --
to $Q^{true}$ as the number 
$N^{data}$ of data
grows, which particularly implies that (say) $D(P^{data},Q^{true})$
for some prefixed aggregated 
divergence
$D(\cdot,\cdot)$ 
becomes close to zero ``fast enough''. On these grounds,
one reasonable strategy to 
down-narrow the true unknown data-generating mechanism
$Q^{true}$ 
is to take a prefixed class $\mathcal{P}^{hyp}$ 
of hypothetical density-function models  
and compute $infodeg:= \inf_{Q\in\mathcal{P}^{hyp}} D(P^{data},Q)$
which in the light of the previous discussions can be
interpreted as an ``unnormalized degree of informative evidence
of $Q^{true}$ being a member of $\mathcal{P}^{hyp}$'',
or from a reversed point of view, as an
``unnormalized degree of goodness of approximation (respectively fit) of
the data-derived density function $P^{data}$
through/by means of $\mathcal{P}^{hyp}$''. 
Within this current paradigm, if 
$infodeg$ is too large
(to be specified in a context-dependent, appropriately quantified sense 
by taking into account the size of $N^{data}$), 
then one has to repeat the same
procedure with a different class 
$\widetilde{\mathcal{P}^{hyp}}$;
on the other hand, if (and roughly only if) 
$infodeg$ is small enough 
then $\widehat{Q^{data}} := \arg\inf_{Q\in\mathcal{P}^{hyp}} D(P^{data},Q)$
(which may not be unique) is ``the most reasonable'' 
approximation. 
This procedure is repeated recursively 
as soon as 
new data points are observed.

\enlargethispage{0.5cm}

\vspace{0.1cm}
\noindent
In contrast to the last paragraph, let us
now cope with the case where the true unknown data-generating mechanism of interest
is prone to uncertainties (i.e. is random, noisy, risk-prone) 
and hence $Q^{true}$ as well as all the candidates $Q \in \mathcal{P}$
\textit{are} of probability-density-function type.  
Even more, the data-derived information-basis-type replica
$\omega \rightarrow data(\omega) \rightarrow P^{data(\omega)} := \big\{p^{data(\omega)}(x)\big\}_{x \in \mathcal{X}}$\\
of $Q^{true}$
is now a 
density-function-valued (!)
random variable; 
notice that in an above-mentioned ``full-scenario'' time-evolutionary context,
this becomes a density-function-on-functions-valued random variable.
Correspondingly, the above-mentioned procedure for the deterministic case
has to be adapted and the notions of convergence and
smallness have to be stochastified, which leads to the need 
of considerably more advanced techniques.


\vspace{0.1cm}
\noindent
Another field of applying divergences to a context 
of synchronous model and data uncertainty 
is Bayesian sequential updating.
In such a ``doubly uncertain'' framework, one deals with a parametric context
of probability density functions 
$Q^{true} = Q_{\theta_{0}}$,
$\mathcal{P} := \{ Q_{\theta} \}_{\theta \in \Theta}$
where the uncertain knowledge about the parameter $\theta$ (to be learnt) is operationalized
by replacing it with a random variable $\vartheta$ on $\Theta$.
Based on both (i) an initial prior distribution $Prior_1[\cdot] := Pr[\vartheta \in \cdot \, ]$ 
of $\vartheta$ (with probability density function pdf $\theta \rightarrow prior_1(\theta)$)
and (ii) observed data $data_1(\omega), \ldots ,data_{N^{data}}(\omega)$ of 
number $N^{data}$, a posterior distribution 
$Post_1[\cdot,\omega] := Pr[\vartheta \in \cdot \,  \Large |  \, data_1(\omega), \ldots ,data_{N^{data}}(\omega); \, prior[\cdot] \, ]$ 
of $\vartheta$ (with pdf $\theta \rightarrow post_1(\theta,\omega)$)
is determined with (amongst other things) the help of
the well-known Bayes formula. 
This procedure is repeated recursively with new incoming data input (block) 
$data_{N^{data}+1}$,
where the new prior distribution $Prior_2[\cdot,\omega] := Post_1[\cdot,\omega]$
is chosen as the old posterior 
and the new posterior distribution is 
$Post_2[\cdot,\omega] :=  Pr[\vartheta \in \cdot \,  \Large |  \, data_1, \ldots ,data_{N^{data}},data_{N^{data}+1}; \,
Prior_2[\cdot,\omega]\,  ]$ (with pdf $\theta \rightarrow post_2(\theta,\omega)$), etc.
The corresponding (say) aggregated 
divergence
$D(P(\omega),Q(\omega))$
between the probability-density-valued random variables
$\omega \rightarrow P(\omega) := \big\{prior_2(\theta,\omega)\big\}_{\theta \in \Theta}$,
and $\omega \rightarrow Q(\omega) := \big\{post_2(\theta,\omega)\big\}_{\theta \in \Theta}$
serves 
as ``degree of informativity of the new data-point
observation on the learning of the true unknown $\theta_{0}$''.

\enlargethispage{0.7cm}

\vspace{0.1cm}
\noindent
As another application in a ``doubly uncertain'' framework,
divergences $D(P,Q)$ appear also in a dichotomous Bayesian testing problem 
between the two alternative probability densities functions $P$ and $Q$,
where $D(P,Q)$ represents an appropriate average (over prior probabilities) of the corresponding
difference between the prior Bayes risk (prior minimal mean decision loss)
and the posterior Bayes risk (posterior minimal mean decision loss).
This, together with non-averaging versions and an interpretation 
of $D(P,Q)$ as a (weighted-average) statistical information measure 
in the sense of De Groot~\cite{DeG:62}
can be found e.g. in {\"O}sterreicher \& Vajda~\cite{Oes:93}; 
see also Stummer~\cite{Stu:99a}~\cite{Stu:01a}~\cite{Stu:04a}, 
Liese \& Vajda~\cite{Lie:06}, 
Reid \& Williamson~\cite{Rei:11}. 
In contrast of this employment of $D(P,Q)$ as 
quantifier of ``decision risk reduction'' respectively ``model risk reduction'' respectively ``information gain'',
a different use of divergences $D(P,Q)$ in a ``double uncertain''
general Bayesian context of dichotomous loss-dependent decisions 
between arbitrary probability density functions $P$ and $Q$
can be found in Stummer \& Vajda~\cite{Stu:07},
where they achieve $D_{\phi_{\alpha}}(P,Q)$ (for some 
power functions $\phi_{\alpha}$ cf.~\eqref{brostu2:fo.def.32}) 
as upper and lower bound of the Bayes risk (minimal mean decision loss) itself
and also give applications to decision making of time-continuous, non-stationary
financial stochastic processes. 

\vspace{0.1cm}
\noindent
Divergences can be also employed to detect
distributional changes in 
streams 
(respectively clouds) 
$(data_{j})_{j \in \tau}$
of uncertain (random, noisy, risk-prone) data indexed by $j$ from an arbitrary 
countable set $\tau$ (e.g. the integers, an undirected graph); a 
survey together with some general framework can be found
in Stummer \& Ki{\ss}linger~\cite{Kis:17b}: the basic idea is
to pick out two 
\footnote{
where one of them may e.g. stem from training data
}
non-identical, purpose-appropriately chosen 
subcollections respectively sample 
patterns (e.g. windows)\\ 
$data_{one}(\omega):= (data_{s_1}(\omega),\ldots, data_{s_{N_1}}(\omega))$,  
$data_{two}(\omega):= (data_{t_1}(\omega),\ldots, data_{t_{N_2}}(\omega))$,\\
and to build from them 
data-derived probability-density functions\\ 
$\omega \rightarrow data_{one}(\omega) \rightarrow P^{data_{one}(\omega)} := 
\big\{p^{data_{one}(\omega)}(x)\big\}_{x \in \mathcal{X}}$, \\
$\omega \rightarrow data_{two}(\omega) \rightarrow P^{data_{two}(\omega)} := 
\big\{p^{data_{two}(\omega)}(x)\big\}_{x \in \mathcal{X}}$.
If a correspondingly chosen (say) aggregated divergence 
$D\big(P^{data_{one}(\omega)} , P^{data_{two}(\omega)}\big)$
-- which plays the role of a condensed change-score -- 
is ``significantly large'' in the sense that it
is large enough
-- compared to some sound threshold 
which within the model reflects the 
desired ``degree of confidential 
plausibility'' --  
then there is strong indication of a distributional 
change 
which we then ``believe in''. 
Notice that now both components of the divergence $D(\cdot,\cdot)$
are now probability-density-function-valued random variables.
The sound threshold can e.g. be derived from advanced random asymptotic theory.

\vspace{0.2cm}
\noindent
From the above discussion it is clear that divergence-based model-uncertainty 
methods are useful tools in concrete applications for machine learning and artificial
intelligence, see e.g.  
Collins et al.~\cite{Col:02},
Murata et al.~\cite{Mur:04}, 
Banerjee et al.~\cite{Ban:05},
Tsuda et al.~\cite{Tsu:05},
Cesa-Bianchi \& Lugosi~\cite{Ces:06},
Nock \& Nielsen~\cite{Noc:09},
Sugiyama et al.~\cite{Sug:12},
Wu et al.~\cite{Wu:12}, 
Nock et al.~\cite{Noc:16a},
Nielsen et al.~\cite{Nie:17c},
respectively
Minka~\cite{Min:05}, Cooper et al.~\cite{Coo:14}, Lizier~\cite{Liz:14}, 
Zhang et al.~\cite{Zha:14}, Chhogyal~\cite{Chh:15},
Cliff et al.~\cite{Cli:16},~\cite{Cli:18}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.6cm}
%
\section{General framework}
\label{sec.2new}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\enlargethispage{0.7cm}

\vspace{-0.4cm}
\noindent
In the above Section \ref{sec.1newb}, we have motivated that for many different tasks within a
broad spectrum of situations, it is useful to employ divergences
as ``directed distances'',
including distances as their symmetric special case.
For the rest of the paper, we shall only deal with aggregated forms of
divergences, and thus drop the attribute ``aggregated'' from now on.
In the following, we present a fairly universal, flexible, multi-component system of 
divergences by
adapting and widening the concept of scaled Bregman divergences of Stummer~\cite{Stu:07} 
and Stummer \& Vajda~\cite{Stu:12} to the current context of arbitrary (measurable) functions.  
To begin with, let us assume that the modeled respectively observed 
(random) data take
values in a state space 
$\mathcal{X}$ 
(with at least two distinct values), 
equipped with
a system  $\mathcal{
F}$ of admissible events 
($\sigma-$algebra) and a $\sigma-$finite measure $\lambda$
(e.g. 
the Lebesgue measure, the counting measure, etc.).
Furthermore, we suppose that $x \rightarrow p(x) \in [-\infty,\infty]$ and 
$x \rightarrow q(x) \in [-\infty,\infty]$ are (correspondingly measurable) functions
on $\mathcal{X}$ which satisfy $p(x) \in ]-\infty,\infty[$, 
$q(x) \in ]-\infty,\infty[$ 
for $\lambda-$almost all (abbreviated as $\lambda-$a.a.) 
$x \in \mathcal{X}$
\footnote{
this means 
that there exists a  
$N \in \mathcal{F}$ 
with $\lambda[N]=0$ 
(where the empty set $N = \emptyset$ is allowed)
such that for all $x \in \mathcal{X}\backslash\{N\}$
 (say)  $p(x) \in ]-\infty,\infty[$ holds
}.
To address the entire functions as objects
we write $P := \big\{p(x)\big\}_{x \in \mathcal{X}}$,
$Q := \big\{q(x)\big\}_{x \in \mathcal{X}}$
and alternatively sometimes also $p(\cdot)$, $q(\cdot)$.
To better highlight
the very important special case of 
\textit{$\lambda-$probability density functions}
-- where $p(x) \geq 0$, $q(x) \geq 0$ for $\lambda-$a.a. $x \in \mathcal{X}$
and $\int_{\mathcal{X}} p(x) \,  \mathrm{d}\lambda(x) =1$,
$\int_{\mathcal{X}} q(x) \,  \mathrm{d}\lambda(x) =1$ --
we use the notation 
$\mathbbm{\overrightharp{P}}$,
$\mathbbm{\overrightharp{p}}$,
$\mathbbm{\overrightharp{Q}}$,
$\mathbbm{\overrightharp{q}}$
instead of $P$, $p$, $Q$, $q$ (where \overrightharp{$\cdots$} symbolizes a lying
$1$).
For instance, if $\lambda = \lambda_{L}$ is
the Lebesgue measure on the $s-$dimensional Euclidean space $\mathcal{X} = \mathbb{R}^{s}$, 
then $\mathbbm{\overrightharp{P}}$, $\mathbbm{\overrightharp{Q}}$ are ``classical'' (e.g. Gaussian) 
probability density functions.
In contrast, in the \textit{discrete setup} 
where the state space (i.e. the set of all possible data points)
$\mathcal{X} = \mathcal{X}_{\#}$ has countably many elements 
and 
$\lambda := \lambda_{\#}$ 
is the counting measure
(i.e., $\lambda_{\#}[\{x\}] =1$ for all $x \in \mathcal{X}_{\#}$),
then $\mathbbm{\overrightharp{P}}$, $\mathbbm{\overrightharp{Q}}$ are probability mass functions
and (say) $\mathbbm{\overrightharp{p}}(x)$ can be interpreted as probability that  
the data point $x$ is taken by the underlying random (uncertainty-prone)
mechanism. If $p(x) \geq 0$, $q(x) \geq 0$ for $\lambda-$a.a. $x \in \mathcal{X}$
(but not necessarily with the restrictions $\int_{\mathcal{X}} p(x) \,  \mathrm{d}\lambda(x) =1
=\int_{\mathcal{X}} q(x) \,  \mathrm{d}\lambda(x)$)
then we write 
$\mathbbm{P}$, $\mathbbm{Q}$, $\mathbbm{p}$, $\mathbbm{q}$
instead of $P$, $p$, $Q$, $q$.

\vspace{0.1cm}
\noindent
Back to generality, we quantify 
the dissimilarity between the two 
functions $P$,$Q$ in terms of divergences 
$D^{c}_{\beta}(P,Q)$ with $\beta = (\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda)$,  
defined by 

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm} \textstyle
0 \leq D^{c}_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q) 
\nonumber\\ 
& & \hspace{-0.2cm} \textstyle
: =
\int_{{\mathcal{X}}} 
\big[ \phi  \big( {
\frac{p(x)}{m_{1}(x)}}\big) -\phi  \big( {\frac{q(x)}{m_{2}(x)}}\big)  
- \phi_{+,c}^{\prime} 
\big( {\frac{q(x)}{m_{2}(x)}}\big) \cdot \big( \frac{p(x)}{m_{1}(x)}-\frac{q(x)}{m_{2}(x)}\big)  
\big] \cdot 
\mathbbm{m}_{3}(x) \, \mathrm{d}\lambda(x) \qquad \ \ 
\label{brostu2:fo.def.1}
\end{eqnarray}

\vspace{-0.1cm}

\noindent
(see Stummer~\cite{Stu:07}, Stummer \& Vajda~\cite{Stu:12} for the case $c=1$).
Here, we use:

\begin{itemize}

\vspace{-0.2cm}

\item[(I1)] 
(measurable) \textit{scaling functions}
$m_{1}: \mathcal{X} \rightarrow [-\infty, \infty]$
and $m_{2}: \mathcal{X} \rightarrow [-\infty, \infty]$
as well as a
nonnegative 
(measurable) \textit{aggregating function}
$\mathbbm{m}_{3}: \mathcal{X} \rightarrow [0,\infty]$
such that $m_{1}(x) \in ]-\infty, \infty[$, 
$m_{2}(x) \in ]-\infty, \infty[$,
$\mathbbm{m}_{3}(x) \in [0, \infty[$
for 
$\lambda-$a.a. 
$x \in \mathcal{X}$
\footnote{
as an example, let $\mathcal{X}= \mathbb{R}$, $\lambda = \lambda_{L}$
be the Lebesgue measure (and hence, except for rare cases, the integral turns 
into a Riemann integral)
and $\mathbbm{\overrightharp{m}}_{1}(x) := \frac{1}{2} \cdot x^{-1/2} \cdot \boldsymbol{1}_{[0,1]}(x) \geq 0$;
since $\int_{{\mathcal{X}}} \mathbbm{\overrightharp{m}}_{1}(x)  \, \mathrm{d}\lambda(x) =1$ this qualifies as a probability
density and thus is a possible candidate for $\mathbbm{\overrightharp{m}}_{1}(x)=\mathbbm{\overrightharp{q}}(x)
$ in Section 3.3.1.2 
below.  
}
. In accordance with the above notation, we 
use the symbols $M_{i} := \big\{m_{i}(x)\big\}_{x \in \mathcal{X}}$
respectively $m_{i}(\cdot)$ to refer to the entire functions,
and $\mathbbm{M_{i}}$, $\mathbbm{m_{i}}$ 
when they are nonnegative
as well as 
$\mathbbm{\overrightharp{M}}_{i}$,
$\mathbbm{\overrightharp{m}}_{i}$ 
when they manifest $\lambda-$probability density functions.
Furthermore, 
let us emphasize that we allow for / cover
adaptive situations
in the sense that all three functions $m_1(x)$, $m_{2}(x)$, $\mathbbm{m}_{3}(x)$
(evaluated at $x$)
may also depend on $p(x)$ and $q(x)$.

\enlargethispage{0.5cm}


\item[(I2)]
the so-called ``divergence-generator'' $\phi$ 
which is a continuous,
convex  (finite) function $\phi: E \rightarrow ]-\infty,\infty[$
on some appropriately chosen open interval $E = ]a,b[$
such that $[a,b]$ 
covers (at least) the union 
$\mathcal{R}\big(\frac{P}{M_{1}}\big) \cup \mathcal{R}\big(\frac{Q}{M_{2}}\big)$ of both ranges 
$\mathcal{R}\big(\frac{P}{M_{1}}\big)$ of 
$\big\{\frac{p(x)}{m_{1}(x)}\big\}_{x \in \mathcal{X}}$
and $\mathcal{R}\big(\frac{Q}{M_{2}}\big)$ of $\big\{\frac{q(x)}{m_{2}(x)}\big\}_{x \in \mathcal{X}}$;
for instance, $E=]0,1[$, $E=]0,\infty[$ or $E=]-\infty,\infty[$;
the class of all such functions will be
denoted by 
$\Phi(]a,b[)$.
Furthermore, we assume that $\phi$ is continuously extended 
to $\overline{\phi}: [a,b] \rightarrow [-\infty,\infty]$ by setting 
$\overline{\phi}(t) := \phi(t)$ for $t\in ]a,b[$ as well as  
$\overline{\phi}(a):= \lim_{t\downarrow a} \phi(t)$,
$\overline{\phi}(b):= \lim_{t\uparrow b} \phi(t)$
on the two boundary points $t=a$ and $t=b$. The latter two 
are the only points at which infinite values may appear.
Moreover, for any fixed $c \in [0,1]$
the (finite) function 
$\phi_{+,c}^{\prime}: ]a,b[ \rightarrow ]-\infty,\infty[$
is well-defined by
$\phi_{+,c}^{\prime}(t) := c \cdot \phi_{+}^{\prime}(t)
+ (1- c) \cdot \phi_{-}^{\prime}(t)$, 
where $\phi_{+}^{\prime}(t)$ denotes
the (always finite) right-hand derivative of $\phi$ at the point $t \in ]a,b[$
and $\phi_{-}^{\prime}(t)$ the (always finite) left-hand derivative of $\phi$ at $t \in ]a,b[$. 
If $\phi \in \Phi(]a,b[)$ is
also continuously differentiable -- which we denote by $\phi \in \Phi_{C_{1}}(]a,b[)$ --
then for all $c \in [0,1]$
one gets $\phi_{+,c}^{\prime}(t) = \phi^{\prime}(t)$ ($t \in ]a,b[$)
and in such a situation we always suppress the obsolete indices $c$, $+$ in the corresponding
 expressions.
We also employ the continuous continuation
$\overline{\phi_{+,c}^{\prime}}: [a,b] \rightarrow [-\infty,\infty]$
given by 
$\overline{\phi_{+,c}^{\prime}}(t) := \phi_{+,c}^{\prime}(t)$ ($t \in ]a,b[$), 
$\overline{\phi_{+,c}^{\prime}}(a) := \lim_{t\downarrow a} \phi_{+,c}^{\prime}(t)$, 
$\overline{\phi_{+,c}^{\prime}}(b) := \lim_{t\uparrow b} \phi_{+,c}^{\prime}(t)$.
To explain the precise meaning of \eqref{brostu2:fo.def.1}, we also make 
use of the (finite, nonnegative) 
function
$\psi_{\phi,c}: ]a,b[ \times ]a,b[ \rightarrow [0,\infty[$
given by
$\psi_{\phi,c}(s,t) := \phi(s) - \phi(t) - \phi_{+,c}^{\prime}(t) \cdot (s-t) \geq 0$
($s,t \in ]a,b[$). To extend this to a lower semi-continuous function
$\overline{\psi_{\phi,c}}: [a,b] \times [a,b] \rightarrow [0,\infty]$
we proceed as follows:
firstly, we set $\overline{\psi_{\phi,c}}(s,t) := \psi_{\phi,c}(s,t)$ for all $s,t \in ]a,b[$.
Moreover, since for fixed $t \in ]a,b[$, the function $s \rightarrow \psi_{\phi,c}(s,t)$
is convex and continuous, the limit 
$\overline{\psi_{\phi,c}}(a,t) := \lim_{s \rightarrow a} \psi_{\phi,c}(s,t)$
always exists and (in order to avoid 
overlines in \eqref{brostu2:fo.def.1}) will be 
interpreted/abbreviated as $\phi(a) - \phi(t) - \phi_{+,c}^{\prime}(t) \cdot (a-t)$.
Analogously, for fixed $t \in ]a,b[$ we set 
$\overline{\psi_{\phi,c}}(b,t) := \lim_{s \rightarrow b} \psi_{\phi,c}(s,t)$
with corresponding short-hand notation
$\phi(b) - \phi(t) - \phi_{+,c}^{\prime}(t) \cdot (b-t)$.
Furthermore, for fixed $s\in ]a,b[$ we interpret
$\phi(s) - \phi(a) - \phi_{+,c}^{\prime}(a) \cdot (s-a)$
as 

\vspace{-0.4cm}

\begin{eqnarray} 
& & \hspace{-0.2cm} \textstyle
\overline{\psi_{\phi,c}}(s,a) := \big\{
\phi(s) - \overline{\phi_{+,c}^{\prime}}(a) \cdot s
+ \lim_{t \rightarrow a} \Big(t \cdot \overline{\phi_{+,c}^{\prime}}(a) - \phi(t) \Big) 
\big\}
\cdot \boldsymbol{1}_{]-\infty,\infty[}\big(\overline{\phi_{+,c}^{\prime}}(a)\big)
\nonumber\\[-0.1cm] 
& & \hspace{1.6cm}  \textstyle
+ \ \infty \cdot \boldsymbol{1}_{\{-\infty\}}\big(\overline{\phi_{+,c}^{\prime}}(a)\big) \, ,
\nonumber 
\end{eqnarray}

\vspace{-0.2cm}

\noindent
where the involved limit always exists but may be infinite.
Analogously, for fixed $s\in ]a,b[$ we interpret
$\phi(s) - \phi(b) - \phi_{+,c}^{\prime}(b) \cdot (s-b)$
as 

\vspace{-0.4cm}

\begin{eqnarray} 
& & \hspace{-0.2cm} \textstyle
\overline{\psi_{\phi,c}}(s,b) := \big\{
\phi(s) - \overline{\phi_{+,c}^{\prime}}(b) \cdot s
+ \lim_{t \rightarrow b} \Big(t \cdot \overline{\phi_{+,c}^{\prime}}(b) - \phi(t) \Big)
\big\}
\cdot \boldsymbol{1}_{]-\infty,\infty[}\big(\overline{\phi_{+,c}^{\prime}}(b)
\big)
\nonumber\\[-0.1cm] 
& & \hspace{1.6cm} \textstyle
+ \ \infty \cdot \boldsymbol{1}_{\{+\infty\}}\big(\overline{\phi_{+,c}^{\prime}}(b)\big) \, ,
\nonumber 
\end{eqnarray}

\vspace{-0.2cm}

\noindent
where again the involved limit always exists but may be infinite.
Finally, we always set $\overline{\psi_{\phi,c}}(a,a):= 0$, $\overline{\psi_{\phi,c}}(b,b):=0$,
and $\overline{\psi_{\phi,c}}(a,b) := \lim_{s \rightarrow a} \overline{\psi_{\phi,c}}(s,b)$,
$\overline{\psi_{\phi,c}}(b,a) := \lim_{s \rightarrow b} \overline{\psi_{\phi,c}}(s,a)$.
Notice that $\overline{\psi_{\phi,c}}(\cdot,\cdot)$ is lower semi-continuous but 
not necessarily continuous.
Since ratios are ultimately involved, we also consistently take 
$\overline{\psi_{\phi,c}}\big(\frac{0}{0},\frac{0}{0}\big) := 0$.
Taking all this 
into account, 
we interpret $D^{c}_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q)$ as 
$\int_{{\mathcal{X}}} 
\overline{\psi_{\phi,c}}\big(\frac{p(x)}{m_{1}(x)},\frac{q(x)}{m_{2}(x)}\big)
\mathbbm{m}_{3}(x) \, \mathrm{d}\lambda(x)$
at first glance (see further investigations in Assumption \ref{brostu2:assu.class1}  below),
and use the (in lengthy examples) less clumsy notation $\olint_{{\mathcal{X}}} 
\psi_{\phi,c}\big(\frac{p(x)}{m_{1}(x)},\frac{q(x)}{m_{2}(x)}\big)
\mathbbm{m}_{3}(x) \, \mathrm{d}\lambda(x)$ as a shortcut for the
implicitly involved boundary behaviour. $\square$

\end{itemize}


\noindent
Notice that despite of the ``difference-structure'' in the integrand of \eqref{brostu2:fo.def.1},
the splitting of the integral into differences of several ``autonomous'' integrals may not always 
be feasible 
due to the possible appearance of differences between infinite integral values.
Furthermore, there is non-uniqueness in the construction \eqref{brostu2:fo.def.1}; 
for instance, 
one (formally) gets 
$D^{c}_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q)= 
D^{c}_{\tilde{\phi},M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q)$
for any 
$\tilde{\phi}(t):= \phi(t) + c_1 + c_2 \cdot t$ \ ($t \in E$)
with $c_1,c_2 \in \mathbb{R}$.
Moreover, there exist ``essentially different'' pairs 
$(\phi,m)$ and $(\breve{\phi},\breve{m})$
(where $\phi(t) - \breve{\phi}(t)$ is nonlinear in $t$) for which 
$D^{c}_{\phi,M,M,M,\lambda}(P,Q)= 
D^{c}_{\breve{\phi},\breve{m},\breve{m},\breve{m},\lambda}(P,Q)$
(see e.g.~\cite{Kis:16}).
Let us also mention that we could further generalize
\eqref{brostu2:fo.def.1} by  
adapting the divergence concept of Stummer \& Ki{\ss}linger~\cite{Stu:17a}
who also deal even with 
non-convex non-concave divergence generators $\phi$;
for the sake of brevity, this is omitted here. 

\vspace{0.1cm}
\noindent
Notice that by construction  
we obtain the following important
assertion:


\begin{theorem}
\label{brostu2:thm.1}
Let $\phi \in \Phi(]a,b[)$ and $c \in [0,1]$. Then 
there holds $D^{c}_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q) \geq 0$
with equality if
$\frac{p(x)}{m_1(x)}=\frac{q(x)}{m_2(x)}$
for $\lambda-$ almost all $x \in \mathcal{X}$.
Depending on the concrete situation,  
$D^{c}_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q)$ may take infinite value.
 
\end{theorem}

\noindent 
To get ``sharp identifiability'' (i.e. reflexivity) 
one needs further assumptions on $\phi \in \Phi(]a,b[)$, $c \in [0,1]$.
As a motivation, consider 
the case where $\mathbbm{m}_{3}(x) \equiv 1$ \\ 
and
$\phi \in \Phi(]a,b[)$ is affine linear on the whole interval $]a,b[$,
and hence its extension $\overline{\phi}$ is affine-linear on $[a,b]$.
Accordingly, one gets for the 
integrand-builder
$\overline{\psi_{\phi,c}}(s,t) \equiv 0$ 
and hence $D^{c}_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q) = 
\int_{{\mathcal{X}}} 
\overline{\psi_{\phi,c}}\big(\frac{p(x)}{m_{1}(x)},\frac{q(x)}{m_{2}(x)}\big)
\, \mathrm{d}\lambda(x)
= 0$
even in cases where $\frac{p(x)}{m_{1}(x)} \ne \frac{q(x)}{m_{2}(x)}$ 
for $\lambda-$a.a. $x \in \mathcal{X}$. 
In order to avoid such and similar phenomena, we use the following 
set of requirements:

\begin{assumptionnew}
\label{brostu2:assu.class1} 
Let $c \in [0,1]$, $\phi \in \Phi(]a,b[)$
and $\mathcal{R}\big(\frac{P}{M_{1}}\big) \cup \mathcal{R}\big(\frac{Q}{M_{2}}\big) \subset [a,b]$. 
The aggregation function is supposed to be of the form 
$\mathbbm{m}_{3}(x)= \mathbbm{w}_{3}\big(x,\frac{p(x)}{m_{1}(x)},\frac{q(x)}{m_{2}(x)} \big)$
for some (measur.) function $\mathbbm{w}_{3}: \mathcal{X} \times [a,b] \times [a,b] \rightarrow [0,\infty]$.
Moreover,
for all 
$s \in \mathcal{R}\big(\frac{P}{M_{1}}\big)$,   
all 
$t \in \mathcal{R}\big(\frac{Q}{M_{2}}\big)$
and $\lambda-$a.a. $x \in \mathcal{X}$, let the following conditions hold:
\begin{itemize}


\item[(a)] $\phi$ is strictly convex at $t$;

\item[(b)] if $\phi$ is differentiable at $t$ and $s \ne t$, then 
$\phi$ is not affine-linear on the interval $[\min(s,t),\max(s,t)]$
(i.e. between $t$ and $s$); 

\item[(c)] if $\phi$ is not differentiable at 
$t$, $s > t$ and 
$\phi$ is affine linear on $[t,s]$, then we 
exclude $c=1$ for the (``globally/universally chosen'') subderivative
$\phi_{+,c}^{\prime}(\cdot) = c \cdot \phi_{+}^{\prime}(\cdot)
+ (1- c) \cdot \phi_{-}^{\prime}(\cdot)$;

\item[(d)] if $\phi$ is not differentiable at 
 $t$, $s < t$ and 
$\phi$ is affine linear on $[s,t]$, then we exclude $c=0$ for $\phi_{+,c}^{\prime}(\cdot)$;

\item[(e)] $\mathbbm{w}_{3}(x,s,t) < \infty$;

\item[(f)] $\mathbbm{w}_{3}(x,s,t) >0$ if $s \ne t$;

\item[(g)] $\mathbbm{w}_{3}(x,a,a) \cdot \psi_{\phi,c}(a,a) :=0$ by convention
(even in cases where the function 
$\mathbbm{w}_{3}(x,\cdot,\cdot) \cdot \psi_{\phi,c}(\cdot,\cdot)$ is not continuous on the boundary point $(a,a)$);

\item[(h)] $\mathbbm{w}_{3}(x,b,b) \cdot \psi_{\phi,c}(b,b) :=0$ by convention
(even in cases where the function 
$\mathbbm{w}_{3}(x,\cdot,\cdot) \cdot \psi_{\phi,c}(\cdot,\cdot)$ is not continuous on the boundary point $(b,b)$);

\item[(i)] $\mathbbm{w}_{3}(x,a,t) \cdot \psi_{\phi,c}(a,t) >0$, 
where 
$\mathbbm{w}_{3}(x,a,t) \cdot \psi_{\phi,c}(a,t) := \lim_{s\rightarrow a} \mathbbm{w}_{3}(x,s,t) \cdot \psi_{\phi,c}(s,t)$ 
if this limit exists, and otherwise we set by convention 
$\mathbbm{w}_{3}(x,a,t) \cdot \psi_{\phi,c}(a,t) := 1$ (or any other strictly positive constant);

\item[(j)] $\mathbbm{w}_{3}(x,b,t) \cdot \psi_{\phi,c}(b,t) >0$, 
where 
$\mathbbm{w}_{3}(x,b,t) \cdot \psi_{\phi,c}(b,t)$ is 
analogous to (i);

\item[(k)] $\mathbbm{w}_{3}(x,s,a) \cdot \psi_{\phi,c}(s,a) >0$, 
where 
$\mathbbm{w}_{3}(x,s,a) \cdot \psi_{\phi,c}(s,a) := \lim_{t\rightarrow a} \mathbbm{w}_{3}(x,s,t) \cdot \psi_{\phi,c}(s,t)$ 
if this limit exists, and otherwise we set by convention 
$\mathbbm{w}_{3}(x,s,a) \cdot \psi_{\phi,c}(s,a) := 1$ (or any other strictly positive constant);

\item[($\ell$)] $\mathbbm{w}_{3}(x,s,b) \cdot \psi_{\phi,c}(s,b) >0$, 
where 
$\mathbbm{w}_{3}(x,s,b) \cdot \psi_{\phi,c}(s,b)$ is 
analogous to (k);

\item[(m)] $\mathbbm{w}_{3}(x,a,b) \cdot \psi_{\phi,c}(a,b) >0$, 
where 
$\mathbbm{w}_{3}(x,a,b) \cdot \psi_{\phi,c}(a,b) := \lim_{s\rightarrow a} \mathbbm{w}_{3}(x,s,b) \cdot \psi_{\phi,c}(s,b)$ 
if this limit exists, and otherwise we set by convention 
$\mathbbm{w}_{3}(x,a,b) \cdot \psi_{\phi,c}(a,b) := 1$ (or any other strictly positive constant);

\item[(n)] $\mathbbm{w}_{3}(x,b,a) \cdot \psi_{\phi,c}(b,a) >0$, 
where 
$\mathbbm{w}_{3}(x,b,a) \cdot \psi_{\phi,c}(b,a) := \lim_{s\rightarrow b} \mathbbm{w}_{3}(x,s,a) \cdot \psi_{\phi,c}(s,a)$ 
if this limit exists, and otherwise we set by convention 
$\mathbbm{w}_{3}(x,b,a) \cdot \psi_{\phi,c}(b,a) := 1$ (or any other strictly positive constant). $\square$

\end{itemize}

\end{assumptionnew}

\enlargethispage{0.5cm}

\noindent 
Under 
Assumption \ref{brostu2:assu.class1},
we always interpret the 
corresponding divergence 

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm} \textstyle
D^{c}_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q) := D^{c}_{\phi,m_{1},m_{2},\mathbbm{W}_{3},\lambda}(P,Q) := 
\nonumber\\ 
& & \hspace{-0.2cm} \textstyle
: =
\olint_{{\mathcal{X}}} 
\mathbbm{w}_{3}\big(x,\frac{p(x)}{m_{1}(x)},\frac{q(x)}{m_{2}(x)} \big) \cdot 
\big[ \phi  \big( {
\frac{p(x)}{m_{1}(x)}}\big) -\phi  \big( {\frac{q(x)}{m_{2}(x)}}\big)
\nonumber
- \phi_{+,c}^{\prime} 
\big( {\frac{q(x)}{m_{2}(x)}}\big) \cdot \big( \frac{p(x)}{m_{1}(x)}-\frac{q(x)}{m_{2}(x)}\big) 
\big] 
\, \mathrm{d}\lambda(x)
\nonumber 
\end{eqnarray}

\vspace{-0.1cm}

\noindent
as $\int_{{\mathcal{X}}} 
\overline{\mathbbm{w}_{3} \cdot \psi_{\phi,c}}\big(\frac{p(x)}{m_{1}(x)},\frac{q(x)}{m_{2}(x)}\big)
 \, \mathrm{d}\lambda(x)$, 
where $\overline{\mathbbm{w}_{3} \cdot \psi_{\phi,c}}(x,s,t)$ denotes the extension of
the function $]a,b[ \times ]a,b[ \ni (s,t) \rightarrow \mathbbm{w}_{3}(x,s,t) \cdot \psi_{\phi,c}(s,t)$
on $[a,b] \times [a,b]$ according to the conditions (g) to (n) above.


\begin{remark}
\label{brostu2:rem.40b}
(a) We could even work with a weaker assumption obtained
by replacing $s$ with  $\frac{p(x)}{m_{1}(x)}$
as well as $t$ with $\frac{q(x)}{m_{2}(x)}$
and by requiring that then the correspondingly plugged-in conditions (a) to (n) 
hold for $\lambda-$a.a. $x \in \mathcal{X}$.\\
(b) Notice that our above context subsumes aggregation functions
of the form $\mathbbm{m}_{3}(x) = \tilde{\mathbbm{w}_{3}}(x,p(x),q(x),m_{1}(x),m_{2}(x))$ 
with $\tilde{\mathbbm{w}_{3}}(x,z_1,z_2,z_3,z_4)$ having
appropriately imbeddable behaviour in its arguments $x,z_1,z_2,z_3,z_4$,
the outcoming ratios $\frac{z_1}{z_3}$, $\frac{z_2}{z_4}$ and possible
boundary values thereof. \quad $\square$
\end{remark}

\noindent
The following requirement is stronger than the 
``model-individual/dependent'' Assumption \ref{brostu2:assu.class1} 
but is more ``universally applicable''
(amongst \textit{all} models such that
$\mathcal{R}\big(\frac{P}{M_{1}}\big) \cup \mathcal{R}\big(\frac{Q}{M_{2}}\big) \subset [a,b]$,
take e.g. $E=]a,b[$ as  
$E=]0,\infty[$ or $E=]-\infty,\infty[$): 

\begin{assumptionnew}
\label{brostu2:assu.class2}
Let $c \in [0,1]$, $\phi \in \Phi(]a,b[)$ on some fixed $]a,b[ \, \in \, ]-\infty,+\infty[$ 
such that $]a,b[ \, \supset \mathcal{R}\big(\frac{P}{M_{1}}\big) \cup \mathcal{R}\big(\frac{Q}{M_{2}}\big)$. 
The aggregation function is of the form 
$\mathbbm{m}_{3}(x)= \mathbbm{w}_{3}\big(x,\frac{p(x)}{m_{1}(x)},\frac{q(x)}{m_{2}(x)} \big)$
for some (measurable) function $\mathbbm{w}_{3}: \mathcal{X} \times [a,b] \times [a,b] \rightarrow [0,\infty]$.
Furthermore, for all $s \in ]a,b[$, $t \in ]a,b[$ and $\lambda-$a.a. $x \in \mathcal{X}$, 
the conditions (a) to (n) of Assumption \ref{brostu2:assu.class1} hold. 
\end{assumptionnew}

\vspace{-0.1cm}

\noindent
Important
examples 
in connection with the Assumptions \ref{brostu2:assu.class1}, \ref{brostu2:assu.class2} will be given in 
Section \ref{subsec.2.2verynew} (for $\phi$) and
Section \ref{subsec.2.3verynew} (for $m_{1}$, $m_{2}$, $\mathbbm{w}_{3}$) below.
With these assumptions at hand, we obtain the following non-negativity 
and reflexivity assertions:

\vspace{-0.1cm}

\begin{theorem}
\label{brostu2:thm.2}
Let the Assumption \ref{brostu2:assu.class1} be satisfied.
Then there holds: \\
(1) $D^{c}_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q) \geq 0$.
Depending on the concrete situation,\\  
$D^{c}_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q)$ may take infinite value.\\[-0.7cm]
\begin{eqnarray} 
& & \hspace{-0.2cm}
(2) \  D^{c}_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q) = 0 \ \ 
\textrm{if and only if} \ \  
\frac{p(x)}{m_1(x)}=\frac{q(x)}{m_2(x)}
\ \textrm{for $\lambda-$a.a. $x \in \mathcal{X}$.} \qquad \ 
\nonumber 
\end{eqnarray} 
\end{theorem}

\vspace{-0.05cm}

\enlargethispage{0.7cm}

\noindent
Theorem \ref{brostu2:thm.2} says that
$D^{c}_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q)$ is indeed
a ``proper'' divergence
under the Assumption \ref{brostu2:assu.class1}.
Hence, the latter will be assumed for the rest of the paper,
unless stated otherwise: for instance, we shall sometimes
work with the stronger Assumption \ref{brostu2:assu.class2};
thus, for more comfortable reference, we state explicitly

\vspace{-0.0cm}

\begin{corollary}
\label{brostu2:coll.1}
Under the more universally applicable Assumption \ref{brostu2:assu.class2},
the Assertions (1) and (2) of Theorem \ref{brostu2:thm.2} hold.
\end{corollary}

\vspace{-0.0cm}

\noindent
\textbf{Proof of Theorem \ref{brostu2:thm.2}.} 
Assertion (1) and the ``if-part'' of (2)
follow immediately from Theorem \ref{brostu2:thm.1} which uses
less restrictive assumptions. In order to show the 
``only-if'' part of (2) (and the ``if-part'' of (2) in an alternative way), 
one can use the straightforwardly provable fact 
that the Assumption \ref{brostu2:assu.class1} implies 

\vspace{-0.5cm}
 
\begin{eqnarray} 
& & \hspace{-0.2cm} 
\overline{\mathbbm{w}_{3} \cdot \psi_{\phi,c}}(x,s,t) \ = \ 0 
\qquad 
\textrm{if and only if}
\qquad
s \ = \  t
\label{brostu2:fo.proof1}
\end{eqnarray}

\vspace{-0.15cm}

\noindent
for all $s \in \mathcal{R}\big(\frac{P}{M_{1}}\big)$,  
all $t \in \mathcal{R}\big(\frac{Q}{M_{2}}\big)$
and $\lambda-$a.a. $x \in \mathcal{X}$.
To proceed, assume that $D^{c}_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q) = 0$,
which by the non-negativity of $\overline{\mathbbm{w}_{3} \cdot \psi_{\phi,c}}(\cdot,\cdot)$
implies that 
$\overline{\mathbbm{w}_{3} \cdot \psi_{\phi,c}}\big(\frac{p(x)}{m_{1}(x)},\frac{q(x)}{m_{2}(x)}\big) = 0$
for $\lambda-$a.a. $x \in \mathcal{X}$.
From this and the ``only-if'' part of \eqref{brostu2:fo.proof1},
we obtain the identity $\frac{p(x)}{m_1(x)}=\frac{q(x)}{m_2(x)}
\ \textrm{for $\lambda-$a.a. $x \in \mathcal{X}$}$.
\ \  $\square$

\vspace{0.1cm}

Under some non-obvious additional constraints on the 
functions 
$P$, $Q$ it may be possible to show the Assertions (1),(2)
of Theorem \ref{brostu2:thm.2} by even dropping the purely generator-concerning 
Assumptions \ref{brostu2:assu.class1}(b) to (d);
see e.g.\ Subsection 3.3.1.2 below.
In the following, we discuss several important features and special cases 
of $\beta = (\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda)$
in a well-structured way. Let us start with the latter. 

\vspace{-0.4cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The reference measure $\lambda$}
\label{subsec.2.1verynew}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.2cm}

In \eqref{brostu2:fo.def.1}, 
$\lambda$ can be interpreted as a ``governer'' upon the 
\textit{principle}
aggregation structure,
whereas the ``aggregation function'' $\mathbbm{m}_{3}$ tunes
the \textit{fine} aggregation details.
For instance, if one chooses $\lambda = \lambda_{L}$ as
the Lebesgue measure on $\mathcal{X} \subset \mathbb{R}$, then the integral
in \eqref{brostu2:fo.def.1} turns out to be of Lebesgue-type and (with some rare exceptions)
consequently of Riemann-type. In contrast, in the \textit{discrete setup} 
where 
$\mathcal{X} := \mathcal{X}_{\#}$ has 
countably many elements and is equipped with the counting measure
$\lambda := \lambda_{\#} := \sum_{z \in \mathcal{X}_{\#}} \delta_{z}$ 
(where $\delta_{z}$ is Dirac's 
one-point 
distribution
$\delta_{z}[A] :=  \boldsymbol{1}_{A}(z)$, 
and thus $\lambda_{\#}[\{z\}] =1$ for all $z \in \mathcal{X}_{\#}$) 
then \eqref{brostu2:fo.def.1} simplifies to

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm} \textstyle
0 \leq D^{c}_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda_{\#}}(P,Q) 
\nonumber\\ 
& & \hspace{-0.2cm} \textstyle
: =
\olsum_{z \in \mathcal{X}} 
\Big[ \phi  \big( {
\frac{p(z)}{m_{1}(z)}}\big) -\phi  \big( {\frac{q(z)}{m_{2}(z)}}\big) 
- \phi_{+,c}^{\prime} 
\big( {\frac{q(z)}{m_{2}(z)}}\big) \cdot \big( \frac{p(z)}{m_{1}(z)}-\frac{q(z)}{m_{2}(z)}\big) 
\Big] \cdot
\mathbbm{m}_{3}(z) \, , \qquad \ \ 
\label{brostu2:fo.def.5}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
which we interpret as
$\sum_{{z \in \mathcal{X}}} 
\overline{\psi_{\phi,c}}\big(\frac{p(z)}{m_{1}(z)},\frac{q(z)}{m_{2}(z)}\big) \cdot
\mathbbm{m}_{3}(z)$
with the same conventions and limits as in paragraph right after \eqref{brostu2:fo.def.1};
if $\mathcal{X}_{\#} = \{z_{0}\}$ for arbitrary $z_{0} \in \widetilde{X}$, we obtain
the corresponding one-point divergence over any space $\widetilde{X}$.


\vspace{-0.4cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The divergence generator $\phi$}
\label{subsec.2.2verynew}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.2cm}

\enlargethispage{0.5cm}

We continue with the inspection of interesting special cases
of $\beta = (\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda)$
by dealing with 
the first component.
For this, let 
$\Phi_{C_1}(]a,b[)$ 
be the class of all functions 
$\phi \in \Phi_{0}(]a,b[)$ 
which are also continuously differentiable on $E = ]a,b[$.  
For divergence generator $\phi \in \Phi_{C_1}(]a,b[)$, the formula \eqref{brostu2:fo.def.1} becomes
(recall that we suppress the obsolete $c$ and subderivative index $+$)

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm} \textstyle
0 \leq D_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q) 
\nonumber\\ 
& & \hspace{-0.2cm} \textstyle
: =
\olint_{{\mathcal{X}}} 
\Big[ \phi  \big( {
\frac{p(x)}{m_{1}(x)}}\big) -\phi  \big( {\frac{q(x)}{m_{2}(x)}}\big)  
- \phi^{\prime} 
\big( {\frac{q(x)}{m_{2}(x)}}\big) \cdot \big( \frac{p(x)}{m_{1}(x)}-\frac{q(x)}{m_{2}(x)}\big) 
\Big] \cdot 
\mathbbm{m}_{3}(x) \, \mathrm{d}\lambda(x) \ , \qquad \ \ 
\label{brostu2:fo.def.10}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
whereas \eqref{brostu2:fo.def.5} turns into

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm} \textstyle
0 \leq D_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda_{\#}}(P,Q) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
: =
\olsum_{x \in \mathcal{X}}  
\Big[ \phi  \big( {
\frac{p(x)}{m_{1}(x)}}\big) -\phi  \big( {\frac{q(x)}{m_{2}(x)}}\big) 
- \phi^{\prime} 
\big( {\frac{q(x)}{m_{2}(x)}}\big) \cdot \big( \frac{p(x)}{m_{1}(x)}-\frac{q(x)}{m_{2}(x)}\big) 
\Big] \cdot
\mathbbm{m}_{3}(x) .
\nonumber 
\end{eqnarray}

\vspace{-0.2cm}

\noindent
Formally, by defining the integral functional 
$g_{\phi,\mathbbm{M}_{3},\lambda}(\xi) := \int_{\mathcal{X}} \phi(\xi(x)) \cdot \mathbbm{m}_{3}(x) \, \mathrm{d}\lambda(x)$
and plugging in e.g. 
$g_{\phi,\mathbbm{M}_{3},\lambda}  \big( {\frac{P}{M_{1}}}\big) 
= \int_{\mathcal{X}} \phi \big( {\frac{p(x)}{m_{1}(x)}}\big) 
\cdot \mathbbm{m}_{3}(x) \, \mathrm{d}\lambda(x)$,
the divergence in \eqref{brostu2:fo.def.10} can be interpreted as 

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm} \textstyle
0 \leq D_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
= g_{\phi,\mathbbm{M}_{3},\lambda}  \big( {\frac{P}{M_{1}}}\big)
- g_{\phi,\mathbbm{M}_{3},\lambda}  \big( {\frac{Q}{M_{2}}}\big)
- g_{\phi,\mathbbm{M}_{3},\lambda}^{\prime}   \big( {\frac{Q}{M_{2}}},
{\frac{P}{M_{1}}} - {\frac{Q}{M_{2}}}\big)
\label{brostu2:fo.def.17}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
where $g_{\phi,\mathbbm{M}_{3},\lambda}^{\prime}   \big( 
\eta, 
\, \cdot \, \big)$ denotes the corresponding directional derivate
at $\eta = \frac{Q}{M_{2}}$.
If one has a ``nonnegativity-setup'' (NN0) in the sense that
for all $x \in \mathcal{X}$ there holds
$\frac{p(x)}{m_{1}(x)} \geq 0$
and $\frac{q(x)}{m_{2}(x)}\geq 0$
(but not necessarily  $p(x) \geq 0$, $q(x) \geq 0$, $m_{1}(x) \geq 0$, $m_{2}(x) \geq 0$)
then one can take $a=0$, $b=\infty$, i.e. $E=]0,\infty[$, and employ 
for the strictly convex power functions

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
\tilde{\phi}(t): = 
\tilde{\phi}_{\alpha}(t) := \frac{t^\alpha-1}{\alpha(\alpha-1)} \ \in ]-\infty,\infty[ , 
\qquad t \in ]0,\infty[, \ \alpha \in \mathbb{R}\backslash\{0,1\} \ , 
\nonumber 
\\ 
& & \hspace{-0.2cm}   \textstyle 
\phi(t): = \phi_{\alpha}(t) := \tilde{\phi}_{\alpha}(t) - \tilde{\phi}_{\alpha}^{\prime}(1) \cdot (t-1) =
\frac{t^\alpha-1}{\alpha(\alpha-1)}-\frac{t-1}{\alpha-1} \ \in [0,\infty[ , 
\quad t \in ]0,\infty[, 
\nonumber \\
& & \hspace{9.2cm}
\ \alpha \in \mathbb{R}\backslash\{0,1\} \ ,
\label{brostu2:fo.def.32}
\end{eqnarray}

\vspace{-0.1cm}

\noindent
which  
satisfy (with the notations introduced in the paragraph right after 
\eqref{brostu2:fo.def.1}) 

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
\phi_{\alpha}(1)=0, \quad 
\phi_{\alpha}^{\prime}(t)=\frac{t^{\alpha-1}-1}{\alpha-1}, \quad
\phi_{\alpha}^{\prime}(1)=0, \quad
\phi_{\alpha}^{\prime \prime}(t)=t^{\alpha-2} >0, \quad t \in ]0,\infty[,
\label{brostu2:fo.def.33a} 
\\
& & \hspace{-0.2cm}   \textstyle
\phi_{\alpha}(0) := \lim_{t\downarrow 0}\phi_{\alpha}(t)= 
\frac{1}{\alpha} \cdot \boldsymbol{1}_{]0,1] \cup ]1,\infty[}(\alpha)
+ \infty \cdot \boldsymbol{1}_{]-\infty,0[}(\alpha), \quad
\phi_{\alpha}(\infty) := \lim_{t\uparrow \infty} \phi_{\alpha}(t)= \infty,
\nonumber \\
\label{brostu2:fo.def.33b} 
\\[-0.2cm]
& & \hspace{-0.2cm}   \textstyle
\phi_{\alpha}^{\prime}(0) := \lim_{t\downarrow 0}\phi_{\alpha}^{\prime}(t)=
\frac{1}{1-\alpha} \cdot \boldsymbol{1}_{]1,\infty[}(\alpha)
- \infty \cdot \boldsymbol{1}_{]-\infty,0[\cup]0,1[}(\alpha),
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\phi_{\alpha}^{\prime}(\infty) := \lim_{t\uparrow \infty}\phi_{\alpha}^{\prime}(t)=
\infty \cdot \boldsymbol{1}_{]1,\infty[}(\alpha)
+ \frac{1}{1-\alpha} \cdot \boldsymbol{1}_{]-\infty,0[\cup]0,1[}(\alpha) = 
\lim_{t\uparrow \infty}\frac{\phi_{\alpha}(t)}{t} ,
\label{brostu2:fo.def.33d}
\\ 
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{\alpha}}(s,t) = \frac{1}{\alpha \cdot (\alpha-1)} \cdot
\Big[ s^{\alpha} + (\alpha-1) \cdot t^{\alpha} - \alpha \cdot s \cdot t^{\alpha-1} \Big],
\quad s,t \in ]0,\infty[ ,
\label{brostu2:fo.def.33e}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{\alpha}}(0,t) = \frac{t^{\alpha}}{\alpha} \cdot \boldsymbol{1}_{]0,1[ \cup ]1,\infty[}(\alpha)
+ \infty \cdot \boldsymbol{1}_{]-\infty,0[}(\alpha), 
\quad t \in ]0,\infty[ ,
\label{brostu2:fo.def.33f}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{\alpha}}(\infty,t) = \infty, \quad t \in ]0,\infty[ ,
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\lim_{s\rightarrow \infty} \frac{1}{s} \cdot \psi_{\phi_{\alpha}}(s,1) = 
\frac{1}{1-\alpha} \cdot  \boldsymbol{1}_{ ]-\infty,0[ \cup ]0,1[}(\alpha)
+ \infty \cdot \boldsymbol{1}_{]1,\infty[}(\alpha),
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{\alpha}}(s,0) = \frac{s^{\alpha}}{\alpha \cdot (\alpha-1)} 
\cdot \boldsymbol{1}_{]1,\infty[}(\alpha) 
+ \infty \cdot \boldsymbol{1}_{]-\infty,0[ \cup ]0,1[}(\alpha), 
\quad s \in ]0,\infty[ ,
\label{brostu2:fo.def.33i}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{\alpha}}(s,\infty) = \frac{s^{\alpha}}{\alpha \cdot (\alpha-1)} 
\cdot \boldsymbol{1}_{]-\infty,0[}(\alpha) 
+ \infty \cdot \boldsymbol{1}_{]0,1[ \cup ]1,\infty[}(\alpha), 
\quad s \in ]0,\infty[ ,
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{\alpha}}(0,0) := 0 \ 
\textrm{(which does not coincide with 
$\lim_{t\rightarrow 0} \lim_{s\rightarrow 0} \psi_{\phi_{\alpha}}(s,t)$
for $\alpha<0$}
\nonumber
\\
& & \hspace{2.0cm}
\textrm{ and which does not coincide with 
$\lim_{s\rightarrow 0} \lim_{t\rightarrow 0} \psi_{\phi_{\alpha}}(s,t)$
for $\alpha>1$}),
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{\alpha}}(\infty,\infty) := 0 \ 
\textrm{(which does not coincide with 
$\lim_{t\rightarrow \infty} \lim_{s\rightarrow \infty} \psi_{\phi_{\alpha}}(s,t)$
for $\alpha \in \mathbb{R}\backslash\{0,1\}$}
\nonumber
\\
& & \hspace{0.6cm}
\textrm{ and which does not coincide with 
$\lim_{s\rightarrow \infty} \lim_{t\rightarrow \infty} \psi_{\phi_{\alpha}}(s,t)$
for $\alpha \in ]0,1[ \cup ]1,\infty[$}),
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{\alpha}}(0,\infty) := \lim_{s \rightarrow 0} \lim_{t \rightarrow \infty} \psi_{\phi_{\alpha}}(s,t)
= \infty 
\label{brostu2:fo.def.33o}
\\
& & \hspace{2.0cm}
\textrm{(which coincides with 
$\lim_{t\rightarrow \infty} \lim_{s\rightarrow 0} \psi_{\phi_{\alpha}}(s,t)$
for $\alpha \in \mathbb{R}\backslash\{0,1\}$}),
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{\alpha}}(\infty,0) := \lim_{s \rightarrow \infty} \lim_{t \rightarrow 0} \psi_{\phi_{\alpha}}(s,t)
= \infty 
\label{brostu2:fo.def.33q}
\\
& & \hspace{2.0cm}
\textrm{(which coincides with 
$\lim_{t\rightarrow 0} \lim_{s\rightarrow \infty} \psi_{\phi_{\alpha}}(s,t)$
for $\alpha \in \mathbb{R}\backslash\{0,1\}$}) .
\nonumber
\end{eqnarray}

\vspace{-0.2cm}

\enlargethispage{0.5cm}

\noindent
The perhaps most important special case is
 $\alpha=2$, for which \eqref{brostu2:fo.def.32} turns into

\vspace{-0.5cm}
 
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\phi_{2}(t) := \frac{(t-1)^2}{2},
\quad t \in ]0,\infty[ = E,  
\label{brostu2:fo.def.34a}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
having for $s,t \in ]0,\infty[$ 
the properties (cf. \eqref{brostu2:fo.def.33b} to \eqref{brostu2:fo.def.33q})
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
\phi_{2}(1)=0, \quad 
\phi_{2}^{\prime}(1)=0, \quad
\phi_{2}(0) 
= \frac{1}{2} , \quad
\phi_{2}(\infty) 
= \infty, \quad
\phi_{2}^{\prime}(0) 
= - \frac{1}{2} , \quad 
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\phi_{2}^{\prime}(\infty) 
= \infty  = 
\lim_{t\uparrow \infty}\frac{\phi_{2}(t)}{t} , 
\psi_{\phi_{2}}(s,t) = \frac{(s-t)^2}{2} , 
\label{brostu2:fo.def.99e}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{2}}(0,t) = \frac{t^{2}}{2} , \quad
\psi_{\phi_{2}}(\infty,t) = \infty , \quad
\lim_{s\rightarrow \infty} \frac{1}{s} \cdot \psi_{\phi_{2}}(s,1) = \infty ,
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{2}}(s,0) = \frac{s^{2}}{2} , \quad
\psi_{\phi_{2}}(s,\infty) = \infty , \quad
\psi_{\phi_{2}}(0,0) := 0 , 
\label{brostu2:fo.def.99k}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{2}}(\infty,\infty) := 0 , \quad
\psi_{\phi_{2}}(0,\infty) 
= \infty , \quad
\psi_{\phi_{2}}(\infty,0) 
= \infty .
\nonumber
\end{eqnarray}

\vspace{-0.2cm}


\noindent
Also notice that the divergence-generator $\phi_{2}$ of \eqref{brostu2:fo.def.34a} 
can be trivially extended to

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\bar{\phi}_{2}(t) := \frac{(t-1)^2}{2},
\quad t \in ]-\infty,\infty[ = \bar{E},  
\label{brostu2:fo.def.34b}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
which is useful in a general setup (GS) where
for all $x \in \mathcal{X}$ one has
$\frac{p(x)}{m_{1}(x)} \in [-\infty, \infty]$
and $\frac{q(x)}{m_{2}(x)} \in [-\infty, \infty]$.
Convex extensions to $]a, \infty[$ with $a \in ]-\infty,0[$
can be easily done by the shift $\bar{\phi}_{\alpha}(t) := \phi_{\alpha}(t-a)$. 


\vspace{0.15cm}
\noindent
Further examples of everywhere strictly convex differentiable divergence generators 
$\phi \in \Phi_{C_{1}}(]a,b[)$ for the ``nonnegativity-setup'' (NN0)
(i.e. $a=0$, $b=\infty$, $E=]0,\infty[$) 
can be obtained by taking the $\alpha-$limits

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
\tilde{\phi}_{1}(t) := \lim_{\alpha \rightarrow 1} \phi_{\alpha}(t) =
t \cdot \log t \ \in [- e^{-1},\infty[ , 
\qquad t \in ]0,\infty[,
\nonumber 
\\ 
& & \hspace{-0.2cm}   \textstyle 
\phi_{1}(t) := \lim_{\alpha \rightarrow 1} \phi_{\alpha}(t) =
\tilde{\phi}_{1}(t) - \tilde{\phi}_{1}^{\prime}(1) \cdot (t-1) =
t \cdot \log t + 1 - t \ \in [0, \infty[, 
\quad t \in ]0,\infty[,  
\nonumber \\
\label{brostu2:fo.def.120b} 
\\
& & \hspace{-0.2cm}   \textstyle
\tilde{\phi}_{0}(t) := \lim_{\alpha \rightarrow 0} \phi_{\alpha}(t) =
- \log t \ \in ]-\infty,\infty[ , 
\qquad t \in ]0,\infty[,
\nonumber 
\\ 
& & \hspace{-0.2cm}   \textstyle 
\phi_{0}(t) := \lim_{\alpha \rightarrow 0} \phi_{\alpha}(t) =
\tilde{\phi}_{0}(t) - \tilde{\phi}_{0}^{\prime}(1) \cdot (t-1) =
- \log t + t - 1 \ \in [0, \infty[, 
\quad t \in ]0,\infty[,  
\nonumber \\
\label{brostu2:fo.def.120d}
\end{eqnarray}

\vspace{-0.5cm}

\noindent
which satisfy 

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
\phi_{1}(1)=0, \quad 
\phi_{1}^{\prime}(t)=\log t, \quad
\phi_{1}^{\prime}(1)=0, \quad
\phi_{1}^{\prime \prime}(t)=t^{-1} >0, \quad t \in ]0,\infty[,
\nonumber
\label{brostu2:fo.def.125a} 
\\
& & \hspace{-0.2cm}   \textstyle
\phi_{1}(0) := \lim_{t\downarrow 0}\phi_{1}(t)= 1, \quad
\phi_{1}(\infty) := \lim_{t\uparrow \infty} \phi_{1}(t)= \infty,
\label{brostu2:fo.def.125b} 
\\
& & \hspace{-0.2cm}   \textstyle
\phi_{1}^{\prime}(0) := \lim_{t\downarrow 0}\phi_{1}^{\prime}(t)=
- \infty, \quad
\phi_{1}^{\prime}(\infty) := \lim_{t\uparrow \infty}\phi_{1}^{\prime}(t)=
+ \infty = 
\lim_{t\uparrow \infty}\frac{\phi_{1}(t)}{t} , \qquad \ \ 
\label{brostu2:fo.def.125d}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{1}}(s,t) = s \cdot \log\big(\frac{s}{t}\big) + t - s ,
\quad s,t \in ]0,\infty[ ,
\label{brostu2:fo.def.125e}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{1}}(0,t) = t, \quad
\psi_{\phi_{1}}(\infty,t) = \infty, 
\quad \lim_{s\rightarrow \infty} \frac{1}{s} \cdot \psi_{\phi_{1}}(s,1) = \infty ,
\quad t \in ]0,\infty[ ,
\label{brostu2:fo.def.125g}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{1}}(s,0) = \infty , \quad
\psi_{\phi_{1}}(s,\infty) = \infty ,
\quad s \in ]0,\infty[ ,
\label{brostu2:fo.def.125i}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{1}}(0,0) := 0 \ 
\textrm{(which coincides with 
$\lim_{t\rightarrow 0} \lim_{s\rightarrow 0} \psi_{\phi_{1}}(s,t)$}
\nonumber
\\
& & \hspace{2.0cm}
\textrm{but which does not coincide with 
$\lim_{s\rightarrow 0} \lim_{t\rightarrow 0} \psi_{\phi_{1}}(s,t) = \infty$}),
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{1}}(\infty,\infty) := 0 \ 
\textrm{(which does not coincide with 
}
\nonumber
\\ 
& & \hspace{2.4cm}
\lim_{t\rightarrow \infty} \lim_{s\rightarrow \infty} \psi_{\phi_{1}}(s,t)
= \lim_{s\rightarrow \infty} \lim_{t\rightarrow \infty} \psi_{\phi_{1}}(s,t) = \infty,
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{1}}(0,\infty) := \lim_{s \rightarrow 0} \lim_{t \rightarrow \infty} \psi_{\phi_{1}}(s,t)
= \infty 
\nonumber
\\
& & \hspace{2.0cm}
\textrm{(which coincides with 
$\lim_{t\rightarrow \infty} \lim_{s\rightarrow 0} \psi_{\phi_{1}}(s,t)$}),
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{1}}(\infty,0) := \lim_{s \rightarrow \infty} \lim_{t \rightarrow 0} \psi_{\phi_{1}}(s,t)
= \infty 
\nonumber
\\
& & \hspace{2.0cm}
\textrm{(which coincides with 
$\lim_{t\rightarrow 0} \lim_{s\rightarrow \infty} \psi_{\phi_{1}}(s,t)$}) ,
\nonumber
\end{eqnarray}

\vspace{-0.3cm}

\enlargethispage{0.5cm}

\noindent
as well as

\vspace{-0.4cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
\phi_{0}(1)=0, \quad 
\phi_{0}^{\prime}(t)=1 - \frac{1}{t}, \quad
\phi_{0}^{\prime}(1)=0, \quad
\phi_{0}^{\prime \prime}(t)=t^{-2} >0, \quad t \in ]0,\infty[, \qquad \ \ 
\label{brostu2:fo.def.127a} 
\\
& & \hspace{-0.2cm}   \textstyle
\phi_{0}(0) := \lim_{t\downarrow 0}\phi_{0}(t)= \infty, \quad
\phi_{0}(\infty) := \lim_{t\uparrow \infty} \phi_{0}(t)= \infty,
\label{brostu2:fo.def.127b} 
\\
& & \hspace{-0.2cm}   \textstyle
\phi_{0}^{\prime}(0) := \lim_{t\downarrow 0}\phi_{0}^{\prime}(t)=
- \infty, \quad
\phi_{0}^{\prime}(\infty) := \lim_{t\uparrow \infty}\phi_{0}^{\prime}(t)=
1 = 
\lim_{t\uparrow \infty}\frac{\phi_{0}(t)}{t} ,
\label{brostu2:fo.def.127d}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{0}}(s,t) = - \log\big(\frac{s}{t}\big) + \frac{s}{t} - 1 ,
\quad s,t \in ]0,\infty[ ,
\label{brostu2:fo.def.127e}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{0}}(0,t) = \infty, \quad
\psi_{\phi_{0}}(\infty,t) = \infty, 
\quad \lim_{s\rightarrow \infty} \frac{1}{s} \cdot \psi_{\phi_{0}}(s,1) = 1 ,
\quad t \in ]0,\infty[ ,
\label{brostu2:fo.def.127g}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{0}}(s,0) = \infty , \quad
\psi_{\phi_{0}}(s,\infty) = \infty ,
\quad s \in ]0,\infty[ ,
\label{brostu2:fo.def.127i}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{0}}(0,0) := 0 \ 
\textrm{(which does not coincide with }
\nonumber
\\
& & \hspace{2.0cm}
\lim_{t\rightarrow 0} \lim_{s\rightarrow 0} \psi_{\phi_{0}}(s,t) =
\lim_{s\rightarrow 0} \lim_{t\rightarrow 0} \psi_{\phi_{0}}(s,t) = \infty),
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{0}}(\infty,\infty) := 0 \ 
\textrm{(which does not coincide with 
}
\nonumber
\\
& & \hspace{2.4cm}
\lim_{t\rightarrow \infty} \lim_{s\rightarrow \infty} \psi_{\phi_{0}}(s,t)
= \lim_{s\rightarrow \infty} \lim_{t\rightarrow \infty} \psi_{\phi_{0}}(s,t) = \infty,
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{0}}(0,\infty) := \lim_{s \rightarrow 0} \lim_{t \rightarrow \infty} \psi_{\phi_{0}}(s,t)
= \infty 
\nonumber
\\
& & \hspace{2.0cm}
\textrm{(which coincides with 
$\lim_{t\rightarrow \infty} \lim_{s\rightarrow 0} \psi_{\phi_{0}}(s,t)$}),
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{0}}(\infty,0) := \lim_{s \rightarrow \infty} \lim_{t \rightarrow 0} \psi_{\phi_{0}}(s,t)
= \infty 
\nonumber
\\
& & \hspace{2.0cm}
\textrm{(which coincides with 
$\lim_{t\rightarrow 0} \lim_{s\rightarrow \infty} \psi_{\phi_{0}}(s,t)$}) .
\nonumber
\end{eqnarray}

\vspace{-0.2cm}

\noindent
An important, but (in our context) technically delicate, convex divergence generator 
is $\phi_{TV}(t):= |t-1|$ which is non-differentiable at $t=1$; the latter is
also the only point of strict convexity.
Further properties are for arbitrarily fixed $s,t \in ]0,\infty[$, $\alpha \in [0,1]$
(if not stated otherwise)

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
\phi_{TV}(1)=0, \quad \phi_{TV}(0) = 1, \quad \phi_{TV}(\infty) = \infty,
\label{brostu2:fo.def.68a0} 
\\
& & \hspace{-0.2cm}   \textstyle
\phi_{TV,+,c}^{\prime}(t)=
\boldsymbol{1}_{[1,\infty[}(t) + (2c-1) \cdot \boldsymbol{1}_{\{1\}}(t)
- \boldsymbol{1}_{]0,1[}(t),
\nonumber 
\\
& & \hspace{-0.2cm}   \textstyle
 \phi_{TV,+,1}^{\prime}(t)=
\boldsymbol{1}_{[1,\infty[}(t)
- \boldsymbol{1}_{]0,1[}(t),
\nonumber 
\\
& & \hspace{-0.2cm}   \textstyle
\phi_{TV,+,\frac{1}{2}}^{\prime}(t)=
\boldsymbol{1}_{]1,\infty[}(t)
- \boldsymbol{1}_{]0,1[}(t) = \textrm{sgn}(t-1) \cdot  \boldsymbol{1}_{]0,\infty[}(t) ,
\nonumber  
\\
& & \hspace{-0.2cm}   \textstyle
\phi_{TV,+,c}^{\prime}(1) = 2(c-1), \quad
 \quad \phi_{TV,+,1}^{\prime}(1) = 1, 
\quad \phi_{TV,+,\frac{1}{2}}^{\prime}(1) =0,
\label{brostu2:fo.def.68b} 
\\
& & \hspace{-0.2cm}   \textstyle
\phi_{TV,+,c}^{\prime}(0) = \lim_{t \rightarrow 0} \phi_{TV,+,c}^{\prime}(t) = -1,
\quad 
\phi_{TV,+,c}^{\prime}(\infty) = \lim_{t \rightarrow \infty} \phi_{TV,+,c}^{\prime}(t) = 1, 
\nonumber
\\ 
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{TV},c}(s,t) = 
\boldsymbol{1}_{]0,1[}(t) \cdot 2 (s-1) \cdot \boldsymbol{1}_{]1,\infty[}(s)
+ \boldsymbol{1}_{]1,\infty[}(t) \cdot 2 (1-s) \cdot \boldsymbol{1}_{]0,1]}(s)
\nonumber\\
& & \hspace{2.0cm}
+ \ \boldsymbol{1}_{\{1\}}(t) \cdot \Big[
2 (1-c) \cdot  (s-1) \cdot \boldsymbol{1}_{]1,\infty[}(s) +  2c \cdot (1-s) \cdot \boldsymbol{1}_{]0,1]}(s)
\Big],
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{TV},\frac{1}{2}}(s,1) = |s-1|,  
\label{brostu2:fo.def.68e2}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{TV},c}(0,t) = \lim_{s \rightarrow 0} \psi_{\phi_{TV},c}(s,t) 
= 2 \cdot \boldsymbol{1}_{]1,\infty[}(t) + 2c \cdot \boldsymbol{1}_{\{1\}}(t) ,
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{TV},c}(\infty,t) = \lim_{s \rightarrow \infty} \psi_{\phi_{TV},c}(s,t)
= \infty \cdot \boldsymbol{1}_{]0,1[}(t)
+ \ \infty \cdot \boldsymbol{1}_{\{1\}}(t) \cdot 
\boldsymbol{1}_{[0,1[}(c) ,
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\lim_{s\rightarrow \infty} \frac{1}{s} \cdot \psi_{\phi_{TV},c}(s,1) = 
2 (1-c),
\label{brostu2:fo.def.68h}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{TV},c}(s,0) = \lim_{t \rightarrow 0} \psi_{\phi_{TV},c}(s,t)
= 2(s-1) \cdot \boldsymbol{1}_{]1,\infty[}(s),
\nonumber 
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{TV},c}(s,\infty) = \lim_{t \rightarrow \infty} \psi_{\phi_{TV},c}(s,t)
= 2(1-s) \cdot \boldsymbol{1}_{]0,1]}(s),
\nonumber 
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{TV},c}(0,0) := 0 \ 
\textrm{(which coincides with both
$\lim_{t\rightarrow 0} \lim_{s\rightarrow 0} \psi_{\phi_{TV},c}(s,t)$
}
\nonumber
\\
& & \hspace{2.6cm}
\textrm{ and  
$\lim_{s\rightarrow 0} \lim_{t\rightarrow 0} \psi_{\phi_{TV},c}(s,t)$
}),
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{TV},c}(\infty,\infty) := 0 \ 
\textrm{(which coincides with both
$\lim_{t\rightarrow \infty} \lim_{s\rightarrow \infty} \psi_{\phi_{TV},c}(s,t)$
}
\nonumber
\\
& & \hspace{2.9cm}
\textrm{ and  
$\lim_{s\rightarrow \infty} \lim_{t\rightarrow \infty} \psi_{\phi_{TV},c}(s,t)$
}),
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{TV},c}(0,\infty) := \lim_{s \rightarrow 0} \lim_{t \rightarrow \infty} \psi_{\phi_{TV},c}(s,t)
= 2 
\nonumber
\\
& & \hspace{2.0cm}
\textrm{(which coincides with 
$\lim_{t\rightarrow \infty} \lim_{s\rightarrow 0} \psi_{\phi_{TV},c}(s,t)$
}),
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{TV},c}(\infty,0) := \lim_{s \rightarrow \infty} \lim_{t \rightarrow 0} \psi_{\phi_{TV},c}(s,t)
= \infty 
\nonumber
\\
& & \hspace{2.0cm}
\textrm{(which coincides with 
$\lim_{t\rightarrow 0} \lim_{s\rightarrow \infty} \psi_{\phi_{TV},c}(s,t)$
}) .
\nonumber
\end{eqnarray}

\vspace{-0.2cm}

\noindent
In particular, one sees from Assumption \ref{brostu2:assu.class1}(a) 
that -- in our context -- $\phi_{TV}$ can only be potentially applied if
$\frac{q(x)}{m_{2}(x)} = 1$ for $\lambda-$a.a. $x \in \mathcal{X}$
and from Assumption \ref{brostu2:assu.class1}(c), (d) that we 
\textit{generally} have to exclude $c=1$ and $c=0$ for $\phi_{+,c}^{\prime}(\cdot)$
(i.e. we choose $c \in ]0,1[$);
as already mentioned above, under some non-obvious additional constraints on 
the functions
$P$, $Q$ it may be possible to drop 
the Assumptions \ref{brostu2:assu.class1}(c), (d), 
see for instance Subsection 3.3.1.2 
below.

\enlargethispage{0.5cm}

\vspace{0.2cm}
\noindent
Another interesting and technically delicate example
is the divergence generator $\phi_{ie}(t):= t -1 + \frac{(1-t)^3}{3} \cdot \boldsymbol{1}_{[0,1]}(t)$
which is convex, twice continuously differentiable, strictly convex at any point $t \in ]0,1]$  
and affine-linear on $[1,\infty[$. More detailed,
one 
obtains
for arbitrarily fixed $s,t \in ]0,\infty[$, $\alpha \in [0,1]$
(if not stated otherwise): 

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
\phi_{ie}(1)=0, \quad \phi_{ie}(0) = - \frac{2}{3}, \quad \phi_{ie}(\infty) = \infty,
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\phi_{ie}^{\prime}(t)=
1 - (1-t)^{2} \cdot \boldsymbol{1}_{]0,1[}(t),  
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\phi_{ie}^{\prime}(1) = 1, \quad
\phi_{ie}^{\prime}(0) = \lim_{t \rightarrow 0} \phi_{ie}^{\prime}(t) = 0,
\quad 
\phi_{ie}^{\prime}(\infty) = \lim_{t \rightarrow \infty} \phi_{ie}^{\prime}(t) = 1, 
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\phi_{ie}^{\prime\prime}(t)=
2(1-t) \cdot \boldsymbol{1}_{]0,1[}(t), \quad \phi_{ie}^{\prime\prime}(1) = 0, 
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{ie}}(s,t) = 
\frac{(1-s)^3}{3} \cdot \boldsymbol{1}_{]0,1[}(s) 
+ \ (1-t)^2 \cdot \Big[\frac{2}{3} \cdot (1-t) + (s-1) \Big] \cdot \boldsymbol{1}_{]0,1[}(t),
\nonumber 
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{ie}}(s,1) = 
\frac{(1-s)^3}{3} \cdot \boldsymbol{1}_{]0,1[}(s) ,
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{ie}}(0,t) = \lim_{s \rightarrow 0} \psi_{\phi_{ie}}(s,t) 
= \frac{1}{3} \cdot \boldsymbol{1}_{[1,\infty[}(t) + 
\frac{1}{3} \cdot \Big[1-(1-t)^{2} \cdot (1-2t)  \Big] \cdot \boldsymbol{1}_{]0,1[}(t) , 
\nonumber 
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{ie}}(\infty,t) = \lim_{s \rightarrow \infty} \psi_{\phi_{ie}}(s,t)
= \infty \cdot \boldsymbol{1}_{]0,1[}(t) ,
\nonumber
\\ 
& & \hspace{-0.2cm}   \textstyle
\lim_{s\rightarrow \infty} \frac{1}{s} \cdot \psi_{\phi_{ie}}(s,1) = 
0,
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{ie}}(s,0) = \lim_{t \rightarrow 0} \psi_{\phi_{ie}}(s,t)
= \big( s - \frac{1}{3} \big) \cdot \boldsymbol{1}_{[1,\infty[}(s)
+ s^{2}\cdot \big( 1 - \frac{s}{3} \big) \cdot \boldsymbol{1}_{]0,1[}(s) , 
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{ie}}(s,\infty) = \lim_{t \rightarrow \infty} \psi_{\phi_{ie}}(s,t)
= \frac{(1-s)^3}{3} \cdot \boldsymbol{1}_{]0,1[}(s) , 
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{ie}}(0,0) := 0 \ 
\textrm{(which coincides with both
$\lim_{t\rightarrow 0} \lim_{s\rightarrow 0} \psi_{\phi_{ie}}(s,t)$
}
\nonumber
\\
& & \hspace{2.6cm}
\textrm{ and  
$\lim_{s\rightarrow 0} \lim_{t\rightarrow 0} \psi_{\phi_{ie}}(s,t)$
}),
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{ie}}(\infty,\infty) := 0 \ 
\textrm{(which coincides with both
$\lim_{t\rightarrow \infty} \lim_{s\rightarrow \infty} \psi_{\phi_{ie}}(s,t)$
}
\nonumber
\\
& & \hspace{2.9cm}
\textrm{ and  
$\lim_{s\rightarrow \infty} \lim_{t\rightarrow \infty} \psi_{\phi_{ie}}(s,t)$
}),
\nonumber
\label{brostu2:fo.def.69n}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{ie}}(0,\infty) := \lim_{s \rightarrow 0} \lim_{t \rightarrow \infty} \psi_{\phi_{ie}}(s,t)
= \frac{1}{3} 
\nonumber
\\
& & \hspace{2.0cm}
\textrm{(which coincides with 
$\lim_{t\rightarrow \infty} \lim_{s\rightarrow 0} \psi_{\phi_{ie}}(s,t)$
}),
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{\phi_{ie}}(\infty,0) := \lim_{s \rightarrow \infty} \lim_{t \rightarrow 0} \psi_{\phi_{ie}}(s,t)
= \infty 
\nonumber
\\
& & \hspace{2.0cm}
\textrm{(which coincides with 
$\lim_{t\rightarrow 0} \lim_{s\rightarrow \infty} \psi_{\phi_{ie}}(s,t)$
}) .
\nonumber
\end{eqnarray}

\vspace{-0.2cm}

\noindent
In particular, one sees from the Assumptions \ref{brostu2:assu.class1}(a),(b) 
that -- in our context -- $\phi_{ie}$ can only be potentially applied in the following
two disjoint situations:\\
$(i)$ \ $\frac{q(x)}{m_{2}(x)} < 1$ for $\lambda-$a.a. $x \in \mathcal{X}$;\\
$(ii)$ \ $\frac{q(x)}{m_{2}(x)} = 1$ and $\frac{p(x)}{m_{1}(x)} \leq 1$
for $\lambda-$a.a. $x \in \mathcal{X}$.\\
As already mentioned above, under some non-obvious additional constraints on 
the functions
$P$, $Q$ it may be possible to drop Assumption \ref{brostu2:assu.class1}(b)
and consequently (ii) can then be replaced by\\
$\widetilde{(ii)}$ \ $\frac{q(x)}{m_{2}(x)} = 1$ for $\lambda-$a.a. $x \in \mathcal{X}$;\\ 
see for instance Subsection 3.3.1.2 
below.

\vspace{-0.4cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The scaling and the aggregation functions $m_1$, $m_2$, $\mathbbm{m}_{3}$}
\label{subsec.2.3verynew}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.2cm}

\enlargethispage{0.5cm}

\noindent
In the above two Subsections \ref{subsec.2.1verynew} and \ref{subsec.2.2verynew}, we have illuminated details of the 
choices of the first and the last component of 
$\beta = (\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda)$. 
Let us now discuss the
\textit{principal} 
roles as well as examples of $m_1$, $m_2$, $\mathbbm{m}_{3}$, 
which 
widen considerably the divergence-modeling flexibility and thus bring in a broad spectrum of 
goal-oriented situation-based applicability. 
To start with, recall that in accordance with \eqref{brostu2:fo.def.1}, 
the aggregation function $\mathbbm{m}_{3}$ tunes 
the fine aggregation details
(whereas $\lambda$ can be interpreted as a ``governer'' upon the 
basic/principle aggregation structure);
furthermore, the function $m_1(\cdot)$ scales the  
function $p(\cdot)$
and 
$m_2(\cdot)$ the 
function $q(\cdot)$.
From a modeling perspective, 
these two scaling functions can e.g. be ``purely direct'' in the sense that
$m_{1}(x)$, $m_{2}(x)$ are chosen to directly reflect some dependence
on the 
data-reflecting state
$x\in \mathcal{X}$ (independent of the choice of $P$,$Q$),
or ``purely adaptive'' in the sense that
$m_{1}(x) = w_{1}(p(x),q(x))$, $m_{2}(x) = w_{2}(p(x),q(x))$
for some appropriate (measurable) ``connector functions'' $w_{1}$, $w_{2}$ on the
product $\mathcal{R}(P) \times \mathcal{R}(Q)$ of the ranges of 
$\big\{p(x)\big\}_{x \in \mathcal{X}}$
and $\big\{q(x)\big\}_{x \in \mathcal{X}}$,
or ``hybrids'' $m_{1}(x) = w_{1}(x,p(x),q(x))$
$m_{2}(x) = w_{2}(x,p(x),q(x))$.
Also recall that in consistency with Assumption \ref{brostu2:assu.class1}
we always assume 
$\mathbbm{m}_{3}(x)= \mathbbm{w}_{3}\big(x,\frac{p(x)}{m_{1}(x)},\frac{q(x)}{m_{2}(x)} \big)$
for some (measurable) function $\mathbbm{w}_{3}: \mathcal{X} \times [a,b] \times [a,b] \rightarrow [0,\infty]$.
Whenever applicable and 
insightfulness-enhancing,  
we use the notation $D^{c}_{\phi,W_{1},W_{2},\mathbbm{W}_{3},\lambda}(P,Q)$
instead of $D^{c}_{\phi,M_{1},M_{2},\mathbbm{M}_{3},\lambda}(P,Q)$.

\vspace{0.2cm} 
\noindent
Let us start with the following
important sub-setup:


\vspace{0.15cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\noindent
\textbf{3.3.1 \ \
$\mathbf{m_{1}(x) = m_{2}(x) := m(x)}$, $\mathbf{\mathbbm{m}_{3}(x) = r(x) \cdot m(x)\in [0,\infty]}$ for some
(meas.) function $\mathbf{r: \mathcal{X} \rightarrow \mathbb{R}}$
satisfying
$\mathbf{r(x) \in ]-\infty,0[ \cup ]0,\infty[}$ for $\mathbf{\lambda -}$a.a. $\mathbf{x \in \mathcal{X}}$
}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{0.15cm}

\noindent
As an interpretation, here the scaling functions are 
strongly coupled with the aggregation function;
in order to avoid ``case-overlapping'', we assume that
the function $r(\cdot)$ does not (explicitly) dependent
on the functions $m(\cdot)$, $p(\cdot)$ and $q(\cdot)$ 
(i.e. it is not of the form $r(\cdot)= h(\cdot, m(\cdot), p(\cdot), q(\cdot))$\, ).
From \eqref{brostu2:fo.def.1} one can deduce

\vspace{-0.6cm}

\enlargethispage{0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D^{c}_{\phi,M,M,R\cdot M,\lambda}(P,Q) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
: =
\olint_{{\mathcal{X}}} 
\Big[ \phi  \big( {
\frac{p(x)}{m(x)}}\big) -\phi  \big( {\frac{q(x)}{m(x)}}\big) 
- \phi_{+,c}^{\prime} 
\big( {\frac{q(x)}{m(x)}}\big) \cdot \big( \frac{p(x)}{m(x)}-\frac{q(x)}{m(x)}\big) 
\Big] \cdot 
m(x) \cdot r(x) \, \mathrm{d}\lambda(x) \ , \qquad \ \ 
\label{brostu2:fo.def.20}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
which for the discrete setup 
$(\mathcal{X},\lambda) = (\mathcal{X}_{\#},\lambda_{\#})$ 
(recall $\lambda_{\#}[\{x\}] =1$ for all $x \in \mathcal{X}_{\#}$) 
simplifies to

\vspace{-0.6cm}

\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D^{c}_{\phi,M,M,R\cdot M,\lambda_{\#}}(P,Q) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
 =
\olsum_{{x \in \mathcal{X}}} 
\Big[ \phi  \big( {
\frac{p(x)}{m(x)}}\big) -\phi  \big( {\frac{q(x)}{m(x)}}\big)
- \phi_{+,c}^{\prime} 
\big( {\frac{q(x)}{m(x)}}\big) \cdot \big( \frac{p(x)}{m(x)}-\frac{q(x)}{m(x)}\big) 
\Big] \cdot
m(x) \cdot r(x) \ . \qquad \ \ 
\label{brostu2:fo.def.21}
\end{eqnarray}

\vspace{-0.3cm}

\begin{remark}
\label{brostu2:rem.40}
(a) \ If one has a ``nonnegativity-setup'' (NN1) in the sense that
for $\lambda-$almost all $x \in \mathcal{X}$ there holds
$\mathbbm{m}(x) \geq 0$, $\mathbbm{r}(x)\geq 0$, $\mathbbm{p}(x) \geq 0$, $\mathbbm{q}(x) \geq 0$,
then \eqref{brostu2:fo.def.20} (and hence also \eqref{brostu2:fo.def.21})
can be interpreted as
scaled Bregman divergence 
$B_{\phi }\big( \mathfrak{P}, \mathfrak{Q}\,|\, \mathfrak{M} \big)$
between the two nonnegative measures $\mathfrak{P}, \mathfrak{Q}$ (on $(\mathcal{X},\mathcal{F})$)
defined by 
$\mathfrak{P}[\bullet] := \mathfrak{P}^{\mathbbm{R} \cdot \lambda}[\bullet] : = 
\int_{\bullet} \mathbbm{p}(x) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x)$ 
and 
$\mathfrak{Q}[\bullet]:= \mathfrak{Q}^{\mathbbm{R} \cdot \lambda}[\bullet] : = 
\int_{\bullet} \mathbbm{q}(x) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x)$,
with scaling by the nonnegative measure 
$\mathfrak{M}[\bullet] := \mathfrak{M}^{\mathbbm{R} \cdot \lambda}[\bullet] : = 
\int_{\bullet} \mathbbm{m}(x) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x)$.\\
(b) \ In a context of $\mathbbm{r}(x) \equiv 1$ and ``$\lambda-$probability-densities'' 
$\mathbbm{\overrightharp{p}}$,
$\mathbbm{\overrightharp{q}}$
on general state space $\mathcal{X}$,
then  
$\mathfrak{\overrightharp{P}}^{\mathbb{1}\cdot \lambda}[\bullet] 
: = \int_{\bullet} \mathbbm{\overrightharp{p}}(x) \, \mathrm{d}\lambda(x)$ 
and 
$\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda}[\bullet] 
: = \int_{\bullet} \mathbbm{\overrightharp{q}}(x) \, \mathrm{d}\lambda(x)$ 
are probability measures (where $\mathbb{1}$ stands for the function with constant value 1).
Accordingly, \eqref{brostu2:fo.def.20} (and hence also \eqref{brostu2:fo.def.21})
can be interpreted as scaled Bregman divergence 
$B_{\phi }\big(
 \mathfrak{\overrightharp{P}}^{\mathbb{1}\cdot \lambda}, \mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda} 
 \,|\,\mathfrak{M}^{\mathbb{1}\cdot \lambda} \big)$
which has been first defined in Stummer~\cite{Stu:07}, Stummer \& Vajda~\cite{Stu:12}, see also
Kisslinger \& Stummer~\cite{Kis:13},~\cite{Kis:15a},~\cite{Kis:16} for the ``purely adaptive'' case 
$\mathbbm{m}(x) = \mathbbm{w}\big(\mathbbm{\overrightharp{p}}(x),\mathbbm{\overrightharp{q}}(x)\big)$ and indication
on non-probability measures.
\vspace{0.2cm}
For instance, if $Y$ is a random variable taking values in the
discrete space $\mathcal{X}_{\#}$, then (with a slight abuse of notation
\footnote{
respectively working with canonical space representation 
and $Y : = id$ 
})
$\mathbbm{\overrightharp{q}}(x) = \mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{\#}}[Y=x]$ 
may be its probability mass function under a hypothetical/candidate law 
$\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{\#}}$,
and $\mathbbm{\overrightharp{p}}(x) = 
\frac{1}{N} \cdot \# \{ i \in \{ 1, \ldots, N\}: Y_i =x \} 
=: \mathbbm{\overrightharp{p}}_{N}^{emp}(x) 
$
is the probability mass function of the 
corresponding data-derived ``empirical distribution'' 
$\mathfrak{\overrightharp{P}}^{\mathbb{1}\cdot \lambda_{\#}}[\bullet] := 
\mathfrak{\overrightharp{P}}_{N}^{emp}[\bullet] 
:= \frac{1}{N} \cdot \sum_{i=1}^{N}   \delta_{Y_{i}}[\bullet]$
of an $N-$size independent and identically distributed (i.i.d.) sample $Y_1, \ldots, Y_N$ of $Y$
which is nothing but the probability distribution reflecting the underlying
(normalized) histogram. 
Typically, for small respectively medium sample size $N$
one gets $\mathbbm{\overrightharp{p}}_{N}^{emp}(x)=0$ for some states
$x \in \mathcal{X}$ which are feasible but ``not yet'' observed;
amongst other things, this explains why density-zeros 
play an important role especially in statistics and information theory.
This concludes the current Remark \ref{brostu2:rem.40}. 
$\square$

\end{remark}


\vspace{-0.15cm}
\noindent
In the following, we illuminate two important special cases of the scaling (and aggregation-part) function $m(\cdot)$,
namely $\mathbbm{m}(x) := 1$ and $m(x):= q(x)$:

\vspace{0.15cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\noindent
\textbf{3.3.1.1 \ \ 
$\mathbf{\mathbbm{m}_{1}(x) = \mathbbm{m}_{2}(x) := 1}$, $\mathbf{\mathbbm{m}_{3}(x) = \mathbbm{r}(x)}$ for some
(measurable) function $\mathbf{\mathbbm{r}: \mathcal{X} \rightarrow [0,\infty]}$
satisfying
$\mathbf{\mathbbm{r}(x) \in ]0,\infty[}$ for $\mathbf{\lambda -}$a.a. $\mathbf{x \in \mathcal{X}}$
}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{0.15cm}

\enlargethispage{0.5cm}

\noindent
Accordingly, \eqref{brostu2:fo.def.20} turns into

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.9cm} \textstyle
0 \leq D^{c}_{\phi,\mathbbm{1},\mathbbm{1},\mathbbm{R} \cdot \mathbbm{1},\lambda}(P,Q) 
\nonumber\\ 
& & \hspace{-0.9cm} \textstyle
: =
\olint_{{\mathcal{X}}} 
\Big[ \phi  \big( p(x)\big) -\phi  \big( q(x) \big)
- \phi_{+,c}^{\prime} 
\big( q(x) \big) \cdot \big( p(x) - q(x) \big) 
\Big] \cdot
\mathbbm{r}(x) \, \mathrm{d}\lambda(x) \ ,
\label{brostu2:fo.def.40var}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
which for the discrete setup 
$(\mathcal{X},\lambda) = (\mathcal{X}_{\#},\lambda_{\#})$ 
becomes

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.9cm} \textstyle
0 \leq D^{c}_{\phi,\mathbbm{1},\mathbbm{1},\mathbbm{R}\cdot \mathbbm{1},\lambda_{\#}}(P,Q) 
\nonumber\\ 
& & \hspace{-0.9cm} 
: =
\olsum_{{x \in \mathcal{X}}} 
\Big[ \phi  \big( p(x)\big) -\phi  \big( q(x) \big) 
- \phi_{+,c}^{\prime} 
\big( q(x) \big) \cdot \big( p(x) - q(x) \big) 
\Big] \cdot
\mathbbm{r}(x) \ .
\label{brostu2:fo.def.41}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
Notice that for $\mathbbm{r}(x) \equiv 1$, the divergences 
\eqref{brostu2:fo.def.40var} and \eqref{brostu2:fo.def.41} are
 ``consistent extensions'' of the 
motivating 
pointwise dissimilarity $d_{\phi}^{(6)}(\cdot,\cdot)$ 
from   
Section \ref{sec.1newb}. A special case of \eqref{brostu2:fo.def.40var}
is e.g. the rho-tau divergence (cf. Lemma 1 of Zhang \& Naudts~\cite{Zha:17}). 

\vspace{0.2cm}
\noindent
Let us exemplarily illuminate 
the special case  
$\phi = \phi_{\alpha}$ 
together with 
$\mathbbm{p}(x) \geq 0$,
$\mathbbm{q}(x) \geq 0$,
for $\lambda-$almost all $x\in \mathcal{X}$
which by means of 
\eqref{brostu2:fo.def.33e}, \eqref{brostu2:fo.def.125e}, \eqref{brostu2:fo.def.127e}
turns 
\eqref{brostu2:fo.def.40var} into the ``explicit-boundary'' version (of 
the corresponding ``implicit-boundary-describing'' $\olint \ldots$)

\vspace{-0.7cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D_{\phi_{\alpha},\mathbbm{1},\mathbbm{1},\mathbbm{R}\cdot \mathbbm{1},\lambda}(\mathbbm{P},\mathbbm{Q})
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
= \olint_{{\mathcal{X}}} 
\frac{\mathbbm{r}(x)}{\alpha \cdot (\alpha-1)} \cdot
\big[ 
\mathbbm{p}(x)^{\alpha} + (\alpha-1) \cdot \mathbbm{q}(x)^{\alpha} - \alpha 
\cdot \mathbbm{p}(x) \cdot \mathbbm{q}(x)^{\alpha-1} 
\big]  \, \mathrm{d}\lambda(x)
\label{brostu2:fo.def.140a0}
\\ 
& & \hspace{-0.2cm}   \textstyle 
= \int_{{\mathcal{X}}} 
\frac{\mathbbm{r}(x)}{\alpha \cdot (\alpha-1)} \cdot
\big[ 
\mathbbm{p}(x)^{\alpha} + (\alpha-1) \cdot \mathbbm{q}(x)^{\alpha} - \alpha 
\cdot \mathbbm{p}(x) \cdot \mathbbm{q}(x)^{\alpha-1} 
\big] \nonumber\\
& & \hspace{7.8cm} 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) \big)
 \, \mathrm{d}\lambda(x) 
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)
\cdot \big[ 
\frac{\mathbbm{p}(x)^{\alpha}}{\alpha \cdot (\alpha-1)} 
\cdot \boldsymbol{1}_{]1,\infty[}(\alpha) 
+ \infty \cdot \boldsymbol{1}_{]-\infty,0[ \cup ]0,1[}(\alpha) 
\big] 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x)
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)
\cdot \big[ 
\frac{\mathbbm{q}(x)^{\alpha}}{\alpha} \cdot \boldsymbol{1}_{]0,1[ \cup ]1,\infty[}(\alpha)
+ \infty \cdot \boldsymbol{1}_{]-\infty,0[}(\alpha)
\big] 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{q}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big) 
\, \mathrm{d}\lambda(x) \, ,
\nonumber \\ 
& & \hspace{9.2cm} 
\textrm{ for } \alpha \in \mathbb{R}\backslash\{0,1\},
\label{brostu2:fo.def.140a}
\\[-0.2cm]
& & \hspace{-0.2cm}   \textstyle 
0 \leq D_{\phi_{1},\mathbbm{1},\mathbbm{1},\mathbbm{R}\cdot \mathbbm{1},\lambda}(\mathbbm{P},\mathbbm{Q}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
= \int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \big[ 
\mathbbm{p}(x) \cdot \log\big(\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}\big) + \mathbbm{q}(x) - \mathbbm{p}(x) 
\big]
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x)\big) \, \mathrm{d}\lambda(x) 
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)
\cdot \infty
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x)
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)
\cdot \mathbbm{q}(x)
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{q}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big) 
\, \mathrm{d}\lambda(x)
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
= \int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot  
\mathbbm{p}(x) \cdot \log\big(\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}\big)
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x)\big) \, \mathrm{d}\lambda(x) 
+ \int_{{\mathcal{X}}} 
\mathbbm{r}(x)
\cdot (\mathbbm{q}(x) - \mathbbm{q}(x)) 
\, \mathrm{d}\lambda(x) 
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ \infty \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot
\big(\mathbbm{p}(x) + \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x)\big)\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x) \, , 
\label{brostu2:fo.def.140b}
\\
& & \hspace{-0.2cm}   \textstyle 
0 \leq D_{\phi_{0},\mathbbm{1},\mathbbm{1},\mathbbm{R}\cdot \mathbbm{1},\lambda}(\mathbbm{P},\mathbbm{Q}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
= \int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \Big[ 
- \log\big(\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}\big) + \frac{\mathbbm{p}(x)}{\mathbbm{q}(x)} - 1 
\Big]
\cdot  \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x)\big) \, \mathrm{d}\lambda(x)
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)
\cdot \infty
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x)
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)
\cdot \infty
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{q}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big) 
\, \mathrm{d}\lambda(x) \, ,
\label{brostu2:fo.def.140c}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
where we have employed 
\eqref{brostu2:fo.def.33f}, \eqref{brostu2:fo.def.33i}
\eqref{brostu2:fo.def.125g}, \eqref{brostu2:fo.def.125i},
\eqref{brostu2:fo.def.127g}, \eqref{brostu2:fo.def.127i};
notice that 
$D_{\phi_{1},\mathbbm{1},\mathbbm{1},\mathbbm{R}\cdot \mathbbm{1},\lambda}(\mathbbm{P},\mathbbm{Q})$
is a generalized version of the Kullback-Leibler information divergence
(resp. of the relative entropy). 
According to the above calculations, 
one should exclude $\alpha \leq 0$ whenever $\mathbbm{p}(x) =0$ for all $x$ in some $A$ with $\lambda[A]>0$,
respectively $\alpha \leq 1$ whenever $\mathbbm{q}(x) =0$ for all $x$ in some $\tilde{A}$ with $\lambda[\tilde{A}]>0$
(a refined alternative for $\alpha=1$ is given in Subsection 3.3.1.2 below).
As far as splitting of the first integral e.g. in \eqref{brostu2:fo.def.140b} resp. \eqref{brostu2:fo.def.140c}
is concerned, notice that the integral 
$(\mathfrak{P}^{\mathbbm{R} \cdot \lambda} - \mathfrak{Q}^{\mathbbm{R} \cdot \lambda})[\mathcal{X}] := 
\int_{{\mathcal{X}}} \big[\mathbbm{q}(x) - \mathbbm{p}(x) \big]
\cdot \mathbbm{r}(x)  \, \mathrm{d}\lambda(x)$ 
resp.
$\int_{{\mathcal{X}}} \Big[  \frac{\mathbbm{p}(x)}{\mathbbm{q}(x)} - 1 \Big]
\cdot \mathbbm{r}(x)  \, \mathrm{d}\lambda(x)$ 
may be finite even in cases where
$\mathfrak{P}^{\mathbbm{R} \cdot \lambda}[\mathcal{X}] = \int_{{\mathcal{X}}} \mathbbm{p}(x)
 \cdot \mathbbm{r}(x)  \, \mathrm{d}\lambda(x) = \infty$
and 
$\mathfrak{Q}^{\mathbbm{R} \cdot \lambda}[\mathcal{X}] = \int_{{\mathcal{X}}} \mathbbm{q}(x) \cdot 
\mathbbm{r}(x)  \, \mathrm{d}\lambda(x) = \infty$
(especially in case of unbounded data space (e.g. $\mathcal{X}=\mathbb{R}$) when
an additive constant is involved and $\mathbbm{r}(\cdot)$ is bounded from above); 
furthermore, there are situations where 
$\mathfrak{P}^{r\cdot \lambda}[\mathcal{X}] = \mathfrak{Q}^{r\cdot \lambda}[\mathcal{X}] < \infty$
and thus $(\mathfrak{P}^{\mathbbm{R} \cdot \lambda} - \mathfrak{Q}^{\mathbbm{R} \cdot \lambda})[\mathcal{X}] =0$
but
$\int_{{\mathcal{X}}} \Big[  \frac{\mathbbm{p}(x)}{\mathbbm{q}(x)} - 1 \Big]
\cdot \mathbbm{r}(x)  \, \mathrm{d}\lambda(x) = \infty$.
For $\alpha=2$, we obtain from \eqref{brostu2:fo.def.140a} and \eqref{brostu2:fo.def.99e} to \eqref{brostu2:fo.def.99k}

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D_{\phi_{2},\mathbbm{1},\mathbbm{1},\mathbbm{R}\cdot \mathbbm{1},\lambda}(\mathbbm{P},\mathbbm{Q}) 
= \int_{{\mathcal{X}}} 
\frac{\mathbbm{r}(x)}{2} \cdot
\big[ \mathbbm{p}(x) - \mathbbm{q}(x) \big]^2
 \, \mathrm{d}\lambda(x) \ , 
\label{brostu2:fo.def.140d}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
where we can exceptionally drop the non-negativity constraints $\mathbbm{p}(x) \geq 0$,
$\mathbbm{q}(x) \geq 0$.
As for interpretation, \eqref{brostu2:fo.def.140d} is nothing but half of the 
$\mathbbm{r}(\cdot)-$weighted squared $L^2(\lambda)-$ distance between
$\mathbbm{p}(\cdot)$ and $\mathbbm{q}(\cdot)$. 


\vspace{0.2cm}
\noindent
In the special sub-setup of $\mathbbm{r}(x) \equiv 1$ and ``$\lambda-$probability-densities'' 
$\mathbbm{\overrightharp{p}}$
$\mathbbm{\overrightharp{q}}$
on 
data space $\mathcal{X}$ (cf. Remark \ref{brostu2:rem.40}(b)),
we can deduce from \eqref{brostu2:fo.def.140a}, \eqref{brostu2:fo.def.140b}, \eqref{brostu2:fo.def.140c}
the divergences

\vspace{-0.2cm}
\begin{equation}
D_{\phi_{\alpha},\mathbbm{1},\mathbbm{1},\mathbbm{1}\cdot 
\mathbbm{1},\lambda}(\mathbbm{\overrightharp{P}},\mathbbm{\overrightharp{Q}})
\label{brostu2:fo.def.140e} 
\end{equation}

\vspace{-0.1cm}

\enlargethispage{0.5cm}

\noindent
which for the choice $\alpha >0$ can be interpreted as
``order$-\alpha$'' density-power divergences DPD of Basu et al.~\cite{Bas:98}
between the two corresponding probability measures $\mathfrak{\overrightharp{P}}^{\mathbb{1}\cdot \lambda}$
and $\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda}$;
for their statistical applications see e.g. Basu et al.\cite{Bas:15a}, Ghosh \& Basu~\cite{Gho:16a},
~\cite{Gho:16b} and the references therein,
and for general $\alpha \in \mathbb{R}$ see e.g. Stummer \& Vajda~\cite{Stu:12}.
In particular, the case $\alpha=1$ corresponding divergence
in \eqref{brostu2:fo.def.140e} 
is called 
``Kullback-Leibler information divergence KL'' between $\mathbbm{\overrightharp{P}}$ and $\mathbbm{\overrightharp{Q}}$,
and is also known under the name ``relative entropy''.
For $\alpha=2$, we derive $D_{\phi_{2},\mathbbm{1},\mathbbm{1},\mathbbm{R}\cdot 
\mathbbm{1},\lambda}(\mathbbm{\overrightharp{P}},\mathbbm{\overrightharp{Q}})$
from \eqref{brostu2:fo.def.140d} with $\mathbbm{r}(x) =1$ 
which is nothing but half of the squared $L^2-$ distance between
the two ``$\lambda-$probability-densities''
$\mathbbm{\overrightharp{p}}$ and $\mathbbm{\overrightharp{q}}$. 

\vspace{0.2cm}
\noindent
For the special discrete setup 
$(\mathcal{X},\lambda) = (\mathcal{X}_{\#},\lambda_{\#})$ 
(recall $\lambda_{\#}[\{x\}] =1$ for all $x \in \mathcal{X}_{\#}$),
the divergences  
\eqref{brostu2:fo.def.140a} to \eqref{brostu2:fo.def.140d}
simplify to

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D_{\phi_{\alpha},\mathbbm{1},\mathbbm{1},\mathbbm{R}\cdot \mathbbm{1},\lambda}(\mathbbm{P},\mathbbm{Q}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
= \sum_{{x \in \mathcal{X}}} 
\frac{\mathbbm{r}(x)}{\alpha \cdot (\alpha-1)} \cdot
\Big[ 
\big(\mathbbm{p}(x)\big)^{\alpha} + (\alpha-1) \cdot \big(\mathbbm{q}(x)\big)^{\alpha} - \alpha 
\cdot \mathbbm{p}(x) \cdot \big(\mathbbm{q}(x)\big)^{\alpha-1} 
\Big] \nonumber\\
& & \hspace{8.2cm} 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) \big) 
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\sum_{{x \in \mathcal{X}}}
\mathbbm{r}(x)
\cdot \big[ 
\frac{\mathbbm{p}(x)^{\alpha}}{\alpha \cdot (\alpha-1)} 
\cdot \boldsymbol{1}_{]1,\infty[}(\alpha) 
+ \infty \cdot \boldsymbol{1}_{]-\infty,0[ \cup ]0,1[}(\alpha) 
\big] 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\sum_{{x \in \mathcal{X}}}
\mathbbm{r}(x)
\cdot \big[ 
\frac{\mathbbm{q}(x)^{\alpha}}{\alpha} \cdot \boldsymbol{1}_{]0,1[ \cup ]1,\infty[}(\alpha)
+ \infty \cdot \boldsymbol{1}_{]-\infty,0[}(\alpha)
\big] 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{q}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big) \, ,
\nonumber \\ 
& & \hspace{9.2cm} 
\textrm{ for } \alpha \in \mathbb{R}\backslash\{0,1\},
\nonumber
\\[-0.2cm]
& & \hspace{-0.2cm}   \textstyle 
0 \leq D_{\phi_{1},\mathbbm{1},\mathbbm{1},\mathbbm{R}\cdot \mathbbm{1},\lambda}(\mathbbm{P},\mathbbm{Q}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
= \sum_{{x \in \mathcal{X}}} 
\mathbbm{r}(x)  \cdot \big[ 
\mathbbm{p}(x) \cdot \log\big(\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}\big) + \mathbbm{q}(x) - \mathbbm{p}(x) 
\big]
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x)\big)  
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\sum_{{x \in \mathcal{X}}} 
\mathbbm{r}(x)
\cdot \infty
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\sum_{{x \in \mathcal{X}}}
\mathbbm{r}(x)
\cdot \mathbbm{q}(x)
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{q}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big) \, ,
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
= \sum_{{x \in \mathcal{X}}} 
\mathbbm{r}(x)  \cdot  
\mathbbm{p}(x) \cdot \log\big(\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}\big)
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x)\big)  
\ + \ 
\sum_{{x \in \mathcal{X}}}
\mathbbm{r}(x)
\cdot (\mathbbm{q}(x) - \mathbbm{q}(x)) 
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ \ \infty \cdot
\sum_{{x \in \mathcal{X}}} 
\mathbbm{r}(x) \cdot
\big(\mathbbm{p}(x) + \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x)\big)\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big) \, , 
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle 
0 \leq D_{\phi_{0},\mathbbm{1},\mathbbm{1},\mathbbm{R}\cdot \mathbbm{1},\lambda}(\mathbbm{P},\mathbbm{Q}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
= \sum_{{x \in \mathcal{X}}} 
\mathbbm{r}(x)  \cdot \big[ 
- \log\big(\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}\big) + \frac{\mathbbm{p}(x)}{\mathbbm{q}(x)} - 1 
\big]
\cdot  \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x)\big) 
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\sum_{{x \in \mathcal{X}}}
\mathbbm{r}(x)
\cdot \infty
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\sum_{{x \in \mathcal{X}}} 
\mathbbm{r}(x)
\cdot \infty
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{q}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big) \, ,
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle 
0 \leq D_{\phi_{2},\mathbbm{1},\mathbbm{1},\mathbbm{R} \cdot \mathbbm{1},\lambda_{\#}}(\mathbbm{P},\mathbbm{Q}) 
= \sum_{{x \in \mathcal{X}}} 
\frac{\mathbbm{r}(x)}{2} \cdot
\big[ \mathbbm{p}(x) - \mathbbm{q}(x) \big]^2 \, .
\nonumber  
\end{eqnarray}

\vspace{-0.2cm}

\noindent
Hence, as above, one should exclude 
$\alpha \leq 0$ whenever $\mathbbm{p}(x) =0$ for all $x$ in some $A$ with $\lambda[A]>0$,
respectively $\alpha \leq 1$ whenever $\mathbbm{q}(x) =0$ for all $x$ in some $\tilde{A}$ with $\lambda[\tilde{A}]>0$
(a refined alternative for $\alpha=1$ is given in Subsection 3.3.1.2 below).


\vspace{0.2cm}
\noindent
In particular, take the probability context of Remark \ref{brostu2:rem.40}(b),
with discrete random variable $Y$, 
hypothetical probability mass function 
$\mathbbm{q}(x) := \mathbbm{\overrightharp{q}}(x) = \mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{\#}}[Y=x]$,
and data-derived probability mass function (relative frequency)
$\mathbbm{p}(x) := \mathbbm{\overrightharp{p}}_{N}^{emp}(x) = 
\frac{1}{N} \cdot \# \{ i \in \{ 1, \ldots, N\}: Y_i =x \}$ with sample size $N$.
For $\mathbbm{r}(x)\equiv 1$, 
the corresponding sample-size-weighted divergences
$2N \cdot D_{\phi_{\alpha},\mathbbm{1},\mathbbm{1},\mathbbm{1},\lambda_{\#}}(
\mathbb{\overrightharp{P}}_{N}^{emp},\mathbbm{\overrightharp{Q}})$
\ (for $\alpha \in \mathbb{R}$) can be used as goodness-of-fit test statistics;
see e.g. Kisslinger \& Stummer~\cite{Kis:16} for their limit behaviour as the sample size $N$
tends to infinity.


\vspace{0.25cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\noindent
\textbf{3.3.1.2 \ \
$\mathbf{m_{1}(x) = m_{2}(x) := q(x)}$, $\mathbf{\mathbbm{m}_{3}(x) = r(x) \cdot q(x) \in [0, \infty]}$ for some
(meas.) function $\mathbf{r: \mathcal{X} \rightarrow \mathbb{R}}$ satisfying
$\mathbf{r(x) \in ]-\infty,0[ \cup ]0,\infty[}$ for $\mathbf{\lambda -}$a.a. $\mathbf{x \in \mathcal{X}}$ 
}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{0.1cm}

\enlargethispage{0.5cm}

\noindent
In such a set-up, 
the divergence \eqref{brostu2:fo.def.20} becomes

\vspace{-0.7cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D^{c}_{\phi,Q,Q,R\cdot Q,\lambda}(P,Q) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
=
\olint_{{\mathcal{X}}} 
\big[ \phi  \big( {
\frac{p(x)}{q(x)}}\big) -\phi  \big( 1 \big) 
- \phi_{+,c}^{\prime} 
\big( 1 \big) \cdot \big( \frac{p(x)}{q(x)}- 1 \big) 
\big] \cdot 
q(x) \cdot r(x) \, \mathrm{d}\lambda(x)  
\label{brostu2:fo.def.45a}
\\ 
& & \hspace{-0.2cm}   \textstyle 
=
\olint_{{\mathcal{X}}} 
\big[ q(x) \cdot \phi  \big( {
\frac{p(x)}{q(x)}}\big) - q(x) \cdot \phi  \big( 1 \big) 
- \phi_{+,c}^{\prime} 
\big( 1 \big) \cdot \big( p(x) - q(x) \big) 
\big] \cdot
r(x) \, \mathrm{d}\lambda(x) \, , \qquad \ 
\label{brostu2:fo.def.45b}
\end{eqnarray}

\vspace{-0.2cm}
\noindent
where in accordance with the descriptions right after \eqref{brostu2:fo.def.1} 
we require that $\phi: ]a,b[  \rightarrow \mathbb{R}$ is convex and 
strictly convex at $1 \in ]a,b[$ and 
incorporate the zeros of $p(\cdot),q(\cdot),r(\cdot)$
by the appropriate limits and conventions.
In the following, we demonstrate this in a non-negativity set-up  
where for $\lambda-$almost all $x \in \mathcal{X}$ one has  
$\mathbbm{r}(x) \in ]0,\infty[$
as well as $\mathbbm{p}(x) \in [0,\infty[$,
$\mathbbm{q}(x) \in [0,\infty[$, 
one can take $E=]a,b[=]0,\infty[$.
In order to achieve a reflexivity result in the spirit of
Theorem \ref{brostu2:thm.2}, we have to check for --
respectively analogously adapt most of -- the 
points in Assumption \ref{brostu2:assu.class1}:
to begin with, the weight 
$w(x,s,t)$ evaluated at $s:= \mathbbm{p}(x)$, 
$t:= \mathbbm{q}(x)$ has to be substituted/replaced by 
$\widetilde{w}(x,\widetilde{t}) := \mathbbm{r}(x) \cdot \widetilde{t}$
evaluated at $\widetilde{t} = \mathbbm{q}(x)$,
and the dissimilarity $\psi_{\phi,c}(s,t)$
has to be substituted/replaced
by $\widetilde{\widetilde{\psi}}_{\phi,c}(\widetilde{s},\widetilde{t}) := \psi_{\phi,c}\big(\frac{\widetilde{s}}{\widetilde{t}},1\big)$
with the plug-in $\widetilde{s} = \mathbbm{p}(x)$. 
Putting things together, instead of the integrand-generating term 
$w(x,s,t) \cdot \psi_{\phi,c}(s,t)$ we have to inspect the boundary behaviour
of  $\widetilde{w}(x,\widetilde{t}) \cdot \widetilde{\widetilde{\psi}}_{\phi,c}(\widetilde{s},\widetilde{t})$
being explicitly given (with a slight abuse of notation) by
the function $\widetilde{\psi}_{\phi,c}: ]0,\infty[^3 \rightarrow [0,\infty[$ in

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\widetilde{\psi}_{\phi,c}\big(r,\widetilde{s},\widetilde{t}\big) := r \cdot \widetilde{t} \cdot \psi_{\phi,c}\big(\frac{\widetilde{s}}{\widetilde{t}},1\big) = 
r \cdot \widetilde{t} \cdot  \big[ \phi\big(\frac{\widetilde{s}}{\widetilde{t}}\big) - \phi(1) - \phi_{+,c}^{\prime}(1) \cdot \big(\frac{\widetilde{s}}{\widetilde{t}}-1 \big) 
\big ] \ 
\nonumber \\  
& & \hspace{-0.2cm}   \textstyle
= r \cdot \widetilde{t} \cdot  \big[ \phi\big(\frac{\widetilde{s}\cdot r}{\widetilde{t} \cdot r}\big) - \phi(1) - \phi_{+,c}^{\prime}(1) 
\cdot \big(\frac{\widetilde{s} \cdot r}{\widetilde{t} \cdot r}-1 \big) 
\big ] \ 
= r \cdot \widetilde{t} \cdot \psi_{\phi,c}\big(\frac{\widetilde{s} \cdot r}{\widetilde{t} \cdot r},1\big) \, . \qquad \ \  
\label{brostu2:fo.def.45btwo}
\end{eqnarray}

\enlargethispage{0.5cm}

\vspace{-0.3cm}

\noindent
Since the general right-hand-derivative concerning assumption $t \in \mathcal{R}\big(\frac{Q}{M_{2}}\big)$ has  
$\frac{\widetilde{s}}{\widetilde{t}} =1$ as its analogue, we require
that the convex function $\phi :]0,\infty[ \rightarrow ]-\infty,\infty[$ is strictly convex (only) at $1$
in conformity with Assumption \ref{brostu2:assu.class1}(a) (which is also employed in Assumption \ref{brostu2:assu.class2});
for the sake of brevity
we use the short-hand notation $2(a)$ etc. in the following discussion. We shall not need 2(b) to 2(d) in the prevailing context,
so that the above-mentioned generator $\phi_{TV}(t):= |t-1|$ is allowed for achieving reflexivity (for reasons
which will become clear in the proof of Theorem \ref{brostu2:thm.2CASD} below). The analogue of 2(e)
is $\mathbbm{r}(x) \cdot \widetilde{t} < \infty$ which is always (almost surely) automatically satisfied (a.a.sat.),
whereas 2(f) converts to ``$\mathbbm{r}(x) \cdot \widetilde{t} > 0$ for all $\widetilde{s} \ne \widetilde{t}$''
which is also a.a.sat. except for the case $\widetilde{t} =0$ which will be 
below incorporated in combination with $\psi_{\phi,c}-$multiplication (cf. \eqref{brostu2:fo.def.45bthree}).
For the derivation of the analogue of 2(k)
we observe that for fixed $r >0$, $\widetilde{s} >0$ the function $\widetilde{t} \rightarrow \widetilde{\psi}_{\phi,c}\big(r,\widetilde{s},\widetilde{t}\big)$
is (the $r-$fold of) the perspective function (at $\widetilde{s}$) of the convex function $\psi_{\phi,c}\big( \cdot ,1\big)$
and thus convex with existing limit 

\vspace{-0.6cm}
 
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\ell i_{1} := r \cdot 0 \cdot \psi_{\phi,c}\big(\frac{\widetilde{s}}{0},1\big) 
: = \lim_{t\rightarrow 0} \widetilde{\psi}_{\phi,c}\big(r,\widetilde{s},\widetilde{t}\big) =  
\nonumber \\  
& & \hspace{-0.2cm}   \textstyle
=  - r \cdot \widetilde{s} \cdot \phi_{+,c}^{\prime}(1) +  r \cdot \widetilde{s} \cdot \lim_{\widetilde{t}\rightarrow 0}
 \big[ \frac{\widetilde{t}}{\widetilde{s}} \cdot \phi\big(\frac{\widetilde{s}}{\widetilde{t}}\big) \big ] 
 =  r \cdot \widetilde{s} \cdot (\phi^{*}(0) -\phi_{+,c}^{\prime}(1)) \geq 0 \, , \qquad \ \ 
\label{brostu2:fo.def.45bthree}
\end{eqnarray}

\vspace{-0.3cm}

\noindent
where $\phi^{*}(0) := \lim_{u\rightarrow 0} u \cdot \phi\big(\frac{1}{u}\big) = 
\lim_{v\rightarrow \infty} \frac{\phi(v)}{v}$ 
exists but may be infinite (recall that $\phi_{+,c}^{\prime}(1)$ is finite).
Notice that in contrast to 2(k) we need not assume $\ell i_{1} >0$
(and thus do not exclude $\phi_{TV}$).
To convert 2(i), we employ the fact that 
for fixed $r >0$, $\widetilde{t} >0$ the function 
$\widetilde{s} \rightarrow \widetilde{\psi}_{\phi,c}\big(r,\widetilde{s},\widetilde{t}\big)$
is convex with existing limit

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.5cm} 
r \cdot \widetilde{t} \cdot \psi_{\phi,c}\big(\frac{0}{\widetilde{t}},1\big) 
: = \lim_{s\rightarrow 0} \widetilde{\psi}_{\phi,c}\big(r,\widetilde{s},\widetilde{t}\big)  
 =  r \cdot \widetilde{t} \cdot (\phi(0) + \phi_{+,c}^{\prime}(1) - \phi(1)) > 0  \, ,  \qquad \ 
\nonumber 
\end{eqnarray}

\vspace{-0.2cm}

\noindent
where $\phi(0) := \lim_{u\rightarrow 0} \phi(u)$ exists but may be infinite.
To achieve the analogue of 2(g), let us first remark
that for fixed $r >0$ the function $(\widetilde{s},\widetilde{t}) \rightarrow \widetilde{\psi}_{\phi,c}\big(r,\widetilde{s},\widetilde{t}\big)$ 
may not be continuous at $(\widetilde{s},\widetilde{t}) = (0,0)$, 
but due to the very nature of a divergence we make the (2g)-conform convention of setting

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
r \cdot 0 \cdot \psi_{\phi,c}\big(\frac{0}{0},1\big) 
: = \widetilde{\psi}_{\phi,c}\big(r,0,0\big) :=  0 \, 
\nonumber
\end{eqnarray}

\vspace{-0.2cm}

\noindent
(notice that e.g. the power function $\phi_{-1}$ of \eqref{brostu2:fo.def.32}
with index $\alpha =-1$ obeys
$\lim_{\widetilde{t} \rightarrow 0} \widetilde{\psi}_{\phi_{-1}}\big(r,\widetilde{t},\widetilde{t}\big)
= 0 \ne \frac{r}{2} = \lim_{\widetilde{t} \rightarrow 0} \widetilde{\psi}_{\phi_{-1}}\big(r,\widetilde{t}^2,\widetilde{t}\big)$).
The analogues of the remaining Assumptions 2(h),(j),($\ell$),(m),(n) are (almost surely)
obsolete because of our basic (almost surely) finiteness requirements.
Summing up, with the above-mentioned limits and conventions 
we write \eqref{brostu2:fo.def.45a} explicitly as

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 \leq D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q},\lambda}(\mathbbm{P},\mathbbm{Q}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
=
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \Big[ \mathbbm{q}(x) \cdot \phi  \big( {
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}}\big) - \mathbbm{q}(x) \cdot \phi  \big( 1 \big) 
- \phi_{+,c}^{\prime} 
\big( 1 \big) \cdot \big( \mathbbm{p}(x) - \mathbbm{q}(x) \big) 
\Big] 
\, 
\nonumber \\ 
& & \hspace{7.2cm} 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) 
\big)
\, \mathrm{d}\lambda(x) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \big[ \phi^{*}(0) -\phi_{+,c}^{\prime}(1) \big] \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{p}(x) 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\big[ \phi(0) + \phi_{+,c}^{\prime}(1) - \phi(1) \big] \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x) 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{q}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big)
\, \mathrm{d}\lambda(x)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
=
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \Big[ \mathbbm{q}(x) \cdot \phi  \big( {
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}}\big) - \mathbbm{q}(x) \cdot \phi  \big( 1 \big) 
- \phi_{+,c}^{\prime} 
\big( 1 \big) \cdot \big( \mathbbm{p}(x) - \mathbbm{q}(x) \big) 
\Big] 
\, 
\nonumber \\ 
& & \hspace{7.2cm} 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) 
\big)
\, \mathrm{d}\lambda(x) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \big[ \phi^{*}(0) -\phi_{+,c}^{\prime}(1) \big] \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{p}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\big[ \phi(0) + \phi_{+,c}^{\prime}(1) - \phi(1) \big] \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big)
\, \mathrm{d}\lambda(x)  \, . 
\label{brostu2:fo.def.47b}
\end{eqnarray}

\enlargethispage{0.5cm}

\vspace{-0.1cm}

\noindent
In case of 
$\mathfrak{Q}^{\mathbbm{R}\cdot \lambda}[\mathcal{X}] := 
\int_{{\mathcal{X}}} \mathbbm{q}(x) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) < \infty$,
the divergence \eqref{brostu2:fo.def.47b} becomes

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q},\lambda}(\mathbbm{P},\mathbbm{Q}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
=
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \Big[ \mathbbm{q}(x) \cdot \phi  \big( {
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}}\big) 
- \phi_{+,c}^{\prime} 
\big( 1 \big) \cdot \big( \mathbbm{p}(x) - \mathbbm{q}(x) \big) 
\Big] 
\, 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) 
\big)
\, \mathrm{d}\lambda(x) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \big[ \phi^{*}(0) -\phi_{+,c}^{\prime}(1) \big] \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{p}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\big[ \phi(0) + \phi_{+,c}^{\prime}(1) \big] \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big)
\, \mathrm{d}\lambda(x)  \, 
 - \phi(1) \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x) 
\, \mathrm{d}\lambda(x)  \, . \qquad \ \ 
\label{brostu2:fo.def.47btwo}
\end{eqnarray}

\noindent
Moreover, in case of $\phi \big( 1 \big) = 0$ and 
$(\mathfrak{P}^{\mathbbm{R}\cdot \lambda}-\mathfrak{Q}^{\mathbbm{R}\cdot \lambda})[\mathcal{X}] 
= \int_{{\mathcal{X}}}  \big( \mathbbm{p}(x) - \mathbbm{q}(x) \big) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) \in [0, \infty[$
(but not necessarily $\mathfrak{P}^{\mathbbm{R}\cdot \lambda}[\mathcal{X}] =  \int_{{\mathcal{X}}} \mathbbm{p}(x) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) < \infty$,
$\mathfrak{Q}^{\mathbbm{R}\cdot \lambda}[\mathcal{X}] = \int_{{\mathcal{X}}} \mathbbm{q}(x) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) < \infty$),
the divergence \eqref{brostu2:fo.def.47b} turns into

\vspace{-0.4cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 \leq D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q},\lambda}(\mathbbm{P},\mathbbm{Q}) 
= \int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \mathbbm{q}(x) \cdot \phi  \big( {
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}}\big) 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) 
\big)
\, \mathrm{d}\lambda(x) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \phi^{*}(0) \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{p}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x)
+ \phi(0) \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big)
\, \mathrm{d}\lambda(x)  
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle
- \phi_{+,c}^{\prime}  \big( 1 \big)  \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \big( \mathbbm{p}(x) - \mathbbm{q}(x) \big)
\, \mathrm{d}\lambda(x) \, .
\label{brostu2:fo.def.47c}
\end{eqnarray} 

\vspace{-0.1cm}

\noindent
Let us remark that \eqref{brostu2:fo.def.47c}
can be interpreted as
$\phi-$divergence 
$D^{c}_{\phi }\big( \mu, \nu \big)$
between the two nonnegative measures $\mu, \nu$ (on $(\mathcal{X},\mathcal{F})$)
(cf. Stummer \& Vajda~\cite{Stu:10}), where 
$\mu[\bullet] := \mathfrak{P}^{\mathbbm{R}\cdot \lambda}[\bullet]$ 
and $\nu[\bullet] :=  \mathfrak{Q}^{\mathbbm{R}\cdot \lambda}[\bullet]$. 
In the following, we briefly discuss two important sub-cases.
First, in the ``$\lambda-$probability-densities'' context of Remark \ref{brostu2:rem.40}(b)
one has for general 
$\mathcal{X}$
the manifestation
$\mathbbm{p}(x) := \mathbbm{\overrightharp{p}}(x) \geq 0$, 
$\mathbbm{q}(x) := \mathbbm{\overrightharp{q}}(x) \geq 0$,
and under the constraint $\phi(1)=0$ the corresponding divergence 
$D^{c}_{\phi,\mathbb{\overrightharp{Q}},\mathbb{\overrightharp{Q}},\mathbb{R}\cdot \mathbb{\overrightharp{Q}},\lambda}(\mathbb{\overrightharp{P}},\mathbb{\overrightharp{Q}})$
turns out to be the ($\mathbbm{r}-$)``local $\phi-$divergence of Avlogiaris et al.~\cite{Avl:16a},~\cite{Avl:16b};
in case of $\mathbbm{r}(x) \equiv 1$ this reduces 
-- due to the fact  
$\int_{{\mathcal{X}}} \big( \mathbbm{\overrightharp{p}}(x) - \mathbbm{\overrightharp{q}}(x) \big) \, \mathrm{d}\lambda(x) \ = \ 0$ 
-- 
to the classical Csiszar-Ali-Silvey $\phi-$divergence CASD
(\cite{Csi:63},~\cite{Ali:66}, see also e.g. Liese \& Vajda~\cite{Lie:87}, Vajda~\cite{Vaj:89}) 

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 \leq D^{c}_{\phi,\mathbb{\overrightharp{Q}},\mathbb{\overrightharp{Q}},\mathbb{1}\cdot \mathbb{\overrightharp{Q}},\lambda}(\mathbb{\overrightharp{P}},\mathbb{\overrightharp{Q}}) 
=
\int_{{\mathcal{X}}} 
\mathbbm{\overrightharp{q}}(x) \cdot \phi  \big( {
\frac{\mathbbm{\overrightharp{p}}(x)}{\mathbbm{\overrightharp{q}}(x)}}\big)  
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{\overrightharp{p}}(x) \cdot \mathbbm{\overrightharp{q}}(x)\big)
\, \mathrm{d}\lambda(x) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \phi^{*}(0) \cdot
\int_{{\mathcal{X}}} 
\mathbbm{\overrightharp{p}}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{\overrightharp{q}}(x)\big)
\, \mathrm{d}\lambda(x) 
+ \phi(0) \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{\overrightharp{q}}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{\overrightharp{p}}(x)\big)
\, \mathrm{d}\lambda(x)  
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle
- \phi_{+,c}^{\prime}  \big( 1 \big)  \cdot
\int_{{\mathcal{X}}} 
\big( \mathbbm{\overrightharp{p}}(x) - \mathbbm{\overrightharp{q}}(x) \big)
\, \mathrm{d}\lambda(x) \, 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
=
\int_{{\mathcal{X}}} 
 \mathbbm{\overrightharp{q}}(x) \cdot \phi  \big( {
\frac{\mathbbm{\overrightharp{p}}(x)}{\mathbbm{\overrightharp{q}}(x)}}\big) 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{\overrightharp{p}}(x) \cdot \mathbbm{\overrightharp{q}}(x)\big)
\, \mathrm{d}\lambda(x) 
\nonumber\\ 
& & \hspace{0.2cm} 
+ \phi^{*}(0) \cdot
\mathfrak{P}^{\mathbb{1}\cdot \lambda}[\mathbbm{\overrightharp{q}}(x) =0] 
+ \phi(0) \cdot 
\mathfrak{Q}^{\mathbb{1}\cdot \lambda}[\mathbbm{\overrightharp{p}}(x) =0] \, ;
\label{brostu2:fo.def.47d}
\end{eqnarray} 

\vspace{-0.2cm}

\noindent
if $\phi(1) \neq 0$ then one has to additionally subtract $\phi(1)$
(cf.\ the corresponding special case of \eqref{brostu2:fo.def.47btwo}).
In particular, for the special sub-setup where
for $\lambda-$almost all $x \in \mathcal{X}$ there holds
$\mathbbm{p}(x) := \mathbbm{\overrightharp{p}}(x) > 0$, 
$\mathbbm{q}(x) := \mathbbm{\overrightharp{q}}(x) > 0$,
$\mathbbm{r}(x) \equiv 1$ , $\phi(1) = 0$,
one ends up with 
the reduced Csiszar-Ali-Silvey
divergence 

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 \leq D^{c}_{\phi,\mathbb{\overrightharp{Q}},\mathbb{\overrightharp{Q}},\mathbb{1}\cdot \mathbb{\overrightharp{Q}},\lambda}(\mathbb{\overrightharp{P}},\mathbb{\overrightharp{Q}}) 
=
\int_{{\mathcal{X}}} 
 \mathbbm{\overrightharp{q}}(x) \cdot \phi  \big( {
\frac{\mathbbm{\overrightharp{p}}(x)}{\mathbbm{\overrightharp{q}}(x)}}\big) 
\, \mathrm{d}\lambda(x)
\nonumber 
\end{eqnarray} 

\vspace{-0.2cm}

\noindent
which can be interpreted as a ``consistent extension'' of
the motivating pointwise dissimilarity $d_{\phi}^{(7)}(\cdot,\cdot)$ 
from the introductory Section \ref{sec.1newb}; notice the fundamental structural
difference to the divergence 
\eqref{brostu2:fo.def.40var} which reflects $d_{\phi}^{(6)}(\cdot,\cdot)$.
For comprehensive treatments of statistical applications of CASD, 
the reader is referred to 
Liese \& Vajda~\cite{Lie:87},  Read \& Cressie~\cite{Rea:88}, Vajda~\cite{Vaj:89},
Pardo~\cite{Par:06}, Liese \& Miescke~\cite{Lie:08}, Basu et al.~\cite{Bas:11}.


\vspace{0.15cm}
\noindent
Returning to the general divergence 
setup 
\eqref{brostu2:fo.def.47b},
we derive the 
reflexivity result:

\begin{theorem}
\label{brostu2:thm.2CASD}
Let $c \in [0,1]$, $\mathbbm{r}(x) \in ]0,\infty[$ for $\lambda-$a.a. $x \in \mathcal{X}$,
$\mathcal{R}\big(\frac{P}{Q}\big) \cup \{1\} \subset [a,b]$,
and $\phi \in \Phi(]a,b[)$ be strictly convex at $t=1$. 
Moreover, suppose that  
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
\int_{{\mathcal{X}}} 
\big( \mathbbm{p}(x) - \mathbbm{q}(x) \big) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) \ = \ 0  
\label{brostu2:fo.AssuCASD1}
\end{eqnarray}
(but not necessarily 
$\int_{{\mathcal{X}}} p(x) \cdot r(x) \, \mathrm{d}\lambda(x)) < \infty$,
$\int_{{\mathcal{X}}} q(x) \cdot r(x) \, \mathrm{d}\lambda(x)) < \infty$).
Then:\\
(1) $D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q},\lambda}(\mathbbm{P},\mathbbm{Q})\geq 0$.
Depending on the concrete situation,\\[0.05cm]  
$D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q},\lambda}(\mathbbm{P},\mathbbm{Q})$ may take infinite value.

\vspace{-0.55cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
(2) \quad D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q},\lambda}(\mathbbm{P},\mathbbm{Q}) = 0 \quad
\textrm{if and only if} \quad 
\mathbbm{p}(x) = \mathbbm{q}(x) 
\ \textrm{for $\lambda-$a.a. $x \in \mathcal{X}$.} \qquad \ 
\label{brostu2:fo.reflex1CASD}
\end{eqnarray} 
\end{theorem}

\begin{remark}
\label{brostu2:rem.40c}
(a) In the context of non-negative measures, the special case $c=1$ --
together with $\int_{{\mathcal{X}}} p(x) \cdot r(x) \, \mathrm{d}\lambda(x)) < \infty$,
$\int_{{\mathcal{X}}} q(x) \cdot r(x) \, \mathrm{d}\lambda(x)) < \infty$ --
of Theorem \ref{brostu2:thm.2CASD} was first achieved by Stummer \& Vajda~\cite{Stu:10}.\\
(b) Assumption \eqref{brostu2:fo.AssuCASD1} is always automatically satisfied
if one has coincidence of finite total masses in the sense of
$\mathfrak{P}^{\mathbbm{R} \cdot \lambda}[\mathcal{X}]  = 
\int_{\mathcal{X}} \mathbbm{p}(x) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x)
= \int_{\mathcal{X}} \mathbbm{q}(x) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x)
=\mathfrak{Q}^{\mathbbm{R} \cdot \lambda}[\mathcal{X}] 
< \infty$. For $\mathbb{r}(x) \equiv 1$ this is always satisfied for
$\lambda-$probability densities $\mathbbm{p}(x) := \mathbbm{\overrightharp{p}}(x)$,
$\mathbbm{q}(x) := \mathbbm{\overrightharp{q}}(x)$,
since $\mathfrak{\overrightharp{P}}^{\mathbbm{1} \cdot \lambda}[\mathcal{X}]
= \mathfrak{\overrightharp{Q}}^{\mathbbm{1} \cdot \lambda}[\mathcal{X}] =1$.\\
(c) Notice that in contrast to Theorem \ref{brostu2:thm.2},
the generator-concerning Assumptions \ref{brostu2:assu.class1}(b) to (d)
are replaced by the ``model-concerning'' constraint
\eqref{brostu2:fo.AssuCASD1}.
This opens the gate for the use of the generators $\phi_{ie}$ and $\phi_{TV}$ 
for cases where \eqref{brostu2:fo.AssuCASD1} is satisfied. For the latter, we obtain
with $c = \frac{1}{2}$ explicitly from \eqref{brostu2:fo.def.45btwo} and \eqref{brostu2:fo.def.68e2}

\vspace{-0.6cm}

$$
\widetilde{\psi}_{\phi_{TV},\frac{1}{2}}\big(r,\widetilde{s},\widetilde{t}\big) := r \cdot \widetilde{t} \cdot \psi_{\phi_{TV},\frac{1}{2}}\big(\frac{\widetilde{s}}{\widetilde{t}},1\big)  
= r \cdot \widetilde{t} \cdot \big| \frac{\widetilde{s}}{\widetilde{t}} -1 \big|
= r \cdot \big| \widetilde{s} - \widetilde{t} \big| ,  
$$

\vspace{-0.2cm}

\enlargethispage{0.5cm}

\noindent
and hence from \eqref{brostu2:fo.def.47b} together with
$\phi_{TV}(1)=0$, $\phi_{TV}(0) = 1$ (cf. \eqref{brostu2:fo.def.68a0}),
$\phi_{TV,+,\frac{1}{2}}^{\prime}(1) =0$ (cf. \eqref{brostu2:fo.def.68b}),
$\phi_{TV}^{*}(0) = \lim_{s\rightarrow \infty} \frac{1}{s} \cdot \psi_{\phi_{TV},\frac{1}{2}}(s,1) = 1$
(cf. \eqref{brostu2:fo.def.68h}) 

\vspace{-0.5cm}
 
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q},\lambda}(\mathbbm{P},\mathbbm{Q}) 
=
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \big| \mathbbm{p}(x) - \mathbbm{q}(x) \big|
\, \mathrm{d}\lambda(x)  \, 
\label{brostu2:fo.def.111}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
which is nothing but the (possibly infinite) $L_{1}(\mathbbm{r}\cdot\lambda)-$distance between
the functions $x \rightarrow \mathbbm{p}(x)$ and $x \rightarrow \mathbbm{q}(x)$.\\
(d) \ In the light of \eqref{brostu2:fo.def.47btwo}, Theorem 
\ref{brostu2:thm.2} (adapted to the current context) and Theorem \ref{brostu2:thm.2CASD},
let us indicate that if one wants to use 
$\Xi := \int_{{\mathcal{X}}} 
\mathbbm{q}(x) \cdot \phi  \big( {
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}}\big)
\cdot \mathbbm{r}(x)  
\, \mathrm{d}\lambda(x) 
$ (with appropriate zero-conventions) as a divergence, then 
one should either employ generators $\phi$ satisfying $\phi(1)=\phi_{+,c}^{\prime}(1)=0$,
or employ models fulfilling the assumption \eqref{brostu2:fo.reflex1CASD} together with 
generators $\phi$ with $\phi(1)=0$. On the other hand, if this integral $\Xi$
appears in your application context ``naturally'',  
then one should be aware that 
$\Xi$ may become negative depending on the involved set-up;
for a counter-example, see Stummer \& Vajda~\cite{Stu:10}.
\end{remark}

\vspace{-0.1cm}

\noindent
\textbf{Proof of Theorem \ref{brostu2:thm.2CASD}.} 
Consistently
with Theorem 
\ref{brostu2:thm.1} (and our adaptions)
the ``if-part'' follows 
from \eqref{brostu2:fo.def.47b}.
By our above investigations on the adaptions of the Assumptions 2 to the current context, 
it remains to investigate 
the ``only-if'' part (2) for
the following four cases (recall that $\phi$ is strictly convex
at $t=1$):\\
$(ia)$ \ $\phi$ is differentiable at $t=1$ (hence, $c$ is obsolete
and $\phi_{+,c}^{\prime}(1)$ collapses to $\phi^{\prime}(1)$)
and the function $\phi$ is affine linear on $[1,s]$ for some 
$s \in \mathcal{R}\big(\frac{P}{Q}\big)\backslash[a,1]$;\\ 
$(ib)$ \ $\phi$ is differentiable at $t=1$, 
and the function $\phi$ is affine linear on $[s,1]$ for some 
$s \in \mathcal{R}\big(\frac{P}{Q}\big)\backslash[1,b]$;\\ 
$(ii)$ \ $\phi$ is not differentiable at  
$t=1$, $c=1$, and the function $\phi$ is affine linear on $[1,s]$ for some 
$s \in \mathcal{R}\big(\frac{P}{Q}\big)\backslash[a,1]$;\\
$(iii)$ \ $\phi$ is not differentiable at  
$t=1$, $c=0$, and the function $\phi$ is affine linear on $[s,1]$ for some 
$s \in \mathcal{R}\big(\frac{P}{Q}\big)\backslash[1,b]$.\\
It is easy to see from the strict convexity at $1$ that for
(ii) 
one has 
$\phi(0) + \phi_{+,1}^{\prime}(1) - \phi(1) >0$,
whereas for (iii) one gets $\phi^{*}(0) -\phi_{+,0}^{\prime}(1) >0$;
furthermore, for (ia) there holds 
$\phi(0) + \phi^{\prime}(1) - \phi(1) >0$ and for
(ib) $\phi^{*}(0) -\phi^{\prime}(1) >0$.
Let us first examine the situations (ia) respectively (ii) under the assumptive constraint 
$D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q},\lambda}(\mathbbm{P},\mathbbm{Q})= 0$
with $c=1$ respectively (in case of differentiability) obsolete $c$, 
for which we can deduce from \eqref{brostu2:fo.def.47b} 

\vspace{-0.6cm}

\enlargethispage{0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 = D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q},\lambda}(\mathbbm{P},\mathbbm{Q}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle  
\geq
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \big[ \mathbbm{q}(x) \cdot \phi  \big( {
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}}\big) - \mathbbm{q}(x) \cdot \phi  \big( 1 \big)
- \phi_{+,c}^{\prime} 
\big( 1 \big) \cdot \big( \mathbbm{p}(x) - \mathbbm{q}(x) \big) 
\big] 
\, 
\nonumber \\[-0.1cm] 
& & \hspace{6.5cm} 
\cdot 
\boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x)  
\big)
\cdot \boldsymbol{1}_{]\mathbbm{p}(x),\infty[}\big(\mathbbm{q}(x) 
\big)
\, \mathrm{d}\lambda(x) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\big[ \phi(0) + \phi_{+,c}^{\prime}(1) - \phi(1) \big] \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big)
\cdot \boldsymbol{1}_{]\mathbbm{p}(x),\infty[}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x)  \, \geq 0 ,
\nonumber  
\end{eqnarray}

\vspace{-0.1cm}

\noindent
and hence $\int_{{\mathcal{X}}} \boldsymbol{1}_{]\mathbbm{p}(x),\infty[}\big(\mathbbm{q}(x)\big)
\cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x)  \, = 0$.
From this and \eqref{brostu2:fo.AssuCASD1} we obtain

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
0 = \int_{{\mathcal{X}}} 
\big( \mathbbm{p}(x) - \mathbbm{q}(x) \big) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) \ = \ 
\int_{{\mathcal{X}}} 
\big( \mathbbm{p}(x) - \mathbbm{q}(x) \big)  
\cdot \boldsymbol{1}_{]\mathbbm{q}(x),\infty[}\big(\mathbbm{p}(x)\big)
\cdot \mathbbm{r}(x)
\, \mathrm{d}\lambda(x) \qquad \ \ 
\nonumber  
\end{eqnarray}

\vspace{-0.2cm}

\noindent
and therefore $\int_{{\mathcal{X}}} \boldsymbol{1}_{]\mathbbm{q}(x),\infty[}\big(\mathbbm{p}(x)\big)
\cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x)  \, = 0$. Since for $\lambda-$a.a. $x\in \mathcal{X}$ 
we have $\mathbbm{r}(x) >0$, we arrive at $\mathbbm{p}(x) =\mathbbm{p}(x)$ for $\lambda-$a.a. $x\in \mathcal{X}$.
The remaining cases (ib) respectively (iii) can be treated analogously. 
\hspace{0.4cm} 
$\square$


\vspace{0.15cm}
\noindent
As an important example, we illuminate 
the special case  
$\phi = \phi_{\alpha}$ with 
$\alpha \in \mathbb{R}\backslash\{0,1\}$
(cf. \eqref{brostu2:fo.def.32})
under the constraint $(\mathfrak{P}^{\mathbbm{R}\cdot \lambda}-\mathfrak{Q}^{\mathbbm{R}\cdot \lambda})[\mathcal{X}] 
= \int_{{\mathcal{X}}}  \big( \mathbbm{p}(x) - \mathbbm{q}(x) \big) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) \in [0, \infty[$.
Accordingly, the ``implicit-boundary-describing'' divergence \eqref{brostu2:fo.def.45b}
resp. the corresponding  ``explicit-boundary'' version \eqref{brostu2:fo.def.47c} turn into
the generalized power divergences of order $\alpha$
(cf. Stummer \& Vajda~\cite{Stu:10} for $\mathbbm{r}(x) \equiv 1$)

\vspace{-0.6cm}
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D_{\phi_{\alpha},\mathbbm{Q},\mathbbm{Q},\mathbbm{R}\cdot \mathbbm{Q},\lambda}(\mathbbm{P},\mathbbm{Q}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
=
\olint_{{\mathcal{X}}}
\frac{1}{\alpha \cdot (\alpha-1)} \cdot
\Big[ \big( {
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}}\big)^{\alpha} - \alpha \cdot \frac{\mathbbm{p}(x)}{\mathbbm{q}(x)} + \alpha -1 
\Big] 
\cdot \mathbbm{q}(x) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) 
\label{brostu2:fo.def.632a}
\\ 
& & \hspace{-0.2cm}   \textstyle 
= \frac{1}{\alpha \cdot (\alpha-1)} 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \mathbbm{q}(x) \cdot \Big[ \big( {
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}}\big)^{\alpha} - \alpha \cdot \frac{\mathbbm{p}(x)}{\mathbbm{q}(x)} + \alpha -1 
\Big] 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) 
\big)
\, \mathrm{d}\lambda(x) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \phi_{\alpha}^{*}(0) \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{p}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x) 
+ \phi_{\alpha}(0) \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big)
\, \mathrm{d}\lambda(x)  
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
= \frac{1}{\alpha \cdot (\alpha-1)} 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \Big[ 
\mathbbm{p}(x)^{\alpha} \cdot \mathbbm{q}(x)^{1-\alpha} -  \mathbbm{q}(x)
\Big] 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) 
\big)
\, \mathrm{d}\lambda(x)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \frac{1}{1-\alpha} \cdot \int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot (\mathbbm{p}(x) - \mathbbm{q}(x)) \, \mathrm{d}\lambda(x)
+ \infty \cdot \boldsymbol{1}_{]1,\infty[}(\alpha) \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{p}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x)
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ \big(\frac{1}{\alpha \cdot (1-\alpha)} \cdot \boldsymbol{1}_{]0,1] \cup ]1,\infty[}(\alpha)
+ \infty \cdot \boldsymbol{1}_{]-\infty,0[}(\alpha) \big) \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big)
\, \mathrm{d}\lambda(x) , \qquad \
\nonumber  
\end{eqnarray}

\vspace{-0.2cm}

\noindent
where we have employed \eqref{brostu2:fo.def.33d} and \eqref{brostu2:fo.def.33b};
especially, one gets for $\alpha=2$

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 \leq D_{\phi_{2},\mathbbm{Q},\mathbbm{Q},\mathbbm{R}\cdot \mathbbm{Q},\lambda}(\mathbbm{P},\mathbbm{Q}) 
= \olint_{{\mathcal{X}}}
\frac{1}{2} \cdot
\frac{(\mathbbm{p}(x) - \mathbbm{q}(x))^2}{\mathbbm{q}(x)} \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) 
\nonumber 
\\ 
& & \hspace{-0.2cm}   \textstyle 
= \frac{1}{2} 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \frac{(\mathbbm{p}(x) - \mathbbm{q}(x))^2}{\mathbbm{q}(x)}
\cdot \boldsymbol{1}_{[0,\infty[}(\mathbbm{p}(x))
\cdot \boldsymbol{1}_{]0,\infty[}(\mathbbm{q}(x))
\, \mathrm{d}\lambda(x) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \infty \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{p}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x) \ .
\nonumber
\end{eqnarray}

\vspace{-0.2cm}

\enlargethispage{0.5cm}

\noindent
which is called Pearsons's chisquare divergence. 
Under the same constraint 
$(\mathfrak{P}^{\mathbbm{R}\cdot \lambda}-\mathfrak{Q}^{\mathbbm{R}\cdot \lambda})[\mathcal{X}]  
\in [0, \infty[$,
the case $\alpha=1$ leads by \eqref{brostu2:fo.def.120b}, \eqref{brostu2:fo.def.125a}, 
\eqref{brostu2:fo.def.125b}, \eqref{brostu2:fo.def.125d} to the 
generalized Kullback-Leibler divergence (generalized relative entropy)

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 \leq D_{\phi_{1},\mathbbm{Q},\mathbbm{Q},\mathbbm{R}\cdot \mathbbm{Q},\lambda}(\mathbbm{P},\mathbbm{Q}) 
= \olint_{{\mathcal{X}}}
\Big[ 
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)} \cdot \log \big( {\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}} \big) 
+ 1 - \frac{\mathbbm{p}(x)}{\mathbbm{q}(x)} 
\Big] 
\cdot \mathbbm{q}(x) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) \qquad \ 
\nonumber  
\\ 
& & \hspace{-0.2cm}   \textstyle 
= \int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \mathbbm{p}(x) \cdot \log \big( {\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}} \big) 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) 
\big)
\, \mathrm{d}\lambda(x) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot (\mathbbm{q}(x) - \mathbbm{p}(x)) \, \mathrm{d}\lambda(x) 
+ \infty \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{p}(x) \cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x)  \qquad \ 
\nonumber 
\end{eqnarray}

\vspace{-0.1cm}

\noindent
(which equals \eqref{brostu2:fo.def.140b}), and for $\alpha=0$ one gets from 
\eqref{brostu2:fo.def.120d},\eqref{brostu2:fo.def.127a},\eqref{brostu2:fo.def.127b},\eqref{brostu2:fo.def.127d} the 
generalized reverse Kullback-Leibler divergence (generalized reverse relative entropy)

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 \leq D_{\phi_{0},\mathbbm{Q},\mathbbm{Q},\mathbbm{R}\cdot \mathbbm{Q},\lambda}(\mathbbm{P},\mathbbm{Q}) 
= \olint_{{\mathcal{X}}}
\big[ 
- \log \big( {\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}} \big) 
+ \frac{\mathbbm{p}(x)}{\mathbbm{q}(x)} - 1 
\big] 
\cdot \mathbbm{q}(x) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x)  \qquad \ 
\nonumber  
\\ 
& & \hspace{-0.2cm}   \textstyle 
= 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \mathbbm{q}(x) \cdot \log \big( {\frac{\mathbbm{q}(x)}{\mathbbm{p}(x)}} \big)  
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) 
\big)
\, \mathrm{d}\lambda(x) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot (\mathbbm{p}(x) - \mathbbm{q}(x)) \, \mathrm{d}\lambda(x)
+ \infty \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x) \cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big)
\, \mathrm{d}\lambda(x) . \qquad \
\nonumber  
\end{eqnarray} 

\vspace{-0.1cm}

\noindent
Notice that instead of the limit in \eqref{brostu2:fo.def.45bthree}
one could also use the convention 
$r \cdot 0 \cdot \psi_{\phi}\big(\frac{s}{0},1\big) 
: = \widetilde{\psi}_{\phi}\big(r,s,0\big) := 0$;
in the context of $\lambda-$probability densities, one then ends up with divergence
by R{\"u}schendorf~\cite{Rue:84}. 

\vspace{0.15cm}
\noindent
For the discrete setup $(\mathcal{X},\lambda) = (\mathcal{X}_{\#},\lambda_{\#})$,  
the divergence in \eqref{brostu2:fo.def.47bdisc} simplifies to

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q},\lambda_{\#}}(\mathbbm{P},\mathbbm{Q}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
=
\sum_{x \in \mathcal{X}} 
\mathbbm{r}(x)  \cdot \big[ \mathbbm{q}(x) \cdot \phi  \big( {
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}}\big) - \mathbbm{q}(x) \cdot \phi  \big( 1 \big)
- \phi_{+,c}^{\prime} 
\big( 1 \big) \cdot \big( \mathbbm{p}(x) - \mathbbm{q}(x) \big) 
\big] 
\,  
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) 
\big)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \big[ \phi^{*}(0) -\phi_{+,c}^{\prime}(1) \big] \cdot
\sum_{x \in \mathcal{X}}  
\mathbbm{r}(x) \cdot \mathbbm{p}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\big[ \phi(0) + \phi_{+,c}^{\prime}(1) - \phi(1) \big] \cdot 
\sum_{x \in \mathcal{X}}  
\mathbbm{r}(x) \cdot \mathbbm{q}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big) \, .
\label{brostu2:fo.def.47bdisc}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
which in case of $\phi(1)=\phi_{+,c}^{\prime}(1)=0$
-- respectively $\phi(1)=0$ and \eqref{brostu2:fo.reflex1CASD} -- turns into

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 \leq D^{c}_{\phi, \mathbbm{Q}, \mathbbm{Q}, \mathbbm{R}\cdot  \mathbbm{Q},\lambda_{\#}}(\mathbbm{P}, \mathbbm{Q}) 
=
\sum_{{x \in \mathcal{X}}} 
 \mathbbm{q}(x) \cdot \phi  \big( {
\frac{ \mathbbm{p}(x)}{ \mathbbm{q}(x)}}\big)
\cdot 
 \mathbbm{r}(x)  \ . 
\label{brostu2:fo.def.45cdis}
\end{eqnarray}

\vspace{0.0cm}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\noindent
\textbf{
3.3.1.3  \ \
$\mathbf{m_{1}(x) = m_{2}(x) := w(p(x),q(x))}$, 
$\mathbf{\mathbbm{m}_{3}(x) = r(x) \cdot w(p(x),q(x)) \in [0, \infty[}$ for some
(measurable) functions
$\mathbf{w: \mathcal{R}(P) \times \mathcal{R}(Q) \rightarrow \mathbb{R}}$
and $\mathbf{r: \mathcal{X} \rightarrow \mathbb{R}}$
}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{0.15cm}
\noindent

\vspace{0.15cm}
\noindent
Such a choice extends the context of the previous Subsection 3.3.1.2
where the ``connector function'' $w$ took the simple form $w(u,v) = v$,
as well as the setup of Subsection 3.3.1.1 dealing with constant $w(u,v) \equiv 1$.
This introduces a wide flexibility with divergences of the form

\vspace{-0.55cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D^{c}_{\phi,W(P,Q),W(P,Q),R\cdot W(P,Q),\lambda}(P,Q) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
: =
\olint_{{\mathcal{X}}} 
\Big[ \phi  \big( {
\frac{p(x)}{w(p(x),q(x))}}\big) -\phi  \big( {\frac{q(x)}{w(p(x),q(x))}}\big)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle  
- \phi_{+,c}^{\prime} 
\big( {\frac{q(x)}{w(p(x),q(x))}}\big) \cdot \big( \frac{p(x)}{w(p(x),q(x))}-\frac{q(x)}{w(p(x),q(x))}\big) 
\Big] 
\cdot w(p(x),q(x)) \cdot r(x) \, \mathrm{d}\lambda(x) \ , \qquad \ 
\label{brostu2:fo.def.755a}
\end{eqnarray}

\vspace{-0.1cm}

\enlargethispage{0.5cm}

\noindent
which for the discrete setup 
$(\mathcal{X},\lambda) = (\mathcal{X}_{\#},\lambda_{\#})$ 
(recall $\lambda_{\#}[\{x\}] =1$ for all $x \in \mathcal{X}_{\#}$) 
simplifies to

\vspace{-0.5cm}

\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D^{c}_{\phi,W(P,Q),W(P,Q),R\cdot W(P,Q),\lambda_{\#}}(P,Q)  =
\olsum_{{x \in \mathcal{X}}} 
\Big[ \phi  \big( {
\frac{p(x)}{w(p(x),q(x))}}\big) -\phi  \big( {\frac{q(x)}{w(p(x),q(x))}}\big)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle  
- \phi_{+,c}^{\prime} 
\big( {\frac{q(x)}{w(p(x),q(x))}}\big) \cdot \big( \frac{p(x)}{w(p(x),q(x))}-\frac{q(x)}{w(p(x),q(x))}\big) 
\Big] 
\cdot w(p(x),q(x)) \cdot r(x) \ . 
\label{brostu2:fo.def.755b}
\end{eqnarray}

\vspace{-0.1cm}

\noindent
A detailed discussion of this wide class of divergences \eqref{brostu2:fo.def.755a},\eqref{brostu2:fo.def.755b} 
is beyond the scope of this paper.
For the $\lambda-$probability density context (and an indication for more general functions), 
see the comprehensive paper of Kisslinger \& Stummer~\cite{Kis:16} and the references therein.
Finally, 
by appropriate choices of $w(\cdot,\cdot)$ we can even derive 
divergences of the form \eqref{brostu2:fo.def.45cdis}
but with non-convex non-concave $\phi$: see e.g. 
the ``perturbed'' power divergences of
Roensch \& Stummer~\cite{Roe:17}.

\vspace{0.25cm}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\noindent
\textbf{
3.3.2  \ \
Global scaling and aggregation, and other paradigms
}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{0.15cm}
\noindent
Our universal framework also contains, as special cases, 
scaling and aggregation functions of the form
$m_{i}(x) := m_{\ell,i}(x) \cdot H_{i}\big( ( m_{g,i}(z) )_{z \in \mathcal{X}} \big)$
for some (meas., possibly nonnegative) functions $m_{l,i}:\mathcal{X} \mapsto \mathbb{R}$, 
$m_{g,i}:\mathcal{X} \mapsto \mathbb{R}$
and some 
nonzero scalar functionals $H_{i}$ thereupon
($i=1,2,3$, $x \in \mathcal{X}$). 
Accordingly,  the components $H_{i}\big( \ldots \big)$ can be viewed as ``global tunings'', and may
depend adaptively on the primary-interest functions $P$ and $Q$, i.e.
$m_{g,i}(z) = w_{g,i}(x,p(x),q(x))$. For instance,
in a finite discrete setup $(\mathcal{X}_{\#},\lambda_{\#})$
with strictly convex and differentiable $\phi$, $m_{1}(x) \equiv m_{2}(x) \equiv 1$,
$m_{3}(x)= H_{i} \big( (w_{g,3}(q(x)) )_{z \in \mathcal{X}} \big)$
this reduces to the conformal divergences of Nock et al.~\cite{Noc:16b}
(they also indicate the extension to equal non-unity scaling $m_{1}(x) \equiv m_{2}(x)$),
for which the subcase $w_{g,3}(q(x)) :=  \left(\phi^{\prime} \negthinspace 
\left( q(x)\right) \right)^2$,  
$H_{3}\left( \big( h(x) \right)_{x \in \mathcal{X}} \big)
:= \big(1+ \sum_{x \in \mathcal{X}} h(x)\big)^{-1/2}$
leads to the total Bregman divergences of Liu et al.~\cite{Liu:10},\cite{Liu:12},  
Vemuri et al.~\cite{Ver:11a}. In contrast,
Nock et al.~\cite{Noc:16a} use
$m_{1}(x) \equiv m_{1} = H_{1} \big( (p(x))_{z \in \mathcal{X}} \big)$,
$m_{2}(x) \equiv m_{1} = H_{1} \big( (q(x))_{z \in \mathcal{X}} \big)$, 
$m_{3}(x) \equiv 1$.
A more detailed discussion can be found in Stummer \& Ki{\ss}linger~\cite{Stu:17a}
and Roensch \& Stummer~\cite{Roe:17},
where they also give versions for nonconvex nonconcave divergence generators.
Let us finally mention that for the construction 
of divergence families, there are other recent paradigms which are 
essentially different to \eqref{brostu2:fo.def.1},
e.g. by means of measuring the tightness of inequalities
(cf. Nielsen et al.~\cite{Nie:17c},\cite{Nie:17d}),
respectively of comparative convexity (cf. Nielsen et al.~\cite{Nie:17b}).

\vspace{-0.35cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Divergences for essentially different functions}
\label{sec.4anew}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.25cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Motivation}
\label{subsec.4anew.1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.1cm}

Especially in divergence-based statistics, one is often faced with the
situation where the functions $p(\cdot)$ and $q(\cdot)$
are of ``essentially different nature''.
For instance, 
consider the situation where the
uncertainty-prone data-generating mechanism is a random variable 
$Y$ taking values in $\mathcal{X}=\mathbb{R}$
having a ``classical'' (e.g. Gaussian) probability density $\mathbbm{\overrightharp{q}}(\cdot)$
with respect to the one-dimensional Lebesque measure $\lambda_{L}$,e
i.e. $Pr[ Y \in \, \bullet \, ]  := 
\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{L}}[\bullet] 
: = \int_{\bullet} \mathbbm{\overrightharp{q}}(x) \, \mathrm{d}\lambda_{L}(x)$ 
where the latter is almost always a Riemann integral 
(i.e. $\mathrm{d}\lambda_{L}(x) = \mathrm{d}x$); notice that we have
set $\mathbbm{r}(x)  \equiv 1$ ($x \in \mathbb{R}$). 
As already indicated above, under independent and identically distributed (i.i.d.) 
data observations
$Y_1, \ldots, Y_N$ of $Y$ one often builds 
the corresponding 
``empirical distribution'' 
$\mathfrak{\overrightharp{P}}_{N}^{emp}[\bullet] 
:= \frac{1}{N} \cdot \sum_{i=1}^{N}   \delta_{Y_{i}}[\bullet]$
which 
is nothing but the probability distribution reflecting the underlying
(normalized) histogram. 
By rewriting
$\mathfrak{\overrightharp{P}}^{\mathbb{1}\cdot \lambda_{\#}}[\bullet]:=
\mathfrak{\overrightharp{P}}_{N}^{emp}[\bullet]
= \int_{\bullet}  \mathbbm{\overrightharp{p}}(x) \, \mathrm{d}\lambda_{\#}(x)$
with empirical probability mass function
$\mathbbm{\overrightharp{p}}(x) : = 
\frac{1}{N} \cdot \# \{ i \in \{ 1, \ldots, N\}: Y_i =x \} 
=: \mathbbm{\overrightharp{p}}_{N}^{emp}(x) $
one encounters some basic problems for 
a straightforward
application of divergence concepts: 
the two aggregating measures $\lambda_{L}$ and 
$\lambda_{\#}$ do not coincide and actually
they are of ``essentially different'' nature;
moreover,  
$\mathbbm{\overrightharp{p}}(\cdot)$ is nonzero only on 
the range $\mathcal{R}(Y_{1}, \ldots, Y_{N}) = \{ z_1, \ldots, z_s \}$
of distinguishable points $z_1, \ldots, z_s$ ($s \leq N$)
occupied by $Y_{1}, \ldots, Y_{N}$. In particular, 
one has $\lambda_{L}[ \{ z_1, \ldots, z_s \} ] = 0$.
Accordingly, building a 
``non-coarsely discriminating''
dissimilarity/divergence 
$D(\mathbbm{\overrightharp{P}},\mathbbm{\overrightharp{Q}})$ between 
such type of functions $\mathbbm{\overrightharp{P}} := \big\{\mathbbm{\overrightharp{p}}(x)\big\}_{x \in \mathcal{X}}$
and $\mathbbm{\overrightharp{Q}} := \big\{\mathbbm{\overrightharp{q}}(x)\big\}_{x \in \mathcal{X}}$,
is  a task like ``comparing apples with pears''. 
There are several solutions to tackle this. 
To begin with, in the following we take the ``encompassing''
approach of quantifying their dissimilarity by means of their
common superordinate characteristics as ``fruits''. 
Put in mathematical terms, we choose e.g. 
$\mathcal{X}= \mathbb{R}$,
$\lambda = \lambda_{L} + \lambda_{\#}$ and work with the particular representations
$\mathbbm{\overrightharp{p}}(x) := 
\widetilde{\overrightharp{p}}(x) \cdot  \boldsymbol{1}_{\{ z_1, \ldots, z_s \}}(x)$
with $\widetilde{\overrightharp{p}}(x) > 0 $ for 
$\lambda-$ almost all 
$x \in \{ z_1, \ldots, z_s \}$
as well as
$\mathbbm{\overrightharp{q}}(x) := 
\widetilde{\overrightharp{q}}(x) \cdot  \boldsymbol{1}_{\widetilde{A} \backslash \{z_1, \ldots, z_s \}}(x)$
with $\widetilde{\overrightharp{q}}(x) > 0 $ for 
$\lambda-$ almost all $x \in \widetilde{A} \backslash \{z_1, \ldots, z_s \}$
with some large enough (measurable) subset $\widetilde{A}$ of $\mathcal{X} = \mathbb{R}$ such that 

\vspace{-0.6cm}

\enlargethispage{0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
1= \int_{\mathcal{X}} 
\mathbbm{\overrightharp{p}}(x)
\, \mathrm{d}\lambda_{\#}(x)
= \int_{\mathcal{X}} 
\mathbbm{\overrightharp{p}}(x)
\, \mathrm{d}\lambda(x)  
\  \textrm{and} \ 
1= \int_{\mathcal{X}} 
\mathbbm{\overrightharp{q}}(x)
\, \mathrm{d}\lambda_{L}(x)
= \int_{\mathcal{X}} 
\mathbbm{\overrightharp{q}}(x)
\, \mathrm{d}\lambda(x) \qquad \ \ 
\label{brostu2:fo.Sing.0} 
\end{eqnarray} 

\vspace{-0.2cm}

\noindent
hold.
In fact, with these choices one gets
$Pr[ Y \in \, \bullet \, ]  
 = \int_{\bullet} \mathbbm{\overrightharp{q}}(x) \, \mathrm{d}\lambda(x)$
and  
$\mathfrak{\overrightharp{P}}_{N}^{emp}[\bullet]
= \int_{\bullet}  \mathbbm{\overrightharp{p}}(x) \, \mathrm{d}\lambda(x)$,
as well as

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
\mathbbm{p}(x) 
\cdot \mathbbm{q}(x) = 0 \quad \textrm{for 
$\lambda-$ almost all 
$x \in \mathcal{X}$},
\label{brostu2:fo.Sing.1}
\\
& & \hspace{-0.2cm}   \textstyle
\mathbbm{p}(x)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
=\mathbbm{p}(x) \quad  \textrm{for 
$\lambda-$ almost all 
$x \in \mathcal{X}$},
\label{brostu2:fo.Sing.2}
\\
& & \hspace{-0.2cm}   \textstyle
\mathbbm{q}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big)
=\mathbbm{q}(x) \quad  \textrm{for 
$\lambda-$ almost all 
$x \in \mathcal{X}$}
\label{brostu2:fo.Sing.3}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
for the special choices 
$\mathbbm{p}(x) = \mathbbm{\overrightharp{p}}(x)$ and
$\mathbbm{q}(x) = \mathbbm{\overrightharp{q}}(x)$.
By means of these and \eqref{brostu2:fo.Sing.0}, the divergence \eqref{brostu2:fo.def.47b}
simplifies to

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D^{c}_{\phi,\mathbbm{\overrightharp{Q}},\mathbbm{\overrightharp{Q}},\mathbb{1}\cdot \mathbbm{\overrightharp{Q}},\lambda}(\mathbbm{\overrightharp{P}},\mathbbm{\overrightharp{Q}}) 
= \phi^{*}(0) + \phi(0)  - \phi(1)  \ > \ 0  .
\label{brostu2:fo.Sing.4}
\end{eqnarray}

\vspace{-0.2cm}
\noindent
Since for arbitrary space $\mathcal{X}$ (and not only $\mathbb{R}$) 
and any aggregator $\lambda$ thereupon, 
the formula \eqref{brostu2:fo.Sing.4} holds for all
functions
$\mathbbm{\overrightharp{P}} := \big\{\mathbbm{\overrightharp{p}}(x)\big\}_{x \in \mathcal{X}}$,
$\mathbbm{\overrightharp{Q}} := \big\{\mathbbm{\overrightharp{q}}(x)\big\}_{x \in \mathcal{X}}$
which satisfy \eqref{brostu2:fo.Sing.0} as well as 
\eqref{brostu2:fo.Sing.1} to \eqref{brostu2:fo.Sing.3}
for $\lambda-$almost all $x \in \mathcal{X}$,
and since $\phi^{*}(0) + \phi(0)  - \phi(1)$ is just a constant (which may be infinite),
these 
divergences $D^{c}_{\phi,\mathbbm{\overrightharp{Q}},\mathbbm{\overrightharp{Q}},\mathbb{1}\cdot \mathbbm{\overrightharp{Q}},\lambda}(\mathbbm{\overrightharp{P}},\mathbbm{\overrightharp{Q}})$
are not suitable for discriminating between
such ``essentially different'' (basically orthogonal) $\lambda-$probability densities 
$\mathbbm{\overrightharp{P}}$
and $\mathbbm{\overrightharp{Q}}$. 
More generally, under the validity of 
\eqref{brostu2:fo.Sing.1} to \eqref{brostu2:fo.Sing.3}
for $\lambda-$almost all $x \in \mathcal{X}$ --
which we denote by $\mathbbm{P} \perp \mathbbm{Q}$ and which basically amounts to pair of functions of the type

\vspace{-0.5cm}

\begin{eqnarray} 
\hspace{-0.2cm}   \textstyle 
\mathbbm{p}(x) := 
\widetilde{p}(x) \cdot  \boldsymbol{1}_{A}(x) \quad 
\textrm{with $\widetilde{p}(x) > 0 $ for $\lambda-$ almost all $x \in A$},
\label{brostu2:fo.Sing.22}
\\
\hspace{-0.2cm}   \textstyle 
\mathbbm{q}(x) := 
\widetilde{q}(x) \cdot  \boldsymbol{1}_{B \backslash A}(x)
\quad \textrm{with $\widetilde{q}(x) > 0 $ for $\lambda-$ almost all $x \in B \backslash A$},
\label{brostu2:fo.Sing.22b}
\end{eqnarray}  

\vspace{-0.2cm}

\noindent
with some (measurable) subsets $\widetilde{A} \subset B$ of $\mathcal{X}$
--  the divergence \eqref{brostu2:fo.def.47b} turns into

\vspace{-0.6cm}

\begin{eqnarray} 
\hspace{-0.2cm}   \textstyle 
D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q},\lambda}(\mathbbm{P},\mathbbm{Q}) 
& = &
 \big[ \phi^{*}(0) -\phi_{+,c}^{\prime}(1) \big] \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{p}(x) 
\, \mathrm{d}\lambda(x)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\big[ \phi(0) + \phi_{+,c}^{\prime}(1) - \phi(1) \big] \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x) 
\, \mathrm{d}\lambda(x)  \ > \ 0 \qquad 
\label{brostu2:fo.Sing.5}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
which now depends on $\mathbbm{P}$ and $\mathbbm{Q}$, in a rudimentary ``weighted-total-mass'' way;
Inspired by this, we specify a
statistically interesting divergence subclass:


\vspace{-0.1cm}

\enlargethispage{0.5cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{definition}
\label{brostu2:def.encomp}
(a) \ We say that a divergence (respectively dissimilarity respectively distance)
\footnote{i.e. the properties (D1) and (D2) (respectively (D2) respectively (D1), (D2) and (D3) are satisfied}
 $D(\cdot,\cdot)$
is \textrm{encompassing for a class $\widetilde{\mathcal{P}}$ of functions} if 

\vspace{-0.3cm}

\begin{itemize}
\item for arbitrarily fixed $Q := \big\{q(x)\big\}_{x \in \mathcal{X}} \in \widetilde{\mathcal{P}}$ 
the function
$P := \big\{p(x)\big\}_{x \in \mathcal{X}} \rightarrow D(P,Q)$
is non-constant on the subfamily of all $P \in \widetilde{\mathcal{P}}$  with $P \perp Q$, and
\item for arbitrarily fixed $P  \in \widetilde{\mathcal{P}}$ the function
$Q \rightarrow D(P,Q)$
is non-constant on the subfamily of all  $Q \in \widetilde{\mathcal{P}}$ with $Q \perp P$.
\end{itemize}

\end{definition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.1cm}

\noindent
Accordingly, due to \eqref{brostu2:fo.Sing.4}  
the prominently used divergences 
$D^{c}_{\phi,\mathbbm{\overrightharp{Q}},\mathbbm{\overrightharp{Q}},\mathbb{1}\cdot \mathbbm{\overrightharp{Q}},\lambda}(\mathbbm{\overrightharp{P}},\mathbbm{\overrightharp{Q}})$
are not encompassing for the class of $\widetilde{\mathcal{P}}$ of all $\lambda-$probability densities; 
more generally, because of \eqref{brostu2:fo.Sing.5} the divergences
$D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q},\lambda}(\mathbbm{P},\mathbbm{Q})$ 
are in general encompassing for the class of $\widetilde{\mathcal{P}}$ of all $\lambda-$probability densities,
but not for $\widetilde{\mathcal{P}}:= \{ \widetilde{P} := \big\{\widetilde{\mathbbm{p}}(x)\big\}_{x \in \mathcal{X}} \, | \, 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \widetilde{\mathbbm{p}}(x) 
\, \mathrm{d}\lambda(x) = \widetilde{c} \, \}$  for any fixed $\widetilde{c}$. 

\vspace{-0.2cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{$\mathbf{\mathbbm{m}_{1}(x) = \mathbbm{m}_{2}(x) := \mathbbm{q}(x)}$, 
$\mathbf{\mathbbm{m}_{3}(x) = \mathbbm{r}(x) \cdot \mathbbm{q}(x)^{\chi} \in [0, \infty]}$ for 
$\chi>1$ and some
(measurable) function $\mathbf{\mathbbm{r}: \mathcal{X} \rightarrow [0,\infty[}$ }
\label{subsec.4anew.2}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\vspace{-0.05cm}

\noindent
In the following, we propose a new way of repairing the above-mentioned 
encompassing-concerning deficiency for
$\lambda-$probability density functions, by introducing a new divergence in terms of choosing
a generator $\phi: ]0,\infty[  \rightarrow \mathbb{R}$ which is convex and 
strictly convex at 
$1$, 
the scaling function $\mathbbm{m}_{1}(x) = \mathbbm{m}_{2}(x) := \mathbbm{q}(x)$ as in the
non-negativity set-up of Subsection 3.3.1.2,
but the more general aggregation function $\mathbbm{m}_{3}(x) = \mathbbm{r}(x) \cdot 
\mathbbm{q}(x)^{\chi} \in [0, \infty[$ for some
power $\chi >1$ and some
(measurable) function $\mathbbm{r} : \mathcal{X} \rightarrow [0,\infty[$
which satisfies $\mathbbm{r}(x) \in ]0,\infty[$ for $\lambda-$almost all $x \in \mathcal{X}$.
To incorporate the zeros of $\mathbbm{p}(\cdot),\mathbbm{q}(\cdot),\mathbbm{r}(\cdot)$
by appropriate limits and conventions, we proceed analogously to Subsection 3.3.1.2.
Accordingly, we inspect the boundary behaviour of
the function $\widetilde{\psi}_{\phi,c}: ]0,\infty[^3 \rightarrow [0,\infty[$ given by

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\widetilde{\psi}_{\phi,c}\big(r,\widetilde{s},\widetilde{t}\big) := r \cdot \widetilde{t}^{\chi} \cdot \psi_{\phi,c}\big(\frac{\widetilde{s}}{\widetilde{t}},1\big) = 
r \cdot \widetilde{t}^{\chi} \cdot  \big[ \phi\big(\frac{\widetilde{s}}{\widetilde{t}}\big) - \phi(1) - \phi_{+,c}^{\prime}(1) \cdot \big(\frac{\widetilde{s}}{\widetilde{t}}-1 \big) 
\big ] \ 
\nonumber \\  
& & \hspace{-0.2cm}   \textstyle
= r \cdot \widetilde{t}^{\chi} \cdot  \big[ \phi\big(\frac{\widetilde{s}\cdot r}{\widetilde{t} \cdot r}\big) - \phi(1) - \phi_{+,c}^{\prime}(1) 
\cdot \big(\frac{\widetilde{s} \cdot r}{\widetilde{t} \cdot r}-1 \big) 
\big ] \ 
= r \cdot \widetilde{t}^{\chi} \cdot \psi_{\phi,c}\big(\frac{\widetilde{s} \cdot r}{\widetilde{t} \cdot r},1\big) . \qquad \ \
\nonumber  
\end{eqnarray}

\vspace{-0.2cm}

\noindent
As in Subsection 3.3.1.2, the Assumption \ref{brostu2:assu.class1}(a) 
is conformly satisfied, for which
we use the short-hand notation $2(a)$ etc. in the following discussion.
Moreover, we require the validity of 2(b) to 2(d) at the point $t=1$.
The analogue of 2(e)
is $\mathbbm{r}(x) \cdot \widetilde{t}^{\chi} < \infty$ which is always (almost surely) automatically satisfied (a.a.sat.),
whereas 2(f) converts to ``$\mathbbm{r}(x) \cdot \widetilde{t}^{\chi} > 0$ for all $\widetilde{s} \ne \widetilde{t}$''
which is also a.a.sat. except for the case $\widetilde{t} =0$ which will be 
incorporated below.
For the derivation of the analogue of 2(k)
we observe that for fixed $r >0$, $\widetilde{s} >0$ 

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\ell i_{2} := r \cdot 0^{\chi} \cdot \psi_{\phi,c}\big(\frac{\widetilde{s}}{0},1\big) 
: = \lim_{t\rightarrow 0} \widetilde{\psi}_{\phi,c}\big(r,\widetilde{s},\widetilde{t}\big) =  
\nonumber \\  
& & \hspace{-0.2cm}   \textstyle
=  r \cdot \widetilde{s}^{\chi} \cdot \lim_{\widetilde{t}\rightarrow 0}
 \big[ \frac{\widetilde{t}^{\chi}}{\widetilde{s}^{\chi}} \cdot \phi\big(\frac{\widetilde{s}}{\widetilde{t}}\big) \big ] 
 =  r \cdot \widetilde{s}^{\chi} \cdot \phi_{\chi}^{*}(0)  \geq 0 ,
\label{brostu2:fo.def.45bthreevar}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
where $\phi_{\chi}^{*}(0) := \lim_{u\rightarrow 0} u^{\chi-1} \cdot u \cdot \phi\big(\frac{1}{u}\big) = 
\lim_{v\rightarrow \infty} \frac{\phi(v)}{v^{\chi}}$ 
exists but may be infinite.
To convert 2(i), we employ the fact that 
for fixed $r >0$, $\widetilde{t} >0$ the function 
$\widetilde{s} \rightarrow \widetilde{\psi}_{\phi,c}\big(r,\widetilde{s},\widetilde{t}\big)$
is convex with existing limit

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.5cm}  \textstyle
\ell i_{3} := r \cdot \widetilde{t}^{\chi} \cdot \psi_{\phi,c}\big(\frac{0}{\widetilde{t}},1\big) 
: = \lim_{s\rightarrow 0} \widetilde{\psi}_{\phi,c}\big(r,\widetilde{s},\widetilde{t}\big)  
 =  r \cdot \widetilde{t}^{\chi} \cdot (\phi(0) + \phi_{+,c}^{\prime}(1) - \phi(1)) > 0 . \qquad \ \  
\label{brostu2:fo.def.45bfourchi}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
To achieve the analogue of 2(g), let us first remark
that for fixed $r >0$ the function $(\widetilde{s},\widetilde{t}) \rightarrow \widetilde{\psi}_{\phi,c}\big(r,\widetilde{s},\widetilde{t}\big)$ 
may not be continuous at $(\widetilde{s},\widetilde{t}) = (0,0)$, 
but due to the very nature of a divergence we make the (2g)-conform convention of setting

\vspace{-0.5cm}

\enlargethispage{0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
r \cdot 0^{\chi} \cdot \psi_{\phi,c}\big(\frac{0}{0},1\big) 
: = \widetilde{\psi}_{\phi,c}\big(r,0,0\big) :=  0 \, . 
\nonumber
\end{eqnarray}

\vspace{-0.2cm}

\noindent
The analogues of the 
Assumptions 2(h),(j),($\ell$),(m),(n) are 
obsolete because of our basic 
finiteness requirements.
Putting together all the building-blocks, with the above-mentioned limits and conventions 
we obtain the divergence

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q}^{\chi},\lambda}(\mathbbm{P},\mathbbm{Q})
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
: =
\olint_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \Big[ \mathbbm{q}(x)^{\chi} \cdot \phi  \big( {
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}}\big) - \mathbbm{q}(x)^{\chi} \cdot \phi  \big( 1 \big) 
- \phi_{+,c}^{\prime} 
\big( 1 \big) \cdot \big( \mathbbm{p}(x) \cdot \mathbbm{q}(x)^{\chi-1} - \mathbbm{q}(x)^{\chi} \big) 
\Big] \,  
\nonumber
\\ 
& & \hspace{-0.2cm}   \textstyle 
: =
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \Big[ \mathbbm{q}(x)^{\chi} \cdot \phi  \big( {
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}}\big) - \mathbbm{q}(x)^{\chi} \cdot \phi  \big( 1 \big) 
- \phi_{+,c}^{\prime} 
\big( 1 \big) \cdot \big( \mathbbm{p}(x) \cdot \mathbbm{q}(x)^{\chi-1} - \mathbbm{q}(x)^{\chi} \big) 
\Big] 
\, 
\nonumber \\ 
& & \hspace{7.2cm} 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) 
\big)
\, \mathrm{d}\lambda(x) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \phi_{\chi}^{*}(0) \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{p}(x)^{\chi} 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\big[ \phi(0) + \phi_{+,c}^{\prime}(1) - \phi(1) \big] \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x)^{\chi} 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{q}(x) 
\big)
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big)
\, \mathrm{d}\lambda(x)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
=
\int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \Big[ \mathbbm{q}(x)^{\chi} \cdot \phi  \big( {
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}}\big) - \mathbbm{q}(x)^{\chi} \cdot \phi  \big( 1 \big) 
- \phi_{+,c}^{\prime} 
\big( 1 \big) \cdot \big( \mathbbm{p}(x) \cdot \mathbbm{q}(x)^{\chi-1} - \mathbbm{q}(x)^{\chi} \big) 
\Big] 
\, 
\nonumber \\ 
& & \hspace{7.2cm} 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) 
\big)
\, \mathrm{d}\lambda(x) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \phi_{\chi}^{*}(0) \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{p}(x)^{\chi} 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\big[ \phi(0) + \phi_{+,c}^{\prime}(1) - \phi(1) \big] \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x)^{\chi} 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big)
\, \mathrm{d}\lambda(x)
  \, . 
\label{brostu2:fo.div.new0}
\end{eqnarray}

\vspace{-0.1cm}

\noindent
In case of 
$\mathfrak{Q}_{\chi}^{\mathbbm{R}\cdot \lambda}[\mathcal{X}] := 
\int_{{\mathcal{X}}} \mathbbm{q}(x)^{\chi} \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) < \infty$,
the divergence \eqref{brostu2:fo.div.new0} becomes

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 \leq D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q}^{\chi},\lambda}(\mathbbm{P},\mathbbm{Q}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
= \int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \Big[ \mathbbm{q}(x)^{\chi} \cdot \phi  \big( {
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}}\big)
- \phi_{+,c}^{\prime} 
\big( 1 \big) \cdot \big( \mathbbm{p}(x) \cdot \mathbbm{q}(x)^{\chi-1} - \mathbbm{q}(x)^{\chi} \big) 
\Big] 
\, 
\nonumber \\ 
& & \hspace{7.2cm} 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) 
\big)
\, \mathrm{d}\lambda(x) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \phi_{\chi}^{*}(0) \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{p}(x)^{\chi} 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ 
\big[ \phi(0) + \phi_{+,c}^{\prime}(1) \big] \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x)^{\chi} 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big)
\, \mathrm{d}\lambda(x)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
 - \phi(1) \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x)^{\chi} 
\, \mathrm{d}\lambda(x)  \, .
\label{brostu2:fo.div.new1}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
Moreover, in case of 
$\phi \big( 1 \big) = 0$ and 
$\int_{{\mathcal{X}}}  \big( \mathbbm{p}(x) \cdot \mathbbm{q}(x)^{\chi-1} - 
\mathbbm{q}(x)^{\chi} \big) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) \in [0, \infty[$
(but not necessarily 
$\int_{{\mathcal{X}}} \mathbbm{p}(x) \cdot \mathbbm{q}(x)^{\chi-1} \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) < \infty$,
$\int_{{\mathcal{X}}} \mathbbm{q}(x)^{\chi} \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) < \infty$),
the divergence \eqref{brostu2:fo.div.new0} turns into

\enlargethispage{0.5cm}

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 \leq D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q}^{\chi},\lambda}(\mathbbm{P},\mathbbm{Q}) 
= \int_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \mathbbm{q}(x)^{\chi} \cdot \phi  \big( {
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}}\big) 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) 
\big)
\, \mathrm{d}\lambda(x) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \phi_{\chi}^{*}(0) \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{p}(x)^{\chi} 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big)
\, \mathrm{d}\lambda(x)
+ \phi(0) \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x)^{\chi} 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big)
\, \mathrm{d}\lambda(x)  
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle
- \phi_{+,c}^{\prime}  \big( 1 \big)  \cdot
\int_{{\mathcal{X}}}  \big( \mathbbm{p}(x) \cdot \mathbbm{q}(x)^{\chi-1} - \mathbbm{q}(x)^{\chi} \big) 
\cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) \, .
\nonumber
\end{eqnarray} 

\vspace{-0.2cm}

\noindent
In contrast to the case $\chi=1$ where 
for $\lambda-$probability-density functions 
$\mathbbm{\overrightharp{p}}$, $\mathbbm{\overrightharp{q}}$, 
the divergence \eqref{brostu2:fo.def.47c}
was further simplified due to
$\int_{{\mathcal{X}}} \big( \mathbbm{\overrightharp{p}}(x) - \mathbbm{\overrightharp{q}}(x) \big) \, \mathrm{d}\lambda(x) \ = \ 0$,
for the current setup $\chi>1$ the latter has no impact for further simplification.
However, in general, for the new divergence defined by \eqref{brostu2:fo.div.new0}
one gets for any $\mathbbm{P} \perp \mathbbm{Q}$
from \eqref{brostu2:fo.Sing.22}, \eqref{brostu2:fo.Sing.22b}, \eqref{brostu2:fo.Sing.1} to \eqref{brostu2:fo.Sing.3}
the expression 

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 \leq D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q}^{\chi},\lambda}(\mathbbm{P},\mathbbm{Q}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
= \phi_{\chi}^{*}(0) \cdot
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{p}(x)^{\chi} 
\, \mathrm{d}\lambda(x)
+ \big[ \phi(0) + \phi_{+,c}^{\prime}(1) - \phi(1) \big] \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{r}(x) \cdot \mathbbm{q}(x)^{\chi} 
\, \mathrm{d}\lambda(x)
  \,  \qquad \ \ 
\label{brostu2:fo.div.new3}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
which is encompassing for the class of $\lambda-$probability functions.
By inspection of the above calculations, one can even relax
the assumptions away from convexity:

\vspace{-0.2cm}

\begin{theorem}
\label{brostu2:thm.7}
Let $\chi >1$, $c \in [0,1]$, $\phi: ]0,\infty[ \rightarrow \mathbb{R}$ such that both 
$\phi_{+,c}^{\prime}(1)$ and $\phi(0) := \lim_{s \rightarrow 0} \phi(s)$ exist and
$\psi_{\phi,c}(s,1) =  \phi(s) - \phi(1) - \phi_{+,c}^{\prime}(1) \cdot (s-1) \geq 0 $ 
for all $s>0$. Moreover, assume that $\psi_{\phi,c}(s,1) = 0$ if and only if $s=1$.
Furthermore, let the limits $\ell i_{2} \geq 0$ defined by \eqref{brostu2:fo.def.45bthreevar} 
and $\ell i_{3} \geq 0$ defined by \eqref{brostu2:fo.def.45bfourchi} exist
and satisfy $\ell i_{2}+\ell i_{3} >0$.
Then one gets 
for the divergence defined by
\eqref{brostu2:fo.div.new0}:\\
(1) $D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q}^{\chi},\lambda}(\mathbbm{P},\mathbbm{Q}) \geq 0$.
Depending on the concrete situation,\\  
$D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q}^{\chi},\lambda}(\mathbbm{P},\mathbbm{Q})$ may take infinite value.

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
(2) \quad D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q}^{\chi},\lambda}(\mathbbm{P},\mathbbm{Q}) = 0 \quad
\textrm{if and only if} \quad 
\mathbbm{p}(x)=\mathbbm{q}(x)
\ \textrm{for $\lambda-$a.a. $x \in \mathcal{X}$.}
\nonumber 
\end{eqnarray}

\vspace{-0.2cm}

\noindent
(3) For $\mathbbm{P} \perp \mathbbm{Q}$, the representation \eqref{brostu2:fo.div.new3} holds.
\end{theorem}

\vspace{-0.4cm}


\begin{remark}
\label{brostu2:rem.90}
(1) As seen above, if the generator $\phi$ is in $\Phi(]0,\infty[)$ and satisfies the 
Assumptions \ref{brostu2:assu.class1}(a) to (d) for $t=1$, then the requirements 
on $\phi$ in Theorem \ref{brostu2:thm.7} are automatically satisfied.
The case $\chi=1$ has already been covered by Theorem \ref{brostu2:thm.2CASD}.\\
(2) For practical purposes, it is sometimes useful to work
with a sub-setup of choices $\chi >1$, $c \in [0,1]$ and $\phi$ 
such that $\ell i_{2} \in ]0,\infty[$ and/or $\ell i_{3} \in ]0,\infty[$. $\square$
\end{remark}

\vspace{-0.15cm}

\noindent
Let us give some examples. To begin with, for $\alpha \in \mathbb{R}\backslash \{0,1\}$
take the power functions
$\phi(t): = \phi_{\alpha}(t) := 
\frac{t^\alpha-1}{\alpha(\alpha-1)}-\frac{t-1}{\alpha-1} \ \in [0,\infty[ , 
\quad t \in ]0,\infty[$, with the properties 
$\phi_{\alpha}(1) =0$, $\phi_{\alpha}^{\prime}(1)=0$
(cf.\ \eqref{brostu2:fo.def.33a})
and $\phi_{\alpha}(0) := \lim_{t\downarrow 0}\phi_{\alpha}(t)= 
\frac{1}{\alpha} \cdot \boldsymbol{1}_{]0,1] \cup ]1,\infty[}(\alpha)
+ \infty \cdot \boldsymbol{1}_{]-\infty,0[}(\alpha)$.
Then, for arbitrary $\chi \in \mathbb{R}$ one gets the representation

\vspace{-0.5cm}
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 \leq D_{\phi_{\alpha},\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q}^{\chi},\lambda}(\mathbbm{P},\mathbbm{Q})
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
: =
\olint_{{\mathcal{X}}} 
\mathbbm{r}(x)  \cdot \Big[ \mathbbm{q}(x)^{\chi} \cdot \phi_{\alpha}  \big( {
\frac{\mathbbm{p}(x)}{\mathbbm{q}(x)}}\big) - \mathbbm{q}(x)^{\chi} \cdot \phi  \big( 1 \big) 
- \phi_{\alpha}^{\prime} 
\big( 1 \big) \cdot \big( \mathbbm{p}(x) \cdot \mathbbm{q}(x)^{\chi-1} - \mathbbm{q}(x)^{\chi} \big) 
\Big]  \, \mathrm{d}\lambda(x)   
\nonumber\\
\label{brostu2:fo.div.ex.154}
\\[-0.3cm] 
& & \hspace{-0.2cm}   \textstyle 
 =
\olint_{{\mathcal{X}}} 
\Big[ \phi_{\alpha}  \big( 
\frac{\mathbbm{p}(x)}{w_{\widetilde{\chi}}{(\mathbbm{p}(x),\mathbbm{q}(x))}} 
\big) 
-\phi_{\alpha}  
\big( {\frac{\mathbbm{q}(x)}{w_{\widetilde{\chi}}(\mathbbm{p}(x),\mathbbm{q}(x))}}\big)
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle  
- \phi_{\alpha}^{\prime} 
\big( {\frac{\mathbbm{q}(x)}{w_{\widetilde{\chi}}(\mathbbm{p}(x),\mathbbm{q}(x))}}\big) \cdot 
\big( \frac{\mathbbm{p}(x)}{w_{\widetilde{\chi}}(\mathbbm{p}(x),\mathbbm{q}(x))}-
\frac{\mathbbm{q}(x)}{w_{\widetilde{\chi}}(\mathbbm{p}(x),\mathbbm{q}(x))}\big) 
\Big] 
\cdot w_{\widetilde{\chi}}(\mathbbm{p}(x),\mathbbm{q}(x)) \cdot \mathbbm{r}(x) \, \mathrm{d}\lambda(x) \ 
\nonumber \\
& & \hspace{-0.2cm}   \textstyle
= D_{\phi_{\alpha},\mathbbm{Q}^{\widetilde{\chi}},\mathbbm{Q}^{\widetilde{\chi}},\mathbbm{R}\cdot 
\mathbbm{Q}^{\widetilde{\chi}},\lambda}(\mathbbm{P},\mathbbm{Q}) \, 
\label{brostu2:fo.div.ex.155}
\end{eqnarray}

\vspace{-0.5cm}

\noindent
with the adaptive scaling/aggregation function $w_{\widetilde{\chi}}(u,v) = v^{\widetilde{\chi}}$
and $\widetilde{\chi} := 1 + \frac{\chi-1}{1-\alpha}$; in other words,
the divergence \eqref{brostu2:fo.div.ex.154} can be seen as a particularly adaptively scaled Bregman
divergence of non-negative functions in the sense of Ki{\ss}linger \& Stummer~\cite{Kis:16},
from which their robustness and non-singularity-asymptotical-statistics properties can be 
derived as a special case (for the probability setup $\mathbbm{\overrightharp{P}}$,
$\mathbbm{\overrightharp{Q}}$, $\mathbbm{r}(x) \equiv 1$, and beyond).
From \eqref{brostu2:fo.div.ex.155}, it is immediate to see that the case 
$\chi=1$ corresponds to the generalized power divergences \eqref{brostu2:fo.def.632a} of order 
$\alpha \in \mathbb{R}\backslash\{0,1\}$, 
whereas $\chi=\alpha$ 
corresponds to 
the unscaled divergences \eqref{brostu2:fo.def.140a0}, i.e.  

\vspace{-0.5cm}
 
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D_{\phi_{\alpha},\mathbbm{Q},\mathbbm{Q},\mathbbm{R}\cdot \mathbbm{Q}^{\alpha},\lambda}(\mathbbm{P},\mathbbm{Q})
= D_{\phi_{\alpha},\mathbbm{1},\mathbbm{1},\mathbbm{R}\cdot \mathbbm{1},\lambda}(\mathbbm{P},\mathbbm{Q})
\label{brostu2:fo.div.ex.279}
\\ 
& & \hspace{-0.2cm}   \textstyle 
= \olint_{{\mathcal{X}}} 
\frac{\mathbbm{r}(x)}{\alpha \cdot (\alpha-1)} \cdot
\Big[ 
\mathbbm{p}(x)^{\alpha} + (\alpha-1) \cdot \mathbbm{q}(x)^{\alpha} - \alpha 
\cdot \mathbbm{p}(x) \cdot \mathbbm{q}(x)^{\alpha-1} 
\Big]  \, \mathrm{d}\lambda(x)
\hspace{0.1cm}
(cf.\ \eqref{brostu2:fo.def.140a0}) \ 
\nonumber
\end{eqnarray}

\vspace{-0.2cm}

\noindent
which for $\alpha >1$, $\mathbbm{r}(x) \equiv 1$, $\mathbbm{p}= \mathbbm{\overrightharp{p}}$,
$\mathbbm{q}= \mathbbm{\overrightharp{q}}$ is a multiple of the $\alpha-$order density-power divergences DPD 
used by Basu et al.~\cite{Bas:98}; 
as a side remark, in the latter setup our divergence \eqref{brostu2:fo.div.ex.155} manifests 
a smooth interconnection between
PD and DPD which differs from that of Patra et al.~\cite{Pat:13}, Ghosh et al.~\cite{Gho:17a}. 

\vspace{0.2cm}
\noindent
For \eqref{brostu2:fo.div.ex.154}, let us shortly inspect
the corresponding $\ell i_{2}$ from \eqref{brostu2:fo.def.45bthreevar} 
as well as $\ell i_{3}$ from \eqref{brostu2:fo.def.45bfourchi}. 
Only for $\alpha \in ]0,1[ \cup ]1,\infty[$, one gets finite 
$\ell i_{3} = \frac{r \widetilde{t}^{\chi}}{\alpha} \in ]0,\infty[$
for all $\chi \in \mathbb{R}$, $r>0$, $\widetilde{t} >0$.
Additionally, one obtains finite $\ell i_{2}$ only for $\chi=1$, $\alpha \in ]0,1[$ 
where $\ell i_{2} = \frac{r \widetilde{s}}{1-\alpha}$ (PD case),
respectively for $\chi >1$, $\alpha \in ]0,1[ \cup ]1,\chi[$ where $\ell i_{2} = 0$,
respectively for $\alpha=\chi >1$ where $\ell i_{2} = \frac{r \widetilde{s}^{\alpha}}{\alpha \cdot (\alpha-1)}$ (DPD case),
for all $r>0$, $\widetilde{s} >0$.

\vspace{0.2cm}
\noindent
Another interesting example for the
divergence $D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q}^{\chi},\lambda}(\mathbbm{P},\mathbbm{Q})$
in \eqref{brostu2:fo.div.new0}
is given for $\alpha \in \mathbb{R}\backslash \{0,1\}$ by the generators

\vspace{-0.5cm}
 
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\phi(t) := \widetilde{\widetilde{\phi}}_{\alpha}(t) := \frac{(\alpha-1) \cdot t^{\alpha}
 - \alpha \cdot t^{\alpha-1} +1}{\alpha \cdot (\alpha-1)},
\ \  t >0, \quad \widetilde{\widetilde{\phi}}_{\alpha}(1) = 0, 
\ \widetilde{\widetilde{\phi}}_{\alpha}^{\prime}(1) = 0 , \qquad  \
\nonumber  
\end{eqnarray}

\vspace{-0.2cm}


\noindent
for which $t \rightarrow \widetilde{\widetilde{\phi}}_{\alpha}(t) = 
\widetilde{\widetilde{\phi}}_{\alpha}(t) - \widetilde{\widetilde{\phi}}_{\alpha}(0)
- \widetilde{\widetilde{\phi}}_{\alpha}^{\prime}(1) \cdot (t-1)
= \psi_{\phi_{\alpha}}(t,1)$ is strictly decreasing
on $]0,1[$ and strictly increasing on $1,\infty[$. Hence, the corresponding
assumptions of Theorem \ref{brostu2:thm.7} are satisfied. Beyond this,
notice that $\widetilde{\widetilde{\phi}}_{\alpha}(\cdot)$ is strictly convex
on $]0,\infty[$ if $\alpha \in ]1,2]$, respectively 
strictly convex on $]1-\frac{1}{\alpha-1}, \infty[$ 
and strictly concave on $]0, 1-\frac{1}{\alpha-1}[$ if $\alpha >2$, respectively 
strictly convex on $]0, 1+\frac{1}{1-\alpha}[$ 
and strictly concave on $]1+\frac{1}{1-\alpha},\infty[$ if $\alpha \in ]-\infty,0[ \cup ]0,1[$.
Furthermore, the corresponding $\ell i_{3}$ is finite only for $\alpha >1$, namely 
$\ell i_{3} = \frac{r \widetilde{t}^{\chi}}{\alpha \cdot (\alpha-1)} \in ]0,\infty[$
for all $\chi \in \mathbb{R}$, $r>0$, $\widetilde{t} >0$. 
Additionally, if $\alpha >1$ one gets finite $\ell i_{2}$ only for $\chi> \alpha >1$
where $\ell i_{2} = 0$, respectively for $\alpha=\chi >1$ where 
$\ell i_{2} = \frac{r \widetilde{s}^{\alpha}}{\alpha}$,
for all $r>0$, $\widetilde{s} >0$. Notice that for $\chi=\alpha >1$,
the limits $\ell i_{2}$, $\ell i_{3}$ 
for the cases $\phi_{\alpha}$ and $\widetilde{\widetilde{\phi}}_{\alpha}$
are asymmetric. Indeed, by straightforward calculations one can easily see that
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D_{\widetilde{\widetilde{\phi}}_{\alpha},\mathbbm{Q},\mathbbm{Q},\mathbbm{R}\cdot \mathbbm{Q}^{\alpha},\lambda}(\mathbbm{P},\mathbbm{Q})
= D_{\phi_{\alpha},\mathbbm{1},\mathbbm{1},\mathbbm{R}\cdot \mathbbm{1},\lambda}(\mathbbm{Q},\mathbbm{P}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
= \olint_{{\mathcal{X}}} 
\frac{\mathbbm{r}(x)}{\alpha \cdot (\alpha-1)} \cdot
\Big[ 
\big(\mathbbm{q}(x)\big)^{\alpha} + (\alpha-1) \cdot \big(\mathbbm{p}(x)\big)^{\alpha} - \alpha 
\cdot \mathbbm{q}(x) \cdot \big(\mathbbm{p}(x)\big)^{\alpha-1} 
\Big]  \, \mathrm{d}\lambda(x) \qquad \ 
\label{brostu2:fo.div.ex.156}
\end{eqnarray}
which is the ``reversion'' of the divergence \eqref{brostu2:fo.def.140a0}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Minimum divergences - the encompassing method}
\label{subsec.4anew.3}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

So far, we have almost entirely dealt with aggregated divergences
between functions
$P := \big\{p(x)\big\}_{x \in \mathcal{X}}$,
$Q := \big\{q(x)\big\}_{x \in \mathcal{X}}$ 
under the \textit{same} 
aggregator (measure) $\lambda$. 
On the other hand, in Subsection \ref{subsec.4anew.1}
we have already encountered an important statistical situation where \textit{two} aggregators  
$\lambda_{1}$ and $\lambda_{2}$ come into play. Let us now investigate such a context
in more detail. To achieve this, for the rest of this paper we confine ourselves to the
following probabilistic setup:  the modeled respectively observed 
(random) data take values in a state space $\mathcal{X}$ (with at least two distinct values), 
equipped with a system  $\mathcal{F}$ of admissible events 
($\sigma-$algebra) and two $\sigma-$finite measures $\lambda_{1}$ and $\lambda_{2}$.
Furthermore, let $\mathbbm{\overrightharp{P}} := \big\{\mathbbm{\overrightharp{p}}\big\}_{x \in \mathcal{X}}$,
$\mathbbm{\overrightharp{Q}} := \big\{\mathbbm{\overrightharp{q}}\big\}_{x \in \mathcal{X}}$
such that 
$\mathbbm{\overrightharp{p}}(x) \geq 0$ for $\lambda_{1}-$a.a. $x \in \mathcal{X}$,
$\mathbbm{\overrightharp{q}}(x) \geq 0$ for $\lambda_{2}-$a.a. $x \in \mathcal{X}$,
$\int_{\mathcal{X}} \mathbbm{\overrightharp{p}}(x) \,  \mathrm{d}\lambda_{1}(x) =1$,
and $\int_{\mathcal{X}} \mathbbm{\overrightharp{q}}(x) \,  \mathrm{d}\lambda_{2}(x) =1$;
in other words, $\mathbbm{\overrightharp{P}}$ is a $\lambda_{1}-$probability density function
and $\mathbbm{\overrightharp{Q}}$ is a $\lambda_{2}-$probability density function;
the two corresponding probability measures are denoted by
$\mathfrak{\overrightharp{P}}^{\mathbb{1}\cdot \lambda_{1}}[\bullet] 
: = \int_{\bullet} \mathbbm{\overrightharp{p}}(x) \, \mathrm{d}\lambda_{1}(x)$ 
and 
$\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{2}}[\bullet] 
: = \int_{\bullet} \mathbbm{\overrightharp{q}}(x) \, \mathrm{d}\lambda_{2}(x)$.
Notice that we henceforth assume $\mathbbm{r}(x) =1$ for all $x \in \mathcal{X}$.

\enlargethispage{0.5cm}

\vspace{0.15cm} 
\noindent
More specific, we deal with a parametric framework 
of double uncertainty in the data  and in the model (cf. Section \ref{subsec.1newb.4}). The former is 
described by a random variable $Y$ taking values in the space $\mathcal{X}$
and by its  
probability law
$\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{2}}_{\theta_{0}}[\bullet]$
which (as far as model risk is concerned) is supposed to be unknown but 
belong to a class 
$\mathcal{Q}_{\Theta}^{\lambda_{2}} =\{\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot 
\lambda_{2}}_{\theta }[\bullet]: \theta \in \Theta \}$ of probability
measures on $({\mathcal{X}},{\mathcal{F}})$ indexed by a set of parameters 
$\Theta \subset {\mathbb{R}}^{d}$ (the non-parametric case works
basically in analogous way, with more sophisticated technicalities).
Accordingly, all $Pr[Y \in \bullet \, | \, \theta ] = 
\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{2}}_{\theta}[\bullet]
= \int_{\bullet} \mathbbm{\overrightharp{q}}_{\theta}(x) \, \mathrm{d}\lambda_{2}(x)$
($\theta \in\Theta$) are principal model-candidate laws, with $\theta_{0}$
to be found out 
(approximately and with high confidence) 
by $N$ concrete data observations described by the independent and identically distributed random variables
$Y_{1}, \ldots Y_{N}$. 
Furthermore, we assume that the true unknown parameter $\theta _{0}$\ (to be learnt) 
is identifiable 
and that the family $\mathcal{Q}_{\Theta}^{\lambda_{2}}$ is (measure-theoretically),
equivalent in the sense

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{2}}_{\theta} 
\neq 
\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{2}}_{\theta_{0}} 
\quad \mbox{and}\quad 
\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{2}}_{\theta} 
\sim
\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{2}}_{\theta_{0}}
\quad \text{for all}\ \theta ,\,\theta _{0}\in \Theta \ \text{
\ with \ }\theta \neq \theta _{0} . 
\label{brostu2:fo.mesequ}
\end{eqnarray}

\vspace{-0.1cm}

\noindent
As usual, the equivalence
$\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot 
\lambda_{2}} \sim
\widetilde{\mathfrak{\overrightharp{Q}}}^{\mathbb{1}\cdot 
\lambda_{2}}$ means that for $\lambda_{2}-$a.a. $x \in \mathcal{X}$
there holds the density-function-relation: $\mathbbm{\overrightharp{q}}(x) = 0$ if and only if
$\widetilde{\mathbbm{\overrightharp{q}}}(x) = 0$; this implies
in particular that 
$\mathbbm{\overrightharp{q}}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\widetilde{\mathbbm{\overrightharp{q}}}(x)\big) = 0$
and 
$\widetilde{\mathbbm{\overrightharp{q}}}(x) 
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{\overrightharp{q}}(x)\big) = 0$
for $\lambda_{2}-$a.a. $x \in \mathcal{X}$, and by cutting off ``datapoints/states of zero contributions'' 
one can then even take $\mathcal{X}$ small enough such that 
$\mathbbm{\overrightharp{q}}(x) \cdot \widetilde{\mathbbm{\overrightharp{q}}}(x) >0$
(and hence, $\boldsymbol{1}_{]0,\infty[}\big(\mathbbm{\overrightharp{q}}(x) \cdot \widetilde{\mathbbm{\overrightharp{q}}}(x) 
\big) = 1$)
for $\lambda_{2}-$a.a. $x \in \mathcal{X}$.
Clearly, since any $\lambda_{2}-$aggregated divergence $D_{\lambda_{2}}(\cdot,\cdot)$ satisfies
(the aggregated version of) the axioms (D1) and (D2),
and since $\theta_{0}$ is identifiable, one gets immediately
in terms of the corresponding $\lambda_{2}-$probability density functions
$\mathbbm{\overrightharp{Q}}_{\theta} := 
\big\{\mathbbm{\overrightharp{q}}_{\theta}(x)\big\}_{x \in \mathcal{X}}$

\vspace{-0.5cm}

\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle
\theta_{0}=\argmin_{\theta \in \Theta} \ 
D_{\lambda_{2}}\big(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta}\big)
\text{ \ \ \ for every }\theta _{0}\in \Theta . 
\label{9a}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
Inspired by this, one major idea of tracking down (respectively, learning) the true unknown $\theta_{0}$ is to replace
$\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{2}}_{\theta_{0}}$
by a data-observation-derived -- and thus noisy -- probability law
$\omega \rightarrow \mathfrak{\overrightharp{P}}_{N}^{obs(\omega); \mathbb{1}\cdot \lambda_{1}}[\bullet]
:= \int_{\bullet} \mathbbm{\overrightharp{p}}^{Y_{1}(\omega),\ldots, Y_{N}(\omega)}(x) \, \mathrm{d}\lambda_{1}(x)$
where the $\lambda_{1}-$probability density function
$\mathbbm{\overrightharp{P}}_{N}^{obs(\omega)} := 
\big\{\mathbbm{\overrightharp{p}}^{Y_{1}(\omega),\ldots, Y_{N}(\omega)}(x)\big\}_{x \in \mathcal{X}}$
depends, as indexed, on the outcome of the observations $Y_{1}(\omega),\ldots, Y_{N}(\omega)$.
If $\mathfrak{\overrightharp{P}}_{N}^{obs(\omega); \mathbb{1}\cdot \lambda_{1}}$ converges in distribution to 
$\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{2}}_{\theta_{0}}$ as $N$ tends to infinity,
then one \textit{intuitively} expects to obtain the 
so-called 
\textit{minimum-divergence estimator} (``approximator'')

\vspace{-0.6cm}

\enlargethispage{0.5cm}

\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle
\widehat{\theta}_{N}(\omega) := \widehat{\theta}_{N,D_{\lambda_{2}}}(\omega)
:= \arginf_{\theta \in \Theta} \ 
D_{\lambda_{2}}\big(
\mathbbm{\overrightharp{P}}_{N}^{obs(\omega)},
\mathbbm{\overrightharp{Q}}_{\theta}
\big) 
\label{15}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
which estimates $\theta _{0}$ consistently in the usual sense of the
convergence $\theta _{n}\rightarrow \theta _{0}$\ for $n\rightarrow \infty $. 
However, by the nature of our divergence construction,
the method \eqref{15} makes principal sense only if the two aggregators $\lambda_{1}$ 
and $\lambda_{2}$ coincide (and if \eqref{15} is analytically respectively computationally solvable)!
Remark that the minimum distance estimator \eqref{15} 
depends on the choice of
the divergence $D_{\lambda_{2}}(\cdot,\cdot)$.

\vspace{0.15cm}
\noindent
\textit{Subsetup 1.}  \ 
For instance, if by nature the set $\mathcal{X}$ of all possible data points 
has only countably many elements, say  $\mathcal{X} = \mathcal{X}_{\#} = \{z_{1}, \ldots z_{s}\}$ 
(where $s$ is an integer larger than one), then
a natural model-concerning aggregator is the counting measure $\lambda_{2} := \lambda_{\#}$  
(recall $\lambda_{\#}[\{x\}] =1$ for all $x \in \mathcal{X}$), and hence
$\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{2}}_{\theta}[\bullet]
= \sum_{x \in \bullet} \mathbbm{\overrightharp{q}}_{\theta}(x)
= \sum_{x \in \mathcal{X}} \boldsymbol{1}_{\bullet}(x) \cdot \mathbbm{\overrightharp{q}}_{\theta}(x)$
(where $\bullet$ stands for any arbitrary subset of $\mathcal{X}$).
In such a context, a popular choice for the data-observation-derived probability
law is the so-called ``empirical distribution''
$\omega \rightarrow \mathfrak{\overrightharp{P}}_{N}^{obs(\omega); \mathbb{1}\cdot \lambda_{1}}[\bullet]
= \int_{\bullet} \mathbbm{\overrightharp{p}}^{Y_{1}(\omega),\ldots, Y_{N}(\omega)}(x) \, \mathrm{d}\lambda_{1}(x)
:= \sum_{x \in \bullet} \mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(x)
=: \mathfrak{\overrightharp{P}}_{N}^{emp(\omega)}[\bullet]   
$,
where $\lambda_{1} := \lambda_{\#} = \lambda_{2}$ and
$\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(x) := 
\frac{1}{N} \cdot \# \{ i \in \{ 1, \ldots, N\}: Y_{i}(\omega) =x \}$
is the total number of $x-$observations divided by the total number $N$ of observations.
In other words, $\mathfrak{\overrightharp{P}}_{N}^{obs(\omega); \mathbb{1}\cdot \lambda_{1}}[\bullet]
:= \mathfrak{\overrightharp{P}}_{N}^{emp(\omega)}[\bullet] 
:= \frac{1}{N} \cdot \sum_{i=1}^{N}   \delta_{Y_{i}(\omega)}[\bullet]$,
where $\delta_{z}[\bullet]$
is the corresponding Dirac (resp. one-point) distribution
given by $\delta_{z}[A] :=  \boldsymbol{1}_{A}(z)$. 
Hence, in such a set-up it 
makes sense to solve the noisy minimization problem

\vspace{-0.5cm}

\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle
\widehat{\theta}_{N}(\omega) := \widehat{\theta}_{N,D}(\omega)
:= \arginf_{\theta \in \Theta} \ 
D_{\lambda_{\#}}\big(
\mathbbm{\overrightharp{P}}_{N}^{emp(\omega)},
\mathbbm{\overrightharp{Q}}_{\theta}
\big) 
\nonumber
\end{eqnarray}

\vspace{-0.2cm}

\noindent
where $\mathbbm{\overrightharp{P}}_{N}^{emp(\omega)} := 
\big\{\mathbbm{\overrightharp{p}}_{N}^{emp}(x)\big\}_{x \in \mathcal{X}}$
and $D_{\lambda_{\#}}(\cdot,\cdot)$ is the discrete version of any of the divergences 
above.
Notice that -- at least for small enough number $N$ of observations -- 
for some $x \in \mathcal{X}$ with $\lambda_{\#}[\{x\}] >0$ one has $\mathbbm{\overrightharp{p}}_{N}^{emp}(x) =0$ but
$\mathbbm{\overrightharp{q}}_{\theta}(x) >0$, and hence,
$\mathbbm{\overrightharp{q}}_{\theta}(x) \cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{\overrightharp{p}}_{N}^{emp}(x)\big) >0$; 
this must be taken into account in the calculation of the explicit forms of the corresponding divergences.
By the assumed convergence, this effect disappears as $N$ becomes large enough.
\hspace{0.5cm} $\square$


\vspace{0.15cm}
\noindent
\textit{Subsetup 2.}  \ 
Consider the ``crossover case'' where
$\mathcal{X}$ is uncountable (e.g. $\mathcal{X}=\mathbb{R}$) and
the family $\mathcal{Q}_{\Theta}^{\lambda_{2}}$
is assumed to be \textit{continuous (nonatomic)} in the
sense

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
0 = \mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot 
\lambda_{2}}_{\theta }[\{z\}] 
= Pr[Y \in \{z\} \, | \, \theta ] 
= \int_{\mathcal{X}} \boldsymbol{1}_{\{z\}}(x) \cdot \mathbbm{\overrightharp{q}}_{\theta}(x) \, \mathrm{d}\lambda_{2}(x)
\textrm{ \ for all $z\in \mathcal{X}$, $\theta \in \Theta$} \qquad \ \ 
\label{brostu2:fo.def.contfam1}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
(e.g. $\mathbbm{\overrightharp{q}}_{\theta}(\cdot)$ are Gaussian densities with mean $\theta$ and
variance $1$),
and the data-observation-derived probability
law is the ``extended'' empirical distribution 

\vspace{-0.6cm}

\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle 
\omega \rightarrow \mathfrak{\overrightharp{P}}_{N}^{obs(\omega); \mathbb{1}\cdot \lambda_{1}}[\bullet]
= \int_{\bullet} \mathbbm{\overrightharp{p}}^{Y_{1}(\omega),\ldots, Y_{N}(\omega)}(x) \, \mathrm{d}\lambda_{1}(x)   
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
:= \sum_{x \in \bullet} \mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(x) 
\cdot \boldsymbol{1}_{\mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega))}(x)
=: \mathfrak{\overrightharp{P}}_{N}^{\overline{emp}(\omega)}[\bullet] \, ,
\label{brostu2:fo.def.pnempcont}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
where the extension on $\mathcal{X}$ is accomplished by attributing zeros to all $x$ outside
the finite range $\mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega)) = \{ z_{1}(\omega), \ldots, z_{s}(\omega) \}$
of distinguishable points $z_{1}(\omega), \ldots, z_{s}(\omega)$ ($s \leq N$)
occupied by the observations $Y_{1}(\omega), \ldots, Y_{N}(\omega)$; 
notice that the involved counting measure given by 
$\lambda_{1}[\bullet] := \sum_{z \in \mathcal{X}} 
\boldsymbol{1}_{\mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega))}(z) 
\cdot  \delta_{z}[\bullet]$
puts $1$ to each data-point $z$ which has been observed.
Because $\lambda_{1}$ and $\lambda_{2}$ are now essentially different,
the minimum-divergence method \eqref{15} can not be applied directly 
(by taking either $\lambda := \lambda_{1}$ or $\lambda := \lambda_{2}$),
despite of $\mathfrak{\overrightharp{P}}_{N}^{\overline{emp}(\omega)}$ converging in distribution to 
$\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{2}}_{\theta_{0}}$ as $N$ tends to infinity.
\hspace{0.5cm} $\square$

\vspace{0.15cm}
\noindent
There are several ways to circumvent the problem 
in Subsetup 2.
In the following, we discuss in more detail our 
abovementioned new encompassing approach:

\vspace{-0.1cm}

\enlargethispage{0.5cm}

\begin{enumerate}

\item[(Enc1)] take the encompassing aggregator $\lambda := \lambda_{1} + \lambda_{2}$
and the imbedding
$\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)} := 
\big\{\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)\big\}_{x \in \mathcal{X}}$
with
$\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x) := \mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(x) 
\cdot \boldsymbol{1}_{\mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega))}(x)$;\\[-0.15cm]

\item[(Enc2)]  choose a ``sufficiently discriminating'' (e.g. encompassing) divergence 
$D_{\lambda}(\cdot,\cdot)$ from above
and evaluate them with the density-functions obtained in (Enc1); \\[-0.25cm]

\item[(Enc3)]  solve the corresponding noisy minimization problem 

\vspace{-0.5cm}

\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle
\widehat{\theta}_{N}(\omega) := \widehat{\theta}_{N,D_{\lambda}}(\omega)
:= \arginf_{\theta \in \Theta} \ 
D_{\lambda}\big(
\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},
\widecheck{\mathbbm{\overrightharp{Q}}}_{\theta}
\big) 
\label{15enc}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
for $\widecheck{\mathbbm{\overrightharp{Q}}}_{\theta} := \mathbbm{\overrightharp{Q}}_{\theta}$
respectively $\widecheck{\mathbbm{\overrightharp{Q}}}_{\theta} := \widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}$
(to be defined right below);

\item[(Enc4)]  compute the noisy minimal distance
$D_{\lambda}\big(
\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},
\widecheck{\mathbbm{\overrightharp{Q}}}_{\theta}
\big) > 0$ 
as an indicator of ``goodness of fit'' (goodness of noisy approximation'');

\item[(Enc5)]  investigate sound statistical properties of the outcoming estimator $\widehat{\theta}_{N}(\omega)$,
e.g. show probabilistic convergence (as $N$ tends to infinity) to the true unknown parameter $\theta_{0}$,
compute the corresponding convergence speed, analyze its robustness against data-contamination, etc.

\end{enumerate}
 
\noindent
Typically, for fixed $N$ the step (Enc3) is not straightforward to solve,  
and consequently, the tasks described in the unavoidable step (Enc4) become 
even much more complicated; a detailed discussion of both is -- for the sake of brevity --
beyond the scope of this paper. As far as (Enc1) is concerned, things are non-trivial
due to the generally well-known fact that ``continuous'' densities are only 
almost-surely unique. Indeed, consider e.g. the case 
where 
the $\theta-$family of functions 
$\mathbbm{\overrightharp{Q}}_{\theta} := \big\{\mathbbm{\overrightharp{q}}_{\theta}(x)\big\}_{x \in \mathcal{X}}$
satisfies

\vspace{-0.5cm}

\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle 
\mathbbm{\overrightharp{q}}_{\theta}(x) >0 \ \  \textrm{for all $x \in \mathcal{X}$}
\ \  \textrm{and} \ \ 
\mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{2}}_{\theta}[\mathcal{X}]
= \int_{\mathcal{X}} \mathbbm{\overrightharp{q}}_{\theta}(x) \, \mathrm{d}\lambda_{2}(x) =1
\quad \textrm{for all $\theta \in \Theta$} \qquad \ \ 
\label{brostu2:fo.enc20}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
and the alternative $\theta-$family of functions 
$\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta} := 
\big\{\widetilde{\mathbbm{\overrightharp{q}}}_{\theta}(x)\big\}_{x \in \mathcal{X}}$
defined by $\widetilde{\mathbbm{\overrightharp{q}}}_{\theta}(x)
:= \mathbbm{\overrightharp{q}}_{\theta}(x) \cdot (1 - \boldsymbol{1}_{\mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega))}(x))$;
for the latter, one obtains

\vspace{-0.5cm}

\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle 
\widetilde{\mathfrak{\overrightharp{Q}}}^{\mathbb{1}\cdot \lambda_{2}}_{\theta}[\mathcal{X}]
= \int_{\mathcal{X}} \widetilde{\mathbbm{\overrightharp{q}}}_{\theta}(x) \, \mathrm{d}\lambda_{2}(x) 
= \int_{\mathcal{X}} \widetilde{\mathbbm{\overrightharp{q}}}_{\theta}(x) \, \mathrm{d}(\lambda_{1}+\lambda_{2})(x)
=1
\quad \textrm{for all $\theta \in \Theta$} . \qquad \ \  
\label{brostu2:fo.enc21}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
Furthermore, due to \eqref{brostu2:fo.def.pnempcont} one has 

\vspace{-0.6cm}

\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle 
1 = \mathfrak{\overrightharp{P}}_{N}^{\overline{emp}(\omega)}[\mathcal{X}]
= \int_{\mathcal{X}} \mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x) \ \mathrm{d}\lambda_{1}(x)   
= \int_{\mathcal{X}} \mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x) \ \mathrm{d}(\lambda_{1}+\lambda_{2})(x)
\qquad \ \ 
\label{brostu2:fo.enc22}
\end{eqnarray}

\vspace{-0.2cm}
\noindent
and the validity of \eqref{brostu2:fo.Sing.1} to \eqref{brostu2:fo.Sing.3} 
with $\mathbbm{p}(x):= \mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)$,
$\mathbbm{q}(x):= \widetilde{\mathbbm{\overrightharp{q}}}_{\theta}(x)$ 
and $\lambda=$ $\lambda_{1}+\lambda_{2}$;
in other words, there holds the singularity (measure-theoretical orthogona\-lity) $\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)} \perp \widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}$ for all $\theta \in \Theta$.
Accordingly, for the step (Enc2) one can e.g. take directly the (family of) 
encompassing divergences  
$D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q}^{\chi},\lambda}(\mathbbm{P},\mathbbm{Q})$
of \eqref{brostu2:fo.div.new0} for 
$\mathbbm{P}:= \mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)}$,$\mathbbm{Q}:= \widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}$, $\lambda:= \lambda_{1} + \lambda_{2}$,
$\mathbbm{r}(x) \equiv 1$, and apply \eqref{brostu2:fo.div.new3} to get

\vspace{-0.5cm}

\enlargethispage{0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{1}\cdot \mathbbm{Q}^{\chi},\lambda}(\mathbbm{P},\mathbbm{Q})  
= \phi_{\chi}^{*}(0) \cdot
\sum_{x \in \mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega))} 
\big(\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(x)\big)^{\chi} 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle
+ \big[ \phi(0) + \phi_{+,c}^{\prime}(1) - \phi(1) \big] \cdot 
\int_{{\mathcal{X}}} 
\big(\mathbbm{\overrightharp{q}}_{\theta}(x)\big)^{\chi} 
\, \mathrm{d}\lambda_{2}(x) \, ;  
\label{brostu2:fo.enc23}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
hence, the corresponding solution of (Enc3) does not depend on 
the data-observations $Y_{1}(\omega), \ldots, Y_{N}(\omega)$, and thus is 
``statistically non-relevant''.
As an important remark for the rest of this paper, let us mention that -- only -- 
in situations where no observations are taken into account, then 
$\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta} = \mathbbm{\overrightharp{Q}}_{\theta}$,
$\mathcal{R}(Y_1, \ldots, Y_N) = \emptyset$, and $\lambda_{1}$ collapses to
the ``zero aggregator'' (i.e. $\lambda_{1}[\bullet] \equiv 0$).


\vspace{0.15cm} 
\noindent
In contrast, let us replace the alternative $\theta-$family
$\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}$
by the original $\mathbbm{\overrightharp{Q}}_{\theta}$,
on which $\lambda_{1}$ acts differently. In fact, instead of \eqref{brostu2:fo.enc21} there holds 

\vspace{-0.6cm}

\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle 
1 = \mathfrak{\overrightharp{Q}}^{\mathbb{1}\cdot \lambda_{2}}_{\theta}[\mathcal{X}]
= \int_{\mathcal{X}} \mathbbm{\overrightharp{q}}_{\theta}(x) \, \mathrm{d}\lambda_{2}(x) 
< \int_{\mathcal{X}} \mathbbm{\overrightharp{q}}_{\theta}(x) \, \mathrm{d}(\lambda_{1}+\lambda_{2})(x)
\nonumber\\
& & \hspace{-0.2cm}   \textstyle
= 1 + \sum_{x \in \mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega))} 
\mathbbm{\overrightharp{q}}_{\theta}(x)
\qquad \textrm{for all $\theta \in \Theta$} \, ;  
\label{brostu2:fo.enc24}
\end{eqnarray}

\vspace{-0.3cm}

\noindent
moreover, one has for all $\theta \in \Theta$ the non-singularity 
$\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)} \not\perp 
\mathbbm{\overrightharp{Q}}_{\theta}$  but 

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
\boldsymbol{1}_{\{0\}}\big(\mathbbm{\overrightharp{q}}_{\theta}(x)\big) = 0 \quad \textrm{for 
all $x \in \mathcal{X}$},
\label{brostu2:fo.enc25}
\\
& & \hspace{-0.2cm}   \textstyle
\boldsymbol{1}_{\{0\}}\big(\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)\big)
= 1 - \boldsymbol{1}_{\mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega))}(x) \quad  \textrm{for 
all $x \in \mathcal{X}$},
\label{brostu2:fo.enc26}
\\
& & \hspace{-0.2cm}   \textstyle
\boldsymbol{1}_{]0,\infty[}\big(
\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x) \cdot \mathbbm{\overrightharp{q}}_{\theta}(x)
\big)
= \boldsymbol{1}_{\mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega))}(x) \quad  \textrm{for 
all $x \in \mathcal{X}$} \, . 
\label{brostu2:fo.enc27}
\end{eqnarray}

\vspace{-0.1cm}

\noindent
Correspondingly, for the step (Enc2) one can e.g. take directly the (family of) 
encompassing divergences  
$D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{R}\cdot \mathbbm{Q}^{\chi},\lambda}(\mathbbm{P},\mathbbm{Q})$
of \eqref{brostu2:fo.div.new0} for $\mathbbm{P}:= \mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)}$, 
$\mathbbm{Q}:= \mathbbm{\overrightharp{Q}}_{\theta}$, $\lambda:= \lambda_{1} + \lambda_{2}$,
$\mathbbm{r}(x) \equiv 1$;  
the corresponding solution of the noisy minimization problem (Enc3) generally \textit{does depend} on 
the data-observations $Y_{1}(\omega), \ldots, Y_{N}(\omega)$, as required.
Let us demonstrate this exemplarily for the special subsetup where 
$\phi:[0,\infty[ \rightarrow [0,\infty[$ is continuous (e.g. strictly convex on $]0,\infty[$),
differentiable at $1$, $\phi(1) = \phi^{\prime}(1) = 0$, 
$\phi(t) \in ]0,\infty[$ for all $t \in [0,1[ \cup[1,\infty[$, 
$\chi >1$, $\mathbbm{r}(x) \equiv 1$,
and $\int_{{\mathcal{X}}} 
\mathbbm{\overrightharp{q}}_{\theta}(x)^{\chi} \, \mathrm{d}\lambda_{2}(x) \in ]0,\infty[$ 
for all $\theta \in \Theta$. Then, for each fixed $\theta \in \Theta$ we derive from
\eqref{brostu2:fo.div.new0} and \eqref{brostu2:fo.enc25} to \eqref{brostu2:fo.enc27} the divergence

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 < D_{\phi,\mathbbm{\overrightharp{Q}}_{\theta},\mathbbm{\overrightharp{Q}}_{\theta},\mathbb{1}\cdot 
\mathbbm{\overrightharp{Q}}_{\theta}^{\ \chi},\lambda_{1}+\lambda_{2}}\big(
\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\mathbbm{\overrightharp{Q}}_{\theta}\big)
\nonumber\\  
& & \hspace{-0.2cm}   \textstyle 
=
\int_{{\mathcal{X}}} 
\mathbbm{\overrightharp{q}}_{\theta}(x)^{\chi} \cdot \phi  \big( {
\frac{\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}}\big) 
\cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x) 
\cdot \mathbbm{\overrightharp{q}}_{\theta}(x) 
\big)
\, \mathrm{d}(\lambda_{1}+\lambda_{2})(x) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle  
+ \, \phi(0) \cdot 
\int_{{\mathcal{X}}} 
\mathbbm{\overrightharp{q}}_{\theta}(x)^{\chi}
\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)\big)
\, \mathrm{d}(\lambda_{1}+\lambda_{2})(x)
\nonumber\\  
& & \hspace{-0.2cm}   \textstyle 
=   \sum_{x \in \mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega))} 
\mathbbm{\overrightharp{q}}_{\theta}(x)^{\chi}
\cdot \phi  \big( {
\frac{\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}}\big)
+ \phi(0) \cdot \int_{{\mathcal{X}}} \mathbbm{\overrightharp{q}}_{\theta}(x)^{\chi} 
\, \mathrm{d}\lambda_{2}(x) < \infty \, . \qquad \ 
\label{brostu2:fo.enc29}
\end{eqnarray}


\vspace{-0.3cm}

\noindent
When choosing this divergence \eqref{brostu2:fo.enc29} in step (Enc2), 
we call the solution $\widehat{\theta}_{N}(\omega)$
of the corresponding noisy minimization problem \eqref{15enc}
of step (Enc3) a
\textit{minimum $(\phi,\chi)-$divergence estimator} of the true unknown
parameter $\theta_{0}$; in ML and AI contexts, the pair $(\phi,\chi)$ may be regarded as ``hyperparameter''.
Exemplarily, for the power functions $\phi := \phi_{\alpha}$  (cf. \eqref{brostu2:fo.def.32})
with $\alpha = \chi >1$, we obtain from \eqref{brostu2:fo.enc29}
(see also \eqref{brostu2:fo.div.ex.279}, \eqref{brostu2:fo.def.140a})
the divergence

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
]0,\infty[ \ni D_{\phi_{\alpha},\mathbbm{\overrightharp{Q}}_{\theta},\mathbbm{\overrightharp{Q}}_{\theta},\mathbb{1}\cdot 
\mathbbm{\overrightharp{Q}}_{\theta}^{\ \alpha},\lambda_{1}+\lambda_{2}}\big(
\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\mathbbm{\overrightharp{Q}}_{\theta}\big)
\ = \ \frac{1}{\alpha} \cdot \int_{{\mathcal{X}}} \mathbbm{\overrightharp{q}}_{\theta}(x)^{\alpha} 
\, \mathrm{d}\lambda_{2}(x)
\nonumber\\  
& & \hspace{-0.2cm}   \textstyle 
+  \sum_{x \in \mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega))}
\big[
\frac{(\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(x))^{\alpha}}{\alpha \cdot (\alpha-1)} 
- \mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(x) \cdot \frac{\mathbbm{\overrightharp{q}}_{\theta}(x)^{\alpha-1}}{\alpha-1} 
+ \frac{\mathbbm{\overrightharp{q}}_{\theta}(x)^{\alpha}}{\alpha}
\big]
\nonumber\\  
& & \hspace{-0.2cm}   \textstyle
\ = \ \frac{1}{\alpha} \cdot \int_{{\mathcal{X}}} \mathbbm{\overrightharp{q}}_{\theta}(x)^{\alpha} 
\, \mathrm{d}\lambda_{2}(x)
\nonumber\\  
& & \hspace{-0.2cm}   \textstyle 
+ \frac{1}{N} \sum_{i=1}^{N} \big[
\frac{(\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega)))^{\alpha-1}}{\alpha \cdot (\alpha-1)}
- \frac{\mathbbm{\overrightharp{q}}_{\theta}(Y_{i}(\omega))^{\alpha-1}}{\alpha-1}
+ \frac{\mathbbm{\overrightharp{q}}_{\theta}(Y_{i}(\omega))^{\alpha}}{\alpha \cdot 
\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))} 
\big] \, , \qquad \ 
\label{brostu2:fo.enc30}
\end{eqnarray} 

\vspace{-0.2cm}

\noindent 
where for the last equality we have used the representation

\vspace{-0.5cm}

\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle 
\sum_{x \in \mathcal{X}} 
\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(x) \cdot
\boldsymbol{1}_{\mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega))}(x)
\cdot \delta_{x}[\bullet]
\ = \ \frac{1}{N} \cdot \sum_{i=1}^{N}  \delta_{Y_{i}(\omega)}[\bullet] \, ; 
\label{brostu2:fo.enc32}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
notice that
$\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))
= \#\{j \in \{1,\ldots,N\}\, : \, Y_{j}(\omega) = Y_{i}(\omega) \} /N$.
Clearly, the outcoming 
minimum $(\phi,\chi)-$divergence estimator of \eqref{brostu2:fo.enc29}
(and in particular, the minimum $(\phi_{\alpha},\alpha)-$divergence estimator of \eqref{brostu2:fo.enc30})
depends
on the data observations $Y_{1}(\omega), \ldots, Y_{N}(\omega)$,
where for technical reasons as e.g. existence and uniqueness --
as well as for the tasks (Enc4), (Enc5) -- 
some further assumptions are generally needed; for the sake of brevity,
corresponding details 
will appear in a forthcoming paper. 

\vspace{-0.3cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Minimum divergences - grouping and smoothing}
\label{subsec.4anew.6}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\noindent
Next, we briefly indicate two other ways to circumvent
the problem described in Subsetup 2 of Section \ref{subsec.4anew.3}, with
continuous (nonatomic) $\mathcal{Q}_{\Theta}^{\lambda_{2}}$ and $\lambda_{2}$ 
from \eqref{brostu2:fo.def.contfam1}:

\vspace{-0.2cm}

\begin{enumerate}

\item[(GR)] grouping of data: \  
convert everything into a purely discrete context, by
subdividing the data-point-set $\mathcal{X} = \bigcup_{j=1}^{s} A_{j}$
into countably many --
(say) $s \in \mathbb{N}\cup\{\infty\} \backslash\{1\}$ -- 
(measurable) disjoint classes $A_{1}, \ldots, A_{s}$ with the property 
$\lambda_{2}[A_{j}] >0$ 
(``essential partition'');
proceed as in Subsetup 1 of Section \ref{subsec.4anew.3}, with 
$\mathcal{X}^{new} := \{A_{1}, \ldots, A_{s}\}$ instead of
$\{z_1, \ldots, z_s\}$,
and thus the $i-$th data observation $Y_{i}(\omega)$ 
and the corresponding running variable $x$) manifest (only) the
corresponding class-membership; clearly, the 
minimum-divergence-estimation result depends on the partitioning,
and corresponding robustness becomes a major object of investigation;

\vspace{0.1cm}

\item[(SM)] smoothing of empirical density function:
convert everything to a purely continuous context,
by keeping the original data-point-set $\mathcal{X}$
and by ``continuously extending'' (e.g. with the help of kernels)
the empirical density $\mathbbm{\overrightharp{p}}_{N}^{emp}(\cdot)$
to a function $\mathbbm{\overrightharp{p}}_{N}^{emp,smo}(\cdot) \geq 0$ such that 
$\int_{\mathcal{X}} \mathbbm{\overrightharp{p}}_{N}^{emp,smo}(x) \, \mathrm{d}\lambda_{2}(x) =1$
and for all $\theta \in \Theta$ there holds:
$\mathbbm{\overrightharp{p}}_{N}^{emp,smo}(x)=0$ if and only if
$\mathbbm{\overrightharp{q}}_{\theta}(x)=0$
(in addition to \eqref{brostu2:fo.mesequ});
of course, the minimum-divergence-estimation result depends on the smoothing methods,
and corresponding robustness needs to be 
addressed. Due to the ``curse of
dimensionality'', such a solution cannot be applied successfully in a 
large-dimension setting, as required in the so called ``big data'' paradigm. 

\end{enumerate}
For the sake of brevity, a detailed discussion is beyond the scope of
this paper.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Minimum divergences - 
%imbedding of the plug-in method
%modified encompassing versus plug-in
the decomposability method}
\label{subsec.4anew.4}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.1cm}

Let us discuss yet another strategy to circumvent the problem described 
in Subsetup 2 of Section \ref{subsec.4anew.3}. As a motivation,
for a divergence of the form

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 \leq D_{\lambda}(\mathbbm{P},\mathbbm{Q})
= \int_{{\mathcal{X}}} 
f_{1}(x) \cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) \big)
 \, \mathrm{d}\lambda(x) 
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ \int_{{\mathcal{X}}} f_{2}(x) \cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big) 
\cdot \boldsymbol{1}_{]0,\infty[}(\mathbbm{q}(x)) \, \mathrm{d}\lambda(x)
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ \int_{{\mathcal{X}}} f_{3}(x) \cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big) 
\cdot \boldsymbol{1}_{]0,\infty[}(\mathbbm{p}(x)) \, \mathrm{d}\lambda(x) \qquad \ \ 
\label{brostu2:fo.def.191b}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
with $f_{1}(x)\geq 0$, $f_{2}(x)\geq 0$, $f_{3}(x)\geq 0$, 
and an ``adjacent'' dissimilarity

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\widetilde{D_{\lambda}}(\mathbbm{P},\mathbbm{Q})
= \int_{{\mathcal{X}}} 
f_{1}(x) \cdot \boldsymbol{1}_{]0,\infty[}\big(\mathbbm{p}(x) \cdot \mathbbm{q}(x) \big)
 \, \mathrm{d}\lambda(x) 
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ \int_{{\mathcal{X}}} g_{2}(x) )\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{p}(x)\big) 
\cdot \boldsymbol{1}_{]0,\infty[}(\mathbbm{q}(x)) \, \mathrm{d}\lambda(x)
\nonumber \\ 
& & \hspace{-0.2cm}   \textstyle 
+ \int_{{\mathcal{X}}} g_{3}(x) )\cdot \boldsymbol{1}_{\{0\}}\big(\mathbbm{q}(x)\big) 
\cdot \boldsymbol{1}_{]0,\infty[}(\mathbbm{p}(x)) \, \mathrm{d}\lambda(x), \qquad \ \ 
\label{brostu2:fo.def.191c}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
there holds $D_{\lambda}(\mathbbm{P},\mathbbm{Q}) = \widetilde{D_{\lambda}}(\mathbbm{P},\mathbbm{Q})$
for all equivalent $\mathbbm{P} \sim \mathbbm{Q}$ (where for both, the second and third integral become zero),
but (in case that $g_{2}(\cdot)$, $g_{3}(\cdot)$ differ sufficiently enough from $f_{2}(\cdot)$, $f_{3}(\cdot)$)
one gets $D_{\lambda}(\mathbbm{P},\mathbbm{Q}) \neq \widetilde{D_{\lambda}}(\mathbbm{P},\mathbbm{Q})$
for $\mathbbm{P} \perp \mathbbm{Q}$  and even for $\mathbbm{P} \not\sim \mathbbm{Q}$;
in the latter two cases, depending on the signs of $g_{2}(\cdot)$, $g_{3}(\cdot)$, 
$\widetilde{D_{\lambda}}(\mathbbm{P},\mathbbm{Q})$ may even become negative.

\vspace{0.1cm}
\noindent
Such issues are of importance for our current problem where e.g.
$\mathbbm{P} := \mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)} 
\perp \widetilde{\mathbbm{\overrightharp{Q}}}_{\theta} =: \mathbbm{Q}$.
For further illuminations, and for the sake of a compact presentation, we
use henceforth the 
notations 
$\mathcal{P}^{\lambda}$
for an arbitrarily fixed class of nonnegative,
mutually equivalent 
functions (i.e. $\mathbbm{P}_{1} \sim \mathbbm{P}_{2}$ 
for all 
$\mathbbm{P}_{1} \in \mathcal{P}^{\lambda}$, $\mathbbm{P}_{2} \in \mathcal{P}^{\lambda}$), 
and $\mathcal{P}^{\lambda\not\sim}$ for a corresponding class of nonnegative
(not necessarily mutually equivalent) functions 
such that $\mathbbm{P}_{1} \not\sim \mathbbm{P}_{2}$ for all 
$\mathbbm{P}_{1} \in \mathcal{P}$, $\mathbbm{P}_{2} \in \mathcal{P}^{\lambda\not\sim}$.
Furthermore, we employ $\widetilde{\mathcal{P}}^{\lambda} := \mathcal{P}^{\lambda} \cup \mathcal{P}^{\lambda\not\sim}$
and specify:

\vspace{-0.1cm} 

\begin{definition}
\label{brostu2:def.pseudo}
We say that a function 
$D_{\lambda}: \widetilde{\mathcal{P}}^{\lambda} \otimes \mathcal{P}^{\lambda} \rightarrow \mathbb{R}$
is \textrm{a pseudo-divergence on $\widetilde{\mathcal{P}}^{\lambda} \times \mathcal{P}^{\lambda}$}, 
if its restriction to $\mathcal{P}^{\lambda} \cup \mathcal{P}^{\lambda}$ is a divergence, i.e. 

\vspace{-0.55cm}
 
\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle 
D_{\lambda}( \mathbbm{P},\mathbbm{Q}) \geq 0 \ \ \textrm{for all} \ \
\mathbbm{P} \in \mathcal{P}^{\lambda},\mathbbm{Q} \in \mathcal{P}^{\lambda}, \quad \textrm{and}
\label{brostu2:fo.def.pseudo1}
\\ 
& & \hspace{-0.2cm}   \textstyle 
D_{\lambda}( \mathbbm{P},\mathbbm{Q}) = 0 \ \ \textrm{if and only if} \ \  
\mathbbm{P} = \mathbbm{Q} \in \mathcal{P}^{\lambda} \, .
\nonumber 
\end{eqnarray}

\vspace{-0.2cm}

\noindent
If also $D_{\lambda}( \mathbbm{P},\mathbbm{Q}) > 0$ for all
$\mathbbm{P} \in \mathcal{P}^{\lambda\not\sim}$,$\mathbbm{Q} \in \mathcal{P}^{\lambda}$,
then $D_{\lambda}(\cdot,\cdot)$ is a divergence.

\end{definition}
As for interpretation, a pseudo-divergence $D_{\lambda}( \cdot,\cdot)$ acts like a divergence 
if both arguments are from $\mathcal{P}^{\lambda}$, but only like a dissimilarity if
the first argument is from $\mathcal{P}^{\lambda\not\sim}$ 
and thus is ``quite different'' from the second argument.
In the following, we often use pseudo-divergences for our 
noisy minimum-distance-estimation problem 
-- cf. \eqref{9a}, \eqref{15} -- by taking $\lambda=\lambda_{1}+\lambda_{2}$,
$\mathcal{P}^{\lambda} := \mathcal{P}_{\Theta}^{\lambda} := \big(\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\big)_{\theta \in \Theta} := 
\big(\big\{\widetilde{\mathbbm{\overrightharp{q}}}_{\theta}(x)\big\}_{x \in \mathcal{X}}\big)_{\theta \in \Theta}$
(cf. \eqref{brostu2:fo.enc20}, \eqref{brostu2:fo.enc21}),
and 
$\mathcal{P}^{\lambda\not\sim} := \mathcal{P}_{emp}^{\lambda\perp} := 
\big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)}\big)_{N \in \mathbb{N}}
=\big(
\big\{\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)\big\}_{x \in \mathcal{X}}
\big)_{N \in \mathbb{N}}
$
(cf. \eqref{brostu2:fo.def.pnempcont}, (Enc1))
covering all numbers $N$ of 
data observations (sample sizes), and 
the according
$\widetilde{\mathcal{P}}^{\lambda} := \mathcal{P}_{\Theta,emp}^{\lambda} =  
\mathcal{P}_{\Theta}^{\lambda} \cup \mathcal{P}_{emp}^{\lambda\perp}$; 
notice that by construction we have even the function-class-relationship 
$\perp$ which is stronger than $\not\sim$.
In such a setup, we have seen that for the choice $\mathbbm{P}:= \mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)}$, 
$\mathbbm{Q}:= \widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}$
the divergence 
$D^{c}_{\phi,\mathbbm{Q},\mathbbm{Q},\mathbb{1}\cdot \mathbbm{Q}^{\chi},\lambda}(\mathbbm{P},\mathbbm{Q}) > 0$
of \eqref{brostu2:fo.enc23} is unpleasant for (Enc3) since the 
solution does not depend on the data-observations $Y_{1}(\omega), \ldots, Y_{N}(\omega)$;
also recall the special case of power functions $\phi := \phi_{\alpha}$  (cf. \eqref{brostu2:fo.def.32})
with $\alpha = \chi >1$ which amounts to the 
unscaled divergences \eqref{brostu2:fo.div.ex.279}, \eqref{brostu2:fo.def.140a0}
and thus to \eqref{brostu2:fo.def.140a}. 
In \eqref{brostu2:fo.enc29}, for general $\phi$ we have repaired this deficiency  
by replacing $\mathbbm{Q}:= \widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}$
with $\mathbbm{Q}:= \mathbbm{\overrightharp{Q}}_{\theta}$, at the cost of
getting total mass larger than $1$ but by keeping the strict positivity of
the involved divergence; especially for $\phi := \phi_{\alpha}$,
the divergence \eqref{brostu2:fo.def.140a} has then amounted to \eqref{brostu2:fo.enc30}.

\vspace{0.2cm}
\noindent In contrast, let us show another method to repair the (Enc3)-deficiency of \eqref{brostu2:fo.def.140a},
by sticking to $\mathbbm{Q}:= \widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}$ but
changing the basically underlying divergence.
In fact, we deal with the even more general

\vspace{-0.1cm}
 
\begin{definition}
\label{brostu2:def.dec}
(a) \ We say that a pseudo-divergence
$D_{\lambda}: \widetilde{\mathcal{P}}^{\lambda} \otimes \mathcal{P}^{\lambda} \rightarrow \mathbb{R}$
is decomposable if there exist
functionals $\mathfrak{D}^{0}: \widetilde{\mathcal{P}}^{\lambda} \mapsto \mathbb{R}$, 
$\mathfrak{D}^{1}:\mathcal{Q}\mapsto \mathbb{R}$ 
and (measurable) mappings
$\rho_{\mathbbm{Q}}:\mathcal{X} \mapsto \mathbb{R}$ 
\ (for each $\mathbbm{Q} \in \mathcal{P}^{\lambda}$) \    
such that
\footnote{
\label{brostu2:foot1}
in an encompassing way, the part (a) reflects a measure-theoretic ``plug-in'' version of decomposable pseudo-divergences
$D: (\mathcal{P}^{meas,\lambda_1} \cup \mathcal{P}^{meas,\lambda_2}) 
 \otimes \mathcal{P}^{meas,\lambda_1} \mapsto \mathbb{R}$,
where $\mathcal{P}^{meas,\lambda_1}$ is a family of mutually equivalent nonnegative measures
of the form $\mathfrak{P}[\bullet] := \mathfrak{P}^{\mathbbm{1} \cdot \lambda_{1}}[\bullet] : = 
\int_{\bullet} \mathbbm{p}(x) \, \mathrm{d}\lambda_{1}(x)$, 
$\mathcal{P}^{meas,\lambda_2}$ is a family of nonnegative measures of the form
$\overline{\mathfrak{P}}[\bullet]:= \overline{\mathfrak{P}}^{\mathbbm{1} \cdot \lambda_{2}}[\bullet] : = 
\int_{\bullet} \mathbbm{q}(x) \, \mathrm{d}\lambda_{2}(x)$ such that
any $\mathfrak{P} \in \mathcal{P}^{meas,\lambda_1}$ is not equivalent to 
any $\overline{\mathfrak{P}} \in \mathcal{P}^{meas,\lambda_2}$, 
 and
\eqref{26anew} is replaced with
$D(\mathfrak{P},\mathfrak{Q})=\mathfrak{D}^{0}(\mathfrak{P})+\mathfrak{D}^{1}(\mathfrak{Q})
+\int_{\mathcal{X}} \rho_{\mathfrak{Q}}(x) \, \mathrm{d}\mathfrak{P}(x)
\quad \text{for all }\mathbbm{P} \in \mathfrak{P} \in \mathcal{P}^{meas,\lambda_1}\cup \mathcal{P}^{meas,\lambda_2},
\mathfrak{Q} \in \mathcal{P}^{meas,\lambda_2}$; cf. Vajda~\cite{Vaj:08}, 
Broniatowski \& Vajda~\cite{Bro:12a}, Broniatowski al.~\cite{Bro:12b};
part (b) is new.
}

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
D_{\lambda}(\mathbbm{P},\mathbbm{Q})=\mathfrak{D}^{0}(\mathbbm{P})+\mathfrak{D}^{1}(\mathbbm{Q})
+\int_{\mathcal{X}} \rho_{\mathbbm{Q}}(x) \cdot \mathbbm{p}(x) \, \mathrm{d}\lambda(x)
\quad \text{for all }\mathbbm{P} \in \widetilde{\mathcal{P}}^{\lambda},
\mathbbm{Q} \in \mathcal{P}^{\lambda}. \qquad \  
\label{26anew}
\end{eqnarray} 

\vspace{-0.3cm}

\noindent
(b)  \ We say that a pseudo-divergence
$D_{\lambda}: \widetilde{\mathcal{P}}^{\lambda} \otimes \mathcal{P}^{\lambda} \rightarrow \mathbb{R}$
is pointwise decomposable if it is of the form
$D_{\lambda}(\mathbbm{P},\mathbbm{Q}) = 
\int_\mathcal{X} \psi(\mathbbm{p}(x), \mathbbm{q}(x))  \, \mathrm{d}\lambda(x)$ 
for some (measurable) mapping $\psi^{dec}: [0,\infty[ \times [0,\infty[ \mapsto \mathbb{R}$
with representation

\vspace{-0.6cm} 

\enlargethispage{0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\psi^{dec}(s,t) := \psi^{0}\big(s + h_{0}(x,s) \cdot \boldsymbol{1}_{\{0\}}(t)\big)
\cdot \boldsymbol{1}_{]\overline{c}_{0},\infty[}(s) \cdot \boldsymbol{1}_{]c_{0},\infty[}(t)
\nonumber \\[-0.1cm] 
& & \hspace{-0.2cm}  
+\psi^{1}\big(t + h_{1}(x) \cdot \boldsymbol{1}_{\{0\}}(t)\big) \cdot \boldsymbol{1}_{]c_{1},\infty[}(t)
\nonumber \\ 
& & \hspace{-0.2cm}  
+ \rho\big(t + h_{2}(x) \cdot \boldsymbol{1}_{\{0\}}(t)\big) \cdot s \quad
\textrm{ for all $(s,t) \in [0,\infty[ \times [0,\infty[ \backslash \{(0,0)\}$} \ , \qquad \ \ 
\label{27new}
\\ 
& & \hspace{-0.2cm}   \textstyle 
\psi^{dec}(0,0):=0,
\nonumber
\end{eqnarray}

\vspace{-0.2cm}

\noindent
with constants $c_{0},c_{1},\overline{c}_{0} \in \{0,1\}$, and (measurable) mappings  
$\psi^{0},\psi^{1},\rho : [0,\infty[ \mapsto \mathbb{R}$,
$h_{1},h_{2} : \mathcal{X} \mapsto [0,\infty[$, 
$h_{0} : \mathcal{X} \times [0,\infty[  \mapsto \mathbb{R}$, 
such that

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\psi^{dec}(s,t)= \psi^{0}(s) +\psi^{1}(t) + \rho(t) \cdot s \geq 0 \quad
\textrm{for all $(s,t) \in ]0,\infty[ \times ]0,\infty[$} \, , \quad \ 
\label{27newb}
\\
& & \hspace{-0.2cm}   \textstyle
\psi^{dec}(s,t) = 0 \quad \textrm{if and only if} \quad s=t \, ,
\label{27newc}
\\
& & \hspace{-0.2cm}   \textstyle
s + h_{0}(x,s) \geq 0 \qquad \textrm{for all $s \in [0,\infty[$ and $\lambda-$almost all $x \in \mathcal{X}$} \, .
\nonumber
\end{eqnarray}

\end{definition}

\vspace{-0.2cm}

\begin{remark}
(a) \ Any pointwise decomposable pseudo-divergence is decomposable, under the additional assumption
that the integral $\int_\mathcal{X} \ldots  \, \mathrm{d}\lambda(x)$
can be split into three appropriate parts.\\
(b) \ For use in (Enc3), $\mathfrak{D}^{1}(\cdot)$ and $\rho_{\mathbbm{Q}}(\cdot)$ should be non-constant.\\
(c) \ In the Definitions \ref{brostu2:def.pseudo} and \ref{brostu2:def.dec}
we have put the ``extension-role'' to the first component $\mathbbm{P}$;
of course, everything can be worked out analogously  for the second component $\mathbbm{Q}$
by using  (pseudo-)divergences
$D_{\lambda}:  \mathcal{P}^{\lambda} \times \widetilde{\mathcal{P}}^{\lambda} \rightarrow \mathbb{R}$.\\
(d) \ We could even extend \eqref{27new} for bivariate functions $h_{1}(x,s)$, $h_{2}(x,s)$. $\square$

\end{remark}

\vspace{-0.05cm}

\noindent
Notice that from \eqref{27new} one obtains the boundary behaviour 

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\mathbb{R} \ni \psi^{dec}(s,0) = \psi^{0}(s+h_{0}(x,s)) \cdot \widecheck{c_{0}}
+\psi^{1}(h_{1}(x)) \cdot \widecheck{c_{1}} + \rho(h_{2}(x)) \cdot s  \quad 
\textrm{for all $s >0$} \, , \qquad \ \ 
\label{27newe}
\\
& & \hspace{-0.2cm}   \textstyle
\mathbb{R} \ni \psi^{dec}(0,t) = \psi^{0}(0) \cdot \widecheck{\overline{c}_{0}} +\psi^{1}(t) \quad 
\textrm{for all $t >0$} \, , \quad \ 
\label{27newf}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
with  
$\widecheck{c_{0}} := \boldsymbol{1}_{]c_{0},\infty[}(0)$,
$\widecheck{c_{1}} := \boldsymbol{1}_{]c_{1},\infty[}(0)$,
$\widecheck{\overline{c}_{0}} := \boldsymbol{1}_{]\overline{c}_{0},\infty[}(0)$.
Notice that $\psi^{dec}(s,0)$ of \eqref{27newe} does generally not coincide with
the eventually existent ``\eqref{27newb}-limit'' $\lim_{t \rightarrow 0} [\psi^{0}(s) +\psi^{1}(t) + \rho(t) \cdot s]$ 
\ ($s>0$), which reflects a possibly ``non-smooth boundary behaviour''
(also recall \eqref{brostu2:fo.def.191b}, \eqref{brostu2:fo.def.191c}). 
Moreover, when choosing 
a decomposable pseudo-divergence \eqref{26anew} in step (Enc2), 
we operationalize the solution $\widehat{\theta}_{N}(\omega)$
of the corresponding noisy minimization problem \eqref{15enc}
of step (Enc3) as follows:

\begin{definition}
\label{Def3.3new}
(a) \ We say that a functional 
$T_{D_{\lambda}}: \mathcal{P}_{\Theta,emp}^{\lambda} \mapsto \Theta $\ 
generates a minimum decomposable pseudo-divergence estimator
(briefly, $\min-decD_{\lambda}-$estimator)

\vspace{-0.5cm}

\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle 
\widehat{\theta}_{N,decD_{\lambda}}(\omega)
:= T_{D_{\lambda}}\big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)}\big)
\quad \textrm{for} \ \ \mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)} \in 
\mathcal{P}_{emp}^{\lambda\perp}  
\label{c1new}
\end{eqnarray} 

\vspace{-0.2cm}

\noindent
of the true unknown parameter $\theta_{0}$,
if $D_{\lambda}(\cdot,\cdot): \mathcal{P}_{\Theta,emp}^{\lambda} \otimes \mathcal{P}_{\Theta}^{\lambda} 
\mapsto \mathbb{R}$\ is a decomposable pseudo-divergence and

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
T_{D_{\lambda}}\big(\mathbbm{\overrightharp{P}}\big)
=\arginf_{\theta \in \Theta}\big[ 
\mathfrak{D}^{1}(\mathbbm{\overrightharp{Q}}_{\theta})
+\int_{\mathcal{X}} \rho_{\mathbbm{\overrightharp{Q}}_{\theta}}(x) \cdot \mathbbm{\overrightharp{p}}(x) \, \mathrm{d}\lambda(x) \big]
\quad \text{for all }\mathbbm{\overrightharp{P}} \in 
\mathcal{P}_{\Theta,emp}^{\lambda}
\, . \qquad \ \ 
\label{c1newb}
\end{eqnarray}

\vspace{-0.2cm}

\noindent 
(b) If $D_{\lambda}(\cdot,\cdot)$ is a pointwise decomposable pseudo-divergence
we replace \eqref{c1newb} by 

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
T_{D_{\lambda}}\big(\mathbbm{\overrightharp{P}}\big)
=\arginf_{\theta \in \Theta}
\int_\mathcal{X} \psi^{dec}(\mathbbm{\overrightharp{p}}(x), 
\widetilde{\mathbbm{\overrightharp{q}}}_{\theta}(x))  \, \mathrm{d}\lambda(x)
\quad \text{for all }\mathbbm{\overrightharp{P}} \in 
\mathcal{P}_{\Theta,emp}^{\lambda} 
\, ,
\nonumber
\end{eqnarray} 

\vspace{-0.2cm}

\enlargethispage{0.5cm}

\noindent
but do not introduce a new notion (also recall that $\lambda=\lambda_{2}$
and $\widetilde{\mathbbm{\overrightharp{q}}}_{\theta}(\cdot)
=\mathbbm{\overrightharp{q}}_{\theta}(\cdot)$ for the case of no observations, e.g. if
$\mathbbm{\overrightharp{P}} \in 
\mathcal{P}_{\Theta}^{\lambda_{2}}$). 
\end{definition}

\noindent
To proceed, let us point out that by \eqref{c1new} and \eqref{brostu2:fo.enc32}
every $\min-decD_{\lambda}-$estimator rewrites straightforwardly as

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
\widehat{\theta}_{N,decD_{\lambda}}(\omega)
=\arginf_{\theta \in \Theta}\big[ 
\mathfrak{D}^{1}(\mathbbm{\overrightharp{Q}}_{\theta})
+ \frac{1}{N} \sum_{i=1}^{N} \rho_{\mathbbm{\overrightharp{Q}}_{\theta}}(Y_{i}(\omega)) \big]
\label{c2new}
\end{eqnarray} 

\vspace{-0.2cm}

\noindent
and is Fisher consistent in the sense that

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
T_{\mathfrak{D}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}})=\arginf_{\theta \in \Theta} \, 
\mathfrak{D}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta}) = \theta_{0}
\quad \textrm{for all $\theta_{0}\in \Theta$} \, .  
\label{c3new}
\end{eqnarray} 

\vspace{-0.2cm}

\noindent
Furthermore, the criterion
to be minimized in \eqref{c2new} is of the form 

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle
\theta \ \ \mapsto \ \ \mathfrak{D}^{1}(\mathbbm{\overrightharp{Q}}_{\theta})
+ \frac{1}{N} \sum_{i=1}^{N} \rho_{\mathbbm{\overrightharp{Q}}_{\theta}}(Y_{i}(\omega)) 
\nonumber
\end{eqnarray}

\vspace{-0.2cm}

\noindent
which e.g. for the task (Enc5) opens the possibility to apply the methods of the asymptotic theory of 
so-called $M-$estimators (cf. e.g. Hampel et al.~\cite{Ham:86}, van der Vaart and Wellner~\cite{Vaa:96}, 
Liese and Mieske~\cite{Lie:08}).
The concept of
$\min-decD_{\lambda}-$estimators \eqref{26anew}
were introduced in Vajda~\cite{Vaj:08}, Broniatowski \& Vajda~\cite{Bro:12a} within the probability-law-restriction of the
non-encompassing, ``plug-in'' context of
footnote \ref{brostu2:foot1}.

\vspace{0.2cm}
\noindent
In the following, we demonstrate that our new concept of pointwise
decomposability defined by \eqref{27new} is very useful and flexible 
for creating new $\min-decD_{\lambda}-$estimators and imbedding existing ones.
In fact, since in our current 
statistics-ML-AI 
context 
we have chosen $\lambda[\bullet] := \lambda_{1}[\bullet] + \lambda_{2}[\bullet]$ 
with $\lambda_{1}[\bullet] := \sum_{z \in \mathcal{X}} \boldsymbol{1}_{\mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega))}(z) 
\cdot  \delta_{z}[\bullet]$ and $\lambda_{2}[\bullet]$ stemming from \eqref{brostu2:fo.enc20},
we have seen that $\mathbbm{P} := \mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)} 
\perp \widetilde{\mathbbm{\overrightharp{Q}}}_{\theta} =: \mathbbm{\overrightharp{Q}}$ for all $\theta \in \Theta$.
Hence, from \eqref{27new}, \eqref{27newe}, \eqref{27newf} we obtain

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
D_{\lambda}\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big) = 
\int_\mathcal{X} 
\psi^{dec}\Big(\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x), \widetilde{\mathbbm{\overrightharp{q}}}_{\theta}(x)\Big)  
\, \mathrm{d}\lambda(x)
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
= \int_\mathcal{X} 
\Big[\psi^{0}(0) \cdot \widecheck{\overline{c}_{0}} + 
\psi^{1}\Big(\widetilde{\mathbbm{\overrightharp{q}}}_{\theta}(x)\Big)  \Big] \cdot \boldsymbol{1}_{\{0\}}(\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x))
 \ \mathrm{d}(\lambda_{1} + \lambda_{2})(x)
 \nonumber
\\
& & \hspace{-0.2cm}   \textstyle
+ \int_\mathcal{X} 
\Big[\psi^{0}\Big(\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)
+h_{0}\Big(x,\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)\Big)\Big) \cdot \widecheck{c_{0}}
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
+\psi^{1}(h_{1}(x)) \cdot \widecheck{c_{1}}
 + \rho(h_{2}(x)) \cdot \mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)  \Big] \cdot 
\boldsymbol{1}_{\{0\}}(\widetilde{\mathbbm{\overrightharp{q}}}_{\theta}(x))
 \, \mathrm{d}(\lambda_{1} + \lambda_{2})(x)
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
= \int_\mathcal{X} 
\Big[\psi^{0}(0) \cdot \widecheck{\overline{c}_{0}}
 + \psi^{1}\Big(\mathbbm{\overrightharp{q}}_{\theta}(x)\Big)  \Big] 
 \ \mathrm{d}\lambda_{2}(x)
+\sum_{x \in \mathcal{X}}  
\Big[\psi^{0}\Big(\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)
+h_{0}\Big(x,\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)\Big)\Big) \cdot \widecheck{c_{0}}
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
+\psi^{1}(h_{1}(x)) \cdot \widecheck{c_{1}} + \rho(h_{2}(x)) 
\cdot \mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)  \Big] \cdot 
\boldsymbol{1}_{\mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega))}(x)
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
= \int_\mathcal{X} 
\Big[\psi^{0}(0) \cdot \widecheck{\overline{c}_{0}} + \psi^{1}\Big(\mathbbm{\overrightharp{q}}_{\theta}(x)\Big)  \Big] 
 \ \mathrm{d}\lambda_{2}(x) + \frac{1}{N} \sum_{i=1}^{N} \rho(h_{2}(Y_{i}(\omega))) 
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
+ \frac{1}{N} \sum_{i=1}^{N}  
\frac{
\psi^{0}\Big(\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))
+h_{0}\big(Y_{i}(\omega),\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))\big)\Big) \cdot \widecheck{c_{0}}
+\psi^{1}(h_{1}(Y_{i}(\omega)))
\cdot \widecheck{c_{1}}}{\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))} 
\, , \qquad \ \ 
\label{brostu2:fo.646a}
\end{eqnarray}

\vspace{-0.2cm}

\enlargethispage{0.5cm}

\noindent
where we have employed \eqref{brostu2:fo.enc32};
recall that 
$\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))
= \#\{j \in \{1,\ldots,N\}\, : \, Y_{j}(\omega) = Y_{i}(\omega) \} /N$.
Hence, we always choose $\mathfrak{D}^{1}(\mathbbm{\overrightharp{Q}}) = \mathfrak{D}^{1}(\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}) = 
\int_\mathcal{X} \Big[\psi^{0}(0) + \psi^{1}\Big(\widetilde{\mathbbm{\overrightharp{q}}}_{\theta}(x)\Big) \Big] 
 \ \mathrm{d}\lambda_{2}(x)
= \int_\mathcal{X} \Big[\psi^{0}(0) + \psi^{1}\Big(\mathbbm{\overrightharp{q}}_{\theta}(x)\Big) \Big] 
 \ \mathrm{d}\lambda_{2}(x)
=\mathfrak{D}^{1}(\mathbbm{\overrightharp{Q}}_{\theta})$. Notice that the
functions $h_{0}$, $h_{1}$, $h_{2}$ may depend on the parameter $\theta$. Indeed,
for $h_{0}(x,s) \equiv 0$, $h_{1}(x) \equiv 0$, $h_{2}(x)= \mathbbm{\overrightharp{q}}_{\theta}(x)$
($\neq \widetilde{\mathbbm{\overrightharp{q}}}_{\theta}(x)$), 
the pseudo-divergence
\eqref{brostu2:fo.646a} turns into

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
D_{\lambda}\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big) 
= \int_\mathcal{X} 
\Big[\psi^{0}(0) \cdot \widecheck{\overline{c}_{0}} + \psi^{1}\Big(\mathbbm{\overrightharp{q}}_{\theta}(x)\Big)  \Big] 
 \ \mathrm{d}\lambda_{2}(x) + \frac{1}{N} \sum_{i=1}^{N} \rho\Big(\mathbbm{\overrightharp{q}}_{\theta}(Y_{i}(\omega))\Big) 
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
+ \frac{1}{N} \sum_{i=1}^{N}  
\frac{
\psi^{0}\Big(\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))\Big) \cdot \widecheck{c_{0}}
+\psi^{1}(0) \cdot \widecheck{c_{1}}
}{\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))} 
\, , \qquad \ \ 
\label{brostu2:fo.646b}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
whereas for $h_{0}(x,s) \equiv 0$, $h_{1}(x) = \mathbbm{\overrightharp{q}}_{\theta}(x)$, 
$h_{2}(x)= \mathbbm{\overrightharp{q}}_{\theta}(x)$, 
\eqref{brostu2:fo.646a} becomes

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
D_{\lambda}\big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big) 
= \int_\mathcal{X} 
\big[\psi^{0}(0) \cdot \widecheck{\overline{c}_{0}} + \psi^{1}\big(\mathbbm{\overrightharp{q}}_{\theta}(x)\big)  \big] 
 \ \mathrm{d}\lambda_{2}(x)  
\nonumber
\\[-0.1cm]
& & \hspace{-0.2cm}   \textstyle
+ \frac{1}{N} \sum_{i=1}^{N}  
\Big[
\rho\Big(\mathbbm{\overrightharp{q}}_{\theta}(Y_{i}(\omega))\Big)
+ \frac{\widecheck{c_{1}} \cdot \psi^{1}(\mathbbm{\overrightharp{q}}_{\theta}(Y_{i}(\omega)))}{
\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))}
\Big]
+ \frac{1}{N} \sum_{i=1}^{N}
\frac{
\psi^{0}\Big(\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))\Big) \cdot \widecheck{c_{0}}
}{\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))} 
\, . \qquad \ \ 
\label{brostu2:fo.646c}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
The last sum in \eqref{brostu2:fo.646b} respectively \eqref{brostu2:fo.646c}
is the desired $\mathfrak{D}^{0}(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)})$. 
As an example, let us take 
$c_{0} = c_{1}= \overline{c}_{0}= -1$ (and hence,
$\widecheck{c_{0}} = \widecheck{c_{1}} = \widecheck{\overline{c}_{0}}=1$)
and for $\alpha >1$
the power functions  
$\phi(t): = \phi_{\alpha}(t) := 
\frac{t^{\alpha}- \alpha \cdot t + \alpha - 1}{\alpha \cdot (\alpha-1)}$
($t \in ]0,\infty[$) of \eqref{brostu2:fo.def.33a}, for which by
\eqref{brostu2:fo.def.33e} and \eqref{27newb} one derives immediately the decomposition
$\psi^{0}(t) := \psi_{\alpha}^{0}(t) := \frac{t^{\alpha}}{\alpha(\alpha-1)} >0$,
$\psi^{1}(t) := \psi_{\alpha}^{1}(t) := \frac{t^{\alpha}}{\alpha} >0$,
$\rho(t) := \rho_{\alpha}(t) := - \frac{t^{\alpha-1}}{\alpha-1}  < 0$
($t \in ]0,\infty[$). Accordingly, \eqref{brostu2:fo.646a} simplifies to



\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
D_{\lambda}\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big) 
:= D_{\lambda,\alpha}\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big)
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
= \frac{1}{\alpha} \int_\mathcal{X} 
\mathbbm{\overrightharp{q}}_{\theta}(x)^{\alpha}
\, \mathrm{d}\lambda_{2}(x) 
- \frac{1}{N \cdot (\alpha-1)} \sum_{i=1}^{N} \Big(h_{2}(Y_{i}(\omega))\Big)^{\alpha-1} 
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
+ \frac{1}{N} \sum_{i=1}^{N}  
\frac{
\Big(\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))
+h_{0}\Big(Y_{i}(\omega),\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))\Big)\Big)^{\alpha}
+ (\alpha-1) \cdot \Big(h_{1}(Y_{i}(\omega))\Big)^{\alpha}}{\alpha \cdot (\alpha-1) \cdot
 \mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))} 
\, , \qquad \ \ 
\label{brostu2:fo.649a}
\end{eqnarray} 
and in particular the special case \eqref{brostu2:fo.646b} turns into
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
D_{\lambda,\alpha}\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big) 
= \frac{1}{\alpha} \int_\mathcal{X} 
\mathbbm{\overrightharp{q}}_{\theta}(x)^{\alpha}
\, \mathrm{d}\lambda_{2}(x) 
- \frac{1}{N \cdot (\alpha-1)} \sum_{i=1}^{N} \Big(\mathbbm{\overrightharp{q}}_{\theta}(Y_{i}(\omega))\Big)^{\alpha-1} 
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
+ \frac{1}{N\cdot \alpha \cdot (\alpha-1)} \sum_{i=1}^{N}  
\Big(\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))\Big)^{\alpha-1}
\, , \qquad \ \ 
\label{brostu2:fo.649b}
\end{eqnarray}
whereas the special case \eqref{brostu2:fo.646c} simplifies to
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 < D_{\lambda,\alpha}\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big) 
= \frac{1}{\alpha} \int_\mathcal{X} 
\mathbbm{\overrightharp{q}}_{\theta}(x)^{\alpha}
\, \mathrm{d}\lambda_{2}(x)  
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
+ \frac{1}{N} \sum_{i=1}^{N}  
\Big[
\frac{\Big(\mathbbm{\overrightharp{q}}_{\theta}(Y_{i}(\omega))\Big)^{\alpha}}{
\alpha \cdot \mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))}
- \frac{\Big(\mathbbm{\overrightharp{q}}_{\theta}(Y_{i}(\omega))\Big)^{\alpha-1}}{\alpha-1}
\Big]
+ \frac{1}{N} \sum_{i=1}^{N}  
\frac{\Big(\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))\Big)^{\alpha-1}}{\alpha \cdot (\alpha-1)}  
\, . \qquad \ \ 
\label{brostu2:fo.649c}
\end{eqnarray}
Notice that \eqref{brostu2:fo.649c} coincides with \eqref{brostu2:fo.enc30},
but both were derived within quite different frameworks:
to obtain \eqref{brostu2:fo.649c} we have used the concept of
decomposable pseudo-divergences (which may generally become negative at the boundary) 
together with $\mathbbm{\overrightharp{Q}}:= \widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}$ 
which leads to total mass of $1$ (cf. \eqref{brostu2:fo.enc21});
on the other hand, for establishing \eqref{brostu2:fo.enc30}
we have employed the concept of divergences (which are generally always strictly positive at the boundary)
together with
$\mathbbm{\overrightharp{Q}}:= \mathbbm{\overrightharp{Q}}_{\theta}$ 
which amounts to total mass greater than $1$ (cf. \eqref{brostu2:fo.enc24}).
Moreover, choosing 
$h_{0}(x,s) \equiv 0$, $h_{1}(x) \equiv 0$, $h_{2}(x) \equiv 0$
in \eqref{brostu2:fo.649a} gives exactly the divergence \eqref{brostu2:fo.enc23}
for the current generator $\phi(t): = \phi_{\alpha}(t)$ with $\alpha >1$;
recall that the latter has been a starting motivation for the search of repairs.
For $c_{0} = c_{1}= \overline{c}_{0}= -1$ 
and the limit case $\alpha \rightarrow 1$
one gets
$\phi(t): = \phi_{1}(t) := 
t \cdot \log t + 1 - t$
($t \in ]0,\infty[$) of \eqref{brostu2:fo.def.120b}, for which by
\eqref{brostu2:fo.def.125e} and \eqref{27newb} we obtain the decomposition
$\psi^{0}(t) := \psi_{1}^{0}(t) := t \cdot \log t - t $,
$\psi^{1}(t) := \psi_{1}^{1}(t) := t >0$,
$\rho(t) := \rho_{1}(t) := - \log t$.
Accordingly, \eqref{brostu2:fo.646a} simplifies to

\vspace{-0.5cm}

\enlargethispage{0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
D_{\lambda}\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big) 
:= D_{\lambda,1}\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big)
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
= 1
- \frac{1}{N} \sum_{i=1}^{N} \log\Big(h_{2}(Y_{i}(\omega))\Big) 
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
+ \frac{1}{N} \sum_{i=1}^{N}  
\frac{
\psi_{1}^{0}\Big(\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))
+h_{0}\Big(Y_{i}(\omega),\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))\Big)\Big)
+ h_{1}(Y_{i}(\omega))}{\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))} 
\, , \qquad \ \ 
\label{brostu2:fo.651a}
\end{eqnarray} 

\vspace{-0.2cm}

\noindent
and in particular the special case \eqref{brostu2:fo.646b} turns into

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
D_{\lambda,1}\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big) 
= \frac{1}{N} \sum_{i=1}^{N} \log\Big(\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))\Big) 
- \frac{1}{N} \sum_{i=1}^{N} \log\Big(\mathbbm{\overrightharp{q}}_{\theta}(Y_{i}(\omega))\Big) 
\, , \qquad \ \ 
\label{brostu2:fo.651b}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
whereas the special case \eqref{brostu2:fo.646c} becomes

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 < D_{\lambda,1}\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big) 
= \frac{1}{N} \sum_{i=1}^{N} \log\Big(\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))\Big) 
- \frac{1}{N} \sum_{i=1}^{N} \log\Big(\mathbbm{\overrightharp{q}}_{\theta}(Y_{i}(\omega))\Big) 
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
+ \frac{1}{N} \sum_{i=1}^{N}  
\frac{\mathbbm{\overrightharp{q}}_{\theta}(Y_{i}(\omega))}{
\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))}  
\, . \qquad \ \ 
\label{brostu2:fo.651c}
\end{eqnarray}

\vspace{-0.1cm}

\noindent
To end up this subsection, let us briefly indicate
that choosing in step (Enc2) a decomposable pseudo-divergence of 
the form (respectively) \eqref{brostu2:fo.646a}, \eqref{brostu2:fo.646b},
\eqref{brostu2:fo.646c}, \eqref{brostu2:fo.649a}, \eqref{brostu2:fo.649b},
\eqref{brostu2:fo.649c}, \eqref{brostu2:fo.651a}, 
\eqref{brostu2:fo.651b}, \eqref{brostu2:fo.651c},
and in the course of (Enc3) minimize this over $\theta\in \Theta$, 
we end up at the corresponding $\min-decD_{\lambda}-$estimator 
\eqref{c2new}. For the special case \eqref{brostu2:fo.651b} (i.e. $\alpha = 1$)
this leads to the omnipresent, celebrated \textit{maximum-likelihood-estimator} (MLE)
which is known to be efficient but not robust. The particular 
choice \eqref{brostu2:fo.649b} for $\alpha > 1$ gives the density-power divergence estimator
DPDE of Basu et al.~\cite{Bas:98}, where $\alpha=2$
amounts to the (squared) $L_{2}$-estimator which is robust but not efficient 
(see e.g. Hampel et al.~\cite{Ham:86} ); accordingly, taking $\alpha \in ]1,2[$ 
builds a smooth bridge between the robustness and efficiency.
The reversed version of the DPDE can be analogously imbedded in our context, by 
employing our new approach with $\phi(t) := \widetilde{\widetilde{\phi}}_{\alpha}(t)$
(cf. \eqref{brostu2:fo.div.ex.156}). 


\vspace{-0.4cm}

\enlargethispage{0.5cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Minimum divergences - generalized subdivergence method}
\label{subsec.4anew.5}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.05cm}

One can flexibilize some of the methods of the previous Subsection \ref{subsec.4anew.4},
by employing 
an additional (a.s.)  strictly positive density function $\mathbbm{M}$
to define a pseudo-divergence 
$D_{\mathbbm{M},\lambda}: \widetilde{\mathcal{P}}^{\lambda} \otimes \mathcal{P}^{\lambda} \rightarrow \mathbb{R}$
of the form
$D_{\mathbbm{M},\lambda}(\mathbbm{P},\mathbbm{Q}) = $ \\
$\int_\mathcal{X} \psi^{dec}\big(\frac{\mathbbm{p}(x)}{\mathbbm{m}(x)}, \frac{\mathbbm{q}(x)}{\mathbbm{m}(x)}\big)
\cdot \mathbbm{m}(x)  \, \mathrm{d}\lambda(x)$ 
for some (measurable) mapping \\
$\psi^{dec}: [0,\infty[ \times [0,\infty[ \mapsto \mathbb{R}$
with representation

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\psi^{dec}(s,t) := \psi^{0}\Big(s + h_{0}(x,s) \cdot \boldsymbol{1}_{\{0\}}(t)\Big)
\cdot \boldsymbol{1}_{]\overline{c}_{0},\infty[}(s) \cdot \boldsymbol{1}_{]c_{0},\infty[}(t)
\nonumber \\ 
& & \hspace{1.2cm}
+\psi^{1}\Big(t + h_{1}(x) \cdot \boldsymbol{1}_{\{0\}}(t)\Big) \cdot \boldsymbol{1}_{]c_{1},\infty[}(t)
\nonumber \\ 
& & \hspace{1.2cm}  
+ \rho\Big(t + h_{2}(x) \cdot \boldsymbol{1}_{\{0\}}(t)\Big) \cdot s \ \ 
\textrm{ for all $(s,t) \in [0,\infty[ \times [0,\infty[ \backslash \{(0,0)\}$} \ , \ \
\nonumber
(cf. \eqref{27new})
\\ 
& & \hspace{-0.2cm}   \textstyle 
\psi^{dec}(0,0):=0.
\nonumber
\end{eqnarray} 

\vspace{-0.2cm}

\noindent 
It is straightforward to see that $D_{\mathbbm{M},\lambda}(\cdot,\cdot)$ 
is a pointwise decomposable pseudo-divergence
in the sense of Definition \ref{brostu2:def.dec}(b), 
and one gets for fixed $m >0$

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\psi_{m}^{dec}(s,t) := m \cdot \psi^{dec}\Big(\frac{s}{m},\frac{t}{m}\Big)
= m \cdot \psi^{0}\Big(\frac{s}{m}\Big) + m \cdot \psi^{1}\Big(\frac{t}{m}\Big) + 
\rho\Big(\frac{t}{m}\Big) \cdot s \geq 0 
\nonumber 
\\
& & \hspace{5.2cm} 
\textrm{for all $(s,t) \in ]0,\infty[ \times ]0,\infty[$} \, , \quad \ 
\label{27newbwithm}
\\
& & \hspace{-0.2cm}   \textstyle
\psi_{m}^{dec}(s,t) = 0 \quad \textrm{if and only if} \quad s=t \, ,
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\frac{s}{m} + h_{0}\Big(x,\frac{s}{m}\Big) \geq 0 
\qquad \textrm{for all $s \in [0,\infty[$ and $\lambda-$almost all $x \in \mathcal{X}$} \, ,
\nonumber\\
& & \hspace{-0.2cm}   \textstyle 
\mathbb{R} \ni \psi_{m}^{dec}(s,0) = 
m \cdot \psi^{0}\Big(\frac{s}{m} + h_{0}\Big(x,\frac{s}{m}\Big) \Big) \cdot \widecheck{c_{0}} 
+ m \cdot \psi^{1}(h_{1}(x)) \cdot \widecheck{c_{1}}
+ \rho(h_{2}(x)) \cdot s  
\nonumber\\
& & \hspace{8.7cm}   \textstyle 
\textrm{for all $s >0$} \, , \qquad \ \
\label{27newewithm}
\\
& & \hspace{-0.2cm}   \textstyle
\mathbb{R} \ni \psi_{m}^{dec}(0,t) = m \cdot \psi^{0}(0) \cdot 
\widecheck{\overline{c}_{0}} + m \cdot \psi^{1}\Big(\frac{t}{m}\Big) \quad 
\textrm{for all $t >0$} \, . \quad \ 
\label{27newfwithm}
\end{eqnarray}

\vspace{-0.5cm}

\noindent
For each class-family member $\mathbbm{M} := \mathbbm{\overrightharp{Q}}_{\tau}$ 
with arbitrarily fixed $\tau \in \Theta$, 
we can apply Definition \ref{Def3.3new} to 
$D_{\lambda}(\cdot,\cdot) := D_{\mathbbm{\overrightharp{Q}}_{\tau},\lambda}(\cdot,\cdot)$, 
and arrive at the corresponding
$\min-decD_{\mathbbm{\overrightharp{Q}}_{\tau},\lambda}-$estimators  

\vspace{-0.4cm}

\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle 
\widehat{\theta}_{N,decD_{\mathbbm{\overrightharp{Q}}_{\tau},\lambda}}(\omega)
:= T_{D_{\mathbbm{\overrightharp{Q}}_{\tau},\lambda}}\big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)}\big)
\quad \textrm{for} \ \ \mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)} \in 
\mathcal{P}_{emp}^{\lambda\perp} 
\nonumber 
\end{eqnarray} 

\vspace{-0.2cm}

\noindent
of the true unknown parameter $\theta_{0}$.
Hence, analogously to the derivation of \eqref{brostu2:fo.646a},
we obtain from  \eqref{27new}, \eqref{27newewithm}, \eqref{27newfwithm} for each $\tau \in \Theta$

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
D_{\mathbbm{\overrightharp{Q}}_{\tau},\lambda}\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big) = 
\int_\mathcal{X} 
\psi^{dec}\Big(\frac{\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)}{\mathbbm{\overrightharp{q}}_{\tau}(x)}, \frac{\widetilde{\mathbbm{\overrightharp{q}}}_{\theta}(x)}{\mathbbm{\overrightharp{q}}_{\tau}(x)}\Big) 
\cdot \mathbbm{\overrightharp{q}}_{\tau}(x)
\, \mathrm{d}\lambda(x)
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
= \int_{\mathcal{X}} \psi^{1}\Big(\frac{\mathbbm{\overrightharp{q}}_{\theta}(x)}{\mathbbm{\overrightharp{q}}_{\tau}(x)}\Big)  
\cdot \mathbbm{\overrightharp{q}}_{\tau}(x) \, \mathrm{d}\lambda_{2}(x)
+\sum_{x \in \mathcal{X}}  
\Big[\mathbbm{\overrightharp{q}}_{\tau}(x) \cdot 
\psi^{0}\Big(\frac{\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)}{\mathbbm{\overrightharp{q}}_{\tau}(x)}
+h_{0}\Big(x,\frac{\mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)}{\mathbbm{\overrightharp{q}}_{\tau}(x)}
\Big)\Big) \cdot \widecheck{c_{0}}
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
+ \, \mathbbm{\overrightharp{q}}_{\tau}(x) \cdot \psi^{1}(h_{1}(x)) \cdot \widecheck{c_{1}} + 
\rho(h_{2}(x)) \cdot \mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)  \Big] \cdot 
\boldsymbol{1}_{\mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega))}(x) + \psi^{0}(0) \cdot \widecheck{\overline{c}_{0}}
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
= \int_{\mathcal{X}} \psi^{1}\Big(\frac{\mathbbm{\overrightharp{q}}_{\theta}(x)}{\mathbbm{\overrightharp{q}}_{\tau}(x)}\Big)  
\cdot \mathbbm{\overrightharp{q}}_{\tau}(x) \, \mathrm{d}\lambda_{2}(x)
 + \frac{1}{N} \sum_{i=1}^{N} \rho(h_{2}(Y_{i}(\omega))) 
 + \psi^{0}(0) \cdot \widecheck{\overline{c}_{0}}
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
+ \frac{1}{N} \sum_{i=1}^{N}  
\frac{
\psi^{0}\Big(
\frac{\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))}{\mathbbm{\overrightharp{q}}_{\tau}(Y_{i}(\omega))}
+h_{0}\Big(Y_{i}(\omega),
\frac{\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))}{\mathbbm{\overrightharp{q}}_{\tau}(Y_{i}(\omega))}
\Big)\Big) \cdot \widecheck{c_{0}}
+\psi^{1}(h_{1}(Y_{i}(\omega))) \cdot \widecheck{c_{1}}}{\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))} 
\cdot  \mathbbm{\overrightharp{q}}_{\tau}(Y_{i}(\omega))
\, . \qquad \ \ 
\label{brostu2:fo.646awithm}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
Just as in the derivation of \eqref{brostu2:fo.646b} respectively \eqref{brostu2:fo.646c},
reasonable choices for the ``boundary-functions'' in \eqref{brostu2:fo.646awithm} are
$h_{0}(x,s) \equiv 0$, $h_{1}(x) \equiv 0$, 
$h_{2}(x)= \frac{\mathbbm{\overrightharp{q}}_{\theta}(x)}{\mathbbm{\overrightharp{q}}_{\tau}(x)}$,
respectively 
$h_{0}(x,s) \equiv 0$, $h_{1}(x) \equiv 
\frac{\mathbbm{\overrightharp{q}}_{\theta}(x)}{\mathbbm{\overrightharp{q}}_{\tau}(x)}$, 
$h_{2}(x)= \frac{\mathbbm{\overrightharp{q}}_{\theta}(x)}{\mathbbm{\overrightharp{q}}_{\tau}(x)}$.
As for example, consider for all $\theta_{0},\theta,\tau \in \Theta$
the scaled Bregman divergences in the sense of Stummer~\cite{Stu:07}, Stummer \& Vajda~\cite{Stu:07}
(cf. Remark \eqref{brostu2:rem.40}(a)), for which we get from \eqref{brostu2:fo.def.20}
with $r(x) \equiv 1$

\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\mathbbm{\overrightharp{Q}}_{\tau},\mathbbm{1}\cdot
 \mathbbm{\overrightharp{Q}}_{\tau},\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
: =
\int_{{\mathcal{X}}} 
\Big[ \phi  \big( {
\frac{\mathbbm{\overrightharp{q}}_{\theta_{0}}(x)}{\mathbbm{\overrightharp{q}}_{\tau}(x)}}\big) -
\phi  \big( \frac{\mathbbm{\overrightharp{q}}_{\theta}(x)}{\mathbbm{\overrightharp{q}}_{\tau}(x)}\big) 
- \phi_{+,c}^{\prime} 
\big( {\frac{\mathbbm{\overrightharp{q}}_{\theta}(x)}{\mathbbm{\overrightharp{q}}_{\tau}(x)}}\big) \cdot \big( \frac{\mathbbm{\overrightharp{q}}_{\theta_{0}}(x)}{\mathbbm{\overrightharp{q}}_{\tau}(x)}
-\frac{\mathbbm{\overrightharp{q}}_{\theta}(x)}{\mathbbm{\overrightharp{q}}_{\tau}(x)}\big) 
\Big] \cdot
\mathbbm{\overrightharp{q}}_{\tau}(x)  \, \mathrm{d}\lambda_{2}(x) \ ,
\nonumber \\
& & \hspace{-0.2cm}   \textstyle
=: D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta}) 
\, ,
\label{brostu2:fo.def.753a}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
from which -- together with \eqref{27newbwithm} -- one can identify immediately the
pointwise decomposability with $\psi^{0}(s) := \psi_{\phi}^{0}(s) := \phi(s)$, 
$\psi^{1}(t) := \psi_{\phi}^{1}(t) := t \cdot \phi_{+,c}^{\prime}(t) -\phi(t)$, 
$\rho(t) := \rho_{\phi}(t) :=  - \phi_{+,c}^{\prime}(t)$; 
by plugging this into \eqref{brostu2:fo.646awithm}, one obtains the 
objective
$D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda_{2}}
\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big)$,
which in the course of (Enc3) should be -- for fixed $\tau \in \Theta$ --
minimized over $\theta\in \Theta$ in order to obtain
the corresponding $\tau-$individual'' 
$\min-decD_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda}-$estimator
$\widehat{\theta}_{N,\tau}(\omega) 
:= \arginf_{\theta \in \Theta} \ 
D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda}
\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big)$.
Recall that this choice can be motivated by 
$0 = \min_{\theta\in \Theta} D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta})$ 
and $\theta_{0} = \argmin_{\theta\in \Theta} D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta})$. 
Furthermore, one gets even\\
$0 = \min_{\theta\in \Theta} \min_{\tau \in \Theta} D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta})$, 
$\theta_{0} = \argmin_{\theta\in \Theta} \min_{\tau \in \Theta} D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta})$,
and in case of $\max_{\tau \in \Theta} D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta}) < \infty$
also 
$0 = \min_{\theta\in \Theta} \max_{\tau \in \Theta} D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta})$, 
$\theta_{0} = \argmin_{\theta\in \Theta} \max_{\tau \in \Theta} D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta})$.
This suggests the alternative, \\
``$\tau-$uniform'' estimators 
$\widehat{\theta}_{N}(\omega) 
:= \argmin_{\theta \in \Theta} \ 
\min_{\tau \in \Theta}
D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda}
\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big) 
$, respectively
$\widehat{\theta}_{N}(\omega) 
:= \argmin_{\theta \in \Theta} \ 
\max_{\tau \in \Theta}
D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda}
\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big) 
$.
As a side remark, let us mention that in general, (say) $\min_{\tau \in \Theta}
D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda}
\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big)$  
is not necessarily decomposable anymore, and 
therefore the standard theory of $M$-estimators is not
applicable to this class of estimators. 

\vspace{0.2cm}
\noindent
With our approach, we can generate numerous further estimators of the true unknown
parameter $\theta_{0}$, by permuting the positions -- but not the roles (!) -- of the
parameters $(\theta_{0},\theta,\tau)$ in the (pseudo-)divergences
of the above investigations.
For the sake of brevity, we only sketch two further cases;
the full variety will appear elsewhere. 
To start with, consider
the adaptively scaled and aggregated divergence


\vspace{-0.6cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq 
D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda_{2}}^{rev}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta})
:=
D^{c}_{\phi,
\mathbbm{\overrightharp{Q}}_{\theta_{0}}^{\ 2}/\mathbbm{\overrightharp{Q}}_{\tau}, \,
\mathbbm{\overrightharp{Q}}_{\theta}^{\ 2}/\mathbbm{\overrightharp{Q}}_{\tau}, \,
\mathbbm{1}\cdot
\mathbbm{\overrightharp{Q}}_{\theta_{0}},
\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
: =
\int_{{\mathcal{X}}} 
\Big[ \phi  
\Bigg( {
\frac{\mathbbm{\overrightharp{q}}_{\theta_{0}}(x)}{
\frac{\mathbbm{\overrightharp{q}}_{\theta_{0}}(x)^{2}}{\mathbbm{\overrightharp{q}}_{\tau}(x)}}
}\Bigg) 
-\phi  
\Bigg( {
\frac{\mathbbm{\overrightharp{q}}_{\theta}(x)}{
\frac{\mathbbm{\overrightharp{q}}_{\theta}(x)^{2}}{\mathbbm{\overrightharp{q}}_{\tau}(x)}}
}\Bigg) 
- \phi_{+,c}^{\prime} 
\Bigg( {
\frac{\mathbbm{\overrightharp{q}}_{\theta}(x)}{
\frac{\mathbbm{\overrightharp{q}}_{\theta}(x)^{2}}{\mathbbm{\overrightharp{q}}_{\tau}(x)}}
}\Bigg) 
\cdot 
\Bigg( 
\Bigg( {
\frac{\mathbbm{\overrightharp{q}}_{\theta_{0}}(x)}{
\frac{\mathbbm{\overrightharp{q}}_{\theta_{0}}(x)^{2}}{\mathbbm{\overrightharp{q}}_{\tau}(x)}}
}\Bigg) 
-
\Bigg( {
\frac{\mathbbm{\overrightharp{q}}_{\theta}(x)}{
\frac{\mathbbm{\overrightharp{q}}_{\theta}(x)^{2}}{\mathbbm{\overrightharp{q}}_{\tau}(x)}}
}\Bigg) 
\Bigg) 
\Big] 
\nonumber \\
& & \hspace{9.5cm}   \textstyle
\cdot
\mathbbm{\overrightharp{q}}_{\tau}(x)  \, \mathrm{d}\lambda_{2}(x) 
\nonumber \\
& & \hspace{-0.2cm}   \textstyle 
=
\int_{{\mathcal{X}}} 
\Big[ \phi  \big( {
\frac{\mathbbm{\overrightharp{q}}_{\tau}(x)}{\mathbbm{\overrightharp{q}}_{\theta_{0}}(x)}}\big) -
\phi  \big( \frac{\mathbbm{\overrightharp{q}}_{\tau}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}\big)
- \phi_{+,c}^{\prime} 
\big( {\frac{\mathbbm{\overrightharp{q}}_{\tau}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}}\big) \cdot \big( \frac{\mathbbm{\overrightharp{q}}_{\tau}(x)}{\mathbbm{\overrightharp{q}}_{\theta_{0}}(x)}
-\frac{\mathbbm{\overrightharp{q}}_{\tau}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}\big) 
\Big] 
\cdot
\mathbbm{\overrightharp{q}}_{\theta_{0}}(x)  \, \mathrm{d}\lambda_{2}(x) 
\nonumber \\
& & \hspace{-0.2cm}   \textstyle 
= :
\int_{{\mathcal{X}}} 
\Big[ 
\psi_{\mathbbm{\overrightharp{q}}_{\tau}(x)}^{0,rev}(\mathbbm{\overrightharp{q}}_{\theta_{0}}(x))
+ \psi_{\mathbbm{\overrightharp{q}}_{\tau}(x)}^{1,rev}(\mathbbm{\overrightharp{q}}_{\theta}(x))
+ \rho_{\mathbbm{\overrightharp{q}}_{\tau}(x)}^{rev}(\mathbbm{\overrightharp{q}}_{\theta}(x)) \cdot  
\mathbbm{\overrightharp{q}}_{\theta_{0}}(x) 
\Big] 
  \, \mathrm{d}\lambda_{2}(x) 
\nonumber
\end{eqnarray}

\vspace{-0.2cm}

\noindent
(indeed, by Theorem \ref{brostu2:thm.2} and 
\eqref{brostu2:fo.mesequ}
this is zero if and only if $\theta= \theta_{0}$).
By means of the involved mappings
$\psi^{0}(s) :=  \psi_{m,}^{0,rev}(s) := s \cdot \phi(\frac{m}{s})$,
$\psi^{1}(t) := \psi_{m}^{1,rev}(t) := - m \cdot \phi_{+,c}^{\prime}(\frac{m}{t})$,
$\rho(t) := \rho_{m}^{rev}(t) := \frac{m}{t} \cdot \phi_{+,c}^{\prime}(\frac{m}{t}) - \phi(\frac{m}{t}) =: 
\phi^{\circledcirc}(\frac{m}{t})$ 
\ ($s,t,m >0$), the properties \eqref{27newb}, \eqref{27newc} are applicable
and thus $D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda_{2}}^{rev}(\cdot,\cdot)$ can be
extended to a pointwise decomposable pseudo-divergence on $\widetilde{\mathcal{P}}^{\lambda} \otimes \mathcal{P}^{\lambda}$
by using \eqref{27new} with appropriate functions $h_{0}$,$h_{1}$,$h_{2}$
and constants $c_{0}$,$c_{1}$,$\overline{c}_{0}$.
Furthermore, by minimizing over $\theta \in \Theta$ the objective \eqref{brostu2:fo.646a} with these choices
$\psi_{m}^{0,rev}(\cdot)$ $\psi_{m}^{1,rev}(\cdot)$,
$\rho_{m}^{rev}(\cdot)$, in the course of (Enc3) we end up at the corresponding
$\min-decD_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda}^{rev}-$estimator. 
In particular, the corresponding special case $h_{0}(x,s) \equiv 0$, $h_{1}(x) \equiv 1$, 
$h_{2}(x)= \mathbbm{\overrightharp{q}}_{\theta}(x)$
($\neq \widetilde{\mathbbm{\overrightharp{q}}}_{\theta}(x)$)
leads to the objective (cf. \eqref{brostu2:fo.646b} but with $\psi^{1}(1)$ instead of $\psi^{1}(0)$)

\vspace{-0.5cm}

\enlargethispage{0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
D_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda_{2}}^{rev}\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big) 
= \phi^{*}(0) \cdot \widecheck{\overline{c}_{0}} - \int_\mathcal{X}
\mathbbm{\overrightharp{q}}_{\tau}(x) \cdot 
\phi_{+,c}^{\prime}\Big(\frac{\mathbbm{\overrightharp{q}}_{\tau}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}\Big) 
 \ \mathrm{d}\lambda_{2}(x)
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle 
 + \frac{1}{N} \sum_{i=1}^{N} 
\phi^{\circledcirc}\Big(\frac{\mathbbm{\overrightharp{q}}_{\tau}(Y_{i}(\omega))}{\mathbbm{\overrightharp{q}}_{\theta}(Y_{i}(\omega))}\Big) 
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
+ \frac{1}{N} \sum_{i=1}^{N}
\Big[
\phi\Big(\frac{\mathbbm{\overrightharp{q}}_{\tau}(Y_{i}(\omega))}{\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))}\Big)
\cdot \widecheck{c_{0}} 
- 
\frac{\mathbbm{\overrightharp{q}}_{\tau}(Y_{i}(\omega)) \cdot \phi_{+,c}^{\prime}( \mathbbm{\overrightharp{q}}_{\tau}(Y_{i}(\omega)))
}{\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))} \cdot \widecheck{c_{1}}
\Big] 
\, \qquad \ \ 
\nonumber
\end{eqnarray}

\vspace{-0.1cm}

\noindent
to be minimized over $\theta$.
As a second possibility to permutate the positions of the parameters $(\theta_{0},\theta,\tau)$,
let us consider

\vspace{-0.5cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
0 \leq D^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\theta},\mathbbm{\overrightharp{Q}}_{\theta},\mathbbm{1}\cdot
 \mathbbm{\overrightharp{Q}}_{\theta},\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\tau}) 
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
: =
\int_{{\mathcal{X}}} 
\Big[ \phi  \big( {
\frac{\mathbbm{\overrightharp{q}}_{\theta_{0}}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}}\big) -
\phi  \big( \frac{\mathbbm{\overrightharp{q}}_{\tau}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}\big) 
- \phi_{+,c}^{\prime} 
\big( {\frac{\mathbbm{\overrightharp{q}}_{\tau}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}}\big) \cdot \big( \frac{\mathbbm{\overrightharp{q}}_{\theta_{0}}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}
-\frac{\mathbbm{\overrightharp{q}}_{\tau}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}\big) 
\Big] \cdot
\mathbbm{\overrightharp{q}}_{\theta}(x)  \, \mathrm{d}\lambda_{2}(x)  
\, ; \qquad \ \ 
\label{brostu2:fo.def.756a}
\end{eqnarray}

\vspace{-0.1cm}

\noindent
this is a pointwise decomposable divergence between $\mathbbm{\overrightharp{Q}}_{\theta_{0}}$ and $\mathbbm{\overrightharp{Q}}_{\tau}$, 
but it is \textit{not} a divergence -- yet still a nonnegative 
and obviously \textit{not} pointwise decomposable functional --
between $\mathbbm{\overrightharp{Q}}_{\theta_{0}}$ and $\mathbbm{\overrightharp{Q}}_{\theta}$. 
Indeed, for $\theta = \theta_{0} \neq \tau$ one obtains 
$D^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{1}\cdot
 \mathbbm{\overrightharp{Q}}_{\theta_{0}},\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\tau}) >0$.
Notice that from \eqref{brostu2:fo.def.756a} one gets 

\vspace{-0.4cm}

\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\int_{{\mathcal{X}}} 
\phi  \big( {
\frac{\mathbbm{\overrightharp{q}}_{\theta_{0}}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}}\big)  
\cdot \mathbbm{\overrightharp{q}}_{\theta}(x)  \, \mathrm{d}\lambda_{2}(x)
\geq 
\int_{{\mathcal{X}}} 
\Big\{\Big[ 
\phi  \big( \frac{\mathbbm{\overrightharp{q}}_{\tau}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}\big)
- \phi_{+,c}^{\prime} 
\big( {\frac{\mathbbm{\overrightharp{q}}_{\tau}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}}\big) 
\cdot \frac{\mathbbm{\overrightharp{q}}_{\tau}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)} 
\Big] \cdot
\mathbbm{\overrightharp{q}}_{\theta}(x)  
\nonumber\\ 
& & \hspace{-0.2cm}   \textstyle 
+ \phi_{+,c}^{\prime} 
\big( {\frac{\mathbbm{\overrightharp{q}}_{\tau}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}}\big)  
\cdot \mathbbm{\overrightharp{q}}_{\theta_{0}}(x)  
\Big\}
\, \mathrm{d}\lambda_{2}(x)
=: \mathcal{D}^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},
\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta}) 
\, ,
\label{brostu2:fo.def.756d}
\end{eqnarray}

\vspace{-0.2cm}

\noindent
provided that the integral on the right-hand side exists and is finite.
If moreover $\phi(1)=0$, then by \eqref{brostu2:fo.def.47d}
the inequality \eqref{brostu2:fo.def.756d} rewrites as 
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle \textstyle
D^{c}_{\phi,\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta}) 
:= D^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\theta},\mathbbm{\overrightharp{Q}}_{\theta},\mathbb{1}\cdot \mathbbm{\overrightharp{Q}}_{\theta},\lambda}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta})
\geq D^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta})
\label{brostu2:fo.def.756e}
\end{eqnarray}  
with (for fixed $\theta$) equality if and only if $\theta_{0} = \tau$; this implies that 
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
D^{c}_{\phi,\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta}) 
= \max_{\tau \in \Theta} \mathcal{D}^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},
\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta})
\label{brostu2:fo.def.756f}
\\
& & \hspace{-0.2cm}   \textstyle
=  \max_{\tau \in \Theta}
\int_{{\mathcal{X}}} 
\Big[ 
\psi_{\mathbbm{\overrightharp{q}}_{\tau}(x)}^{1,sub}(\mathbbm{\overrightharp{q}}_{\theta}(x))
+ \rho_{\mathbbm{\overrightharp{q}}_{\tau}(x)}^{sub}(\mathbbm{\overrightharp{q}}_{\theta}(x)) \cdot  
\mathbbm{\overrightharp{q}}_{\theta_{0}}(x) 
\Big] 
  \, \mathrm{d}\lambda_{2}(x) 
\label{brostu2:fo.def.756g}
\end{eqnarray} 
with $\psi^{0}(s) := \psi_{m}^{0,sub}(s) \equiv 0$,
$\psi^{1}(t) := \psi_{m}^{1,sub}(t) := 
t\cdot \phi(\frac{m}{t}) - m \cdot \phi_{+,c}^{\prime}(\frac{m}{t})$,
$\rho(t) := \rho_{m}^{sub}(t) := \phi_{+,c}^{\prime}(\frac{m}{t})$ 
\ ($s,t,m >0$). In other words, this means that the Csiszar-Ali-Silvey divergence 
CASD $D^{c}_{\phi,\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta})$
can be represented as the $\tau-$maximum over -- not necessarily nonnegative --
pointwise decomposable (in the sense of \eqref{27newb}, \eqref{27newc}) functionals  
$\mathcal{D}^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},
\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta})$
between $\mathbbm{\overrightharp{Q}}_{\theta_{0}}$ and $\mathbbm{\overrightharp{Q}}_{\theta}$.
Furthermore, from Theorem \ref{brostu2:thm.2CASD} and \eqref{brostu2:fo.def.756g}
we arrive at
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
0 = \min_{\theta \in \Theta} D^{c}_{\phi,\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta}) 
= \min_{\theta \in \Theta} \ \max_{\tau \in \Theta} \mathcal{D}^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},
\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta})
\nonumber 
\\
& & \hspace{-0.2cm}   \textstyle
= \min_{\theta \in \Theta} \ \max_{\tau \in \Theta}
\int_{{\mathcal{X}}} 
\Big[ 
\psi_{\mathbbm{\overrightharp{q}}_{\tau}(x)}^{1,sub}(\mathbbm{\overrightharp{q}}_{\theta}(x))
+ \rho_{\mathbbm{\overrightharp{q}}_{\tau}(x)}^{sub}(\mathbbm{\overrightharp{q}}_{\theta}(x)) \cdot  
\mathbbm{\overrightharp{q}}_{\theta_{0}}(x) 
\Big] 
  \, \mathrm{d}\lambda_{2}(x) \, , 
  \nonumber
\\
& & \hspace{-0.2cm}   \textstyle
\theta_{0} = 
\argmin_{\theta \in \Theta} \ \max_{\tau \in \Theta} \mathcal{D}^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},
\lambda_{2}}(\mathbbm{\overrightharp{Q}}_{\theta_{0}},\mathbbm{\overrightharp{Q}}_{\theta}) .
\label{brostu2:fo.def.757c}
\end{eqnarray} 
Accordingly, in analogy to the spirit of \eqref{9a}, \eqref{15}, \eqref{15enc},
respectively Definition \ref{Def3.3new} and \eqref{c3new},
in order to achieve an estimator of the true unknown parameter $\theta_{0}$
we first extend the ``pure parametric case'' 
$\mathcal{D}^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda_{2}}: \mathcal{P}_{\Theta}^{\lambda} 
\otimes \mathcal{P}_{\Theta}^{\lambda} \mapsto \mathbb{R}$ 
to a singularity-covering functional
$\mathcal{D}^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda}: \mathcal{P}_{\Theta,emp}^{\lambda} 
\otimes \mathcal{P}_{\Theta}^{\lambda} \mapsto \mathbb{R}$, although it is not a pseudo-divergence anymore;
indeed, 
by employing the reduced form of \eqref{27new} we take
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\mathcal{D}^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda}(\mathbbm{\overrightharp{P}},\mathbbm{\overrightharp{Q}})
: = \int_{{\mathcal{X}}} 
\Big[ 
\psi_{\mathbbm{\overrightharp{q}}_{\tau}(x)}^{1,sub}\Big(
\mathbbm{\overrightharp{q}}(x) + h_{1}(x) \cdot \boldsymbol{1}_{\{0\}}(\mathbbm{\overrightharp{q}}(x))
\Big) \cdot \boldsymbol{1}_{]c_{1},\infty[}(\mathbbm{\overrightharp{q}}(x)) \qquad \ \ 
\nonumber 
\\
& & \hspace{-0.2cm}   \textstyle
+ \rho_{\mathbbm{\overrightharp{q}}_{\tau}(x)}^{sub}\Big(
\mathbbm{\overrightharp{q}}(x) + h_{2}(x) \cdot \boldsymbol{1}_{\{0\}}(\mathbbm{\overrightharp{q}}(x))
\Big) \cdot  
\mathbbm{\overrightharp{p}}(x) 
\Big] 
  \, \mathrm{d}\lambda(x) \, \quad
  \textrm{for all $\mathbbm{\overrightharp{P}} \in \mathcal{P}_{\Theta,emp}^{\lambda}, 
\mathbbm{\overrightharp{Q}} \in \mathcal{P}_{\Theta}^{\lambda}$} \, . \qquad \ \ 
\label{brostu2:fo.def.777b}
\end{eqnarray}
Hence, analogously to the derivation of \eqref{brostu2:fo.646a},
we obtain from \eqref{brostu2:fo.def.777b}
\begin{eqnarray} 
& & \hspace{-0.2cm}   \textstyle 
\sup_{\tau \in \Theta} \ 
\mathcal{D}^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda}\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big) 
\ \  = \ \ \sup_{\tau \in \Theta} \ 
\int_{\mathcal{X}} 
\psi_{\mathbbm{\overrightharp{q}}_{\tau}(x)}^{1,sub}\Big(\mathbbm{\overrightharp{q}}_{\theta}(x)\Big)  
\, \mathrm{d}\lambda_{2}(x)
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
+\sum_{x \in \mathcal{X}}  
\Big[
\psi_{\mathbbm{\overrightharp{q}}_{\tau}(x)}^{1,sub}\Big(h_{1}(x)\Big) \cdot \widecheck{c_{1}}
+ \rho_{\mathbbm{\overrightharp{q}}_{\tau}(x)}^{sub}(h_{2}(x)) \cdot \mathbbm{\overrightharp{p}}_{N}^{\overline{emp}(\omega)}(x)  
\Big] \cdot 
\boldsymbol{1}_{\mathcal{R}(Y_{1}(\omega), \ldots, Y_{N}(\omega))}(x) 
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
= \sup_{\tau \in \Theta} \ 
\int_{\mathcal{X}} 
\Big[ 
\mathbbm{\overrightharp{q}}_{\theta}(x) \cdot 
\phi\Big(\frac{\mathbbm{\overrightharp{q}}_{\tau}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}\Big)  
- \mathbbm{\overrightharp{q}}_{\tau}(x) \cdot 
\phi_{+,c}^{\prime}\Big(\frac{\mathbbm{\overrightharp{q}}_{\tau}(x)}{\mathbbm{\overrightharp{q}}_{\theta}(x)}\Big)
\Big] \, \mathrm{d}\lambda_{2}(x)
\\
& & \hspace{-0.2cm}   \textstyle
 + \frac{1}{N} \sum_{i=1}^{N} 
\phi_{+,c}^{\prime}\Big(\frac{\mathbbm{\overrightharp{q}}_{\tau}(Y_{i}(\omega))}{h_{2}(Y_{i}(\omega))}\Big) 
\nonumber
\\
& & \hspace{-0.2cm}   \textstyle
+ \frac{1}{N} \sum_{i=1}^{N}  
\frac{
h_{1}(Y_{i}(\omega)) \cdot 
\phi\Big(\frac{\mathbbm{\overrightharp{q}}_{\tau}(Y_{i}(\omega))}{h_{1}(Y_{i}(\omega))}\Big)  
- \mathbbm{\overrightharp{q}}_{\tau}(Y_{i}(\omega)) \cdot 
\phi_{+,c}^{\prime}\Big(\frac{\mathbbm{\overrightharp{q}}_{\tau}(Y_{i}(\omega))}{h_{1}(Y_{i}(\omega))}\Big)
}{\mathbbm{\overrightharp{p}}_{N}^{emp(\omega)}(Y_{i}(\omega))} \cdot \widecheck{c_{1}}
\,  \qquad \ \ 
\label{brostu2:fo.397b}
\end{eqnarray}
to be minimized over $\theta \in \Theta$. In the view of \eqref{brostu2:fo.def.757c}, we can estimate
(respectively learn) the true unknown parameter $\theta_{0}$ 
by the estimator
\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle 
\widehat{\theta}_{N,sup\mathcal{D}_{\phi,\lambda}}(\omega)
:= \arginf_{\theta \in \Theta} \ 
\sup_{\tau \in \Theta} \ 
\mathcal{D}^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda}\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big) 
\quad \textrm{for} \ \ \mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)} \in 
\mathcal{P}_{emp}^{\lambda\perp} \, ,  \qquad \ \ 
\nonumber
\end{eqnarray}
which under appropriate technical assumptions (integrability, etc.) exists, is finite, unique,
and Fisher consistent;
moreover, this method can be straightforwardly extended to non-parametric setups.
Similarly to the derivation of \eqref{brostu2:fo.646b} respectively \eqref{brostu2:fo.646c},
reasonable choices for the ``boundary-functions'' in \eqref{brostu2:fo.397b} are
$h_{2}(x) := \mathbbm{\overrightharp{q}}_{\theta}(x)$ together with
$h_{1}(x) \equiv 1$ respectively $h_{1}(x) := \mathbbm{\overrightharp{q}}_{\theta}(x)$
(where the nominator in the last sum becomes $- \mathbbm{\overrightharp{q}}_{\tau}(Y_{i}(\omega)) \cdot 
\phi_{+,c}^{\prime}(1))$). In the special case with
$c_{1}= 0 =\widecheck{c_{1}}$ -- where the choice of $h_{1}(\cdot)$ is irrelevant -- and 
$h_{2}(x) := \mathbbm{\overrightharp{q}}_{\theta}(x)$,
the estimator $\widehat{\theta}_{N,sup\mathcal{D}_{\phi,\lambda}}(\omega)$
was first proposed independently by Liese \&
Vajda~\cite{Lie:06} under the name \textsl{modified }$\phi $\textsl{-divergence
estimator }and Broniatowski \& Keziou~\cite{Bro:06},~\cite{Bro:09} under the name \textsl{
minimum dual }$\phi $\textsl{-divergence estimator}; furthermore,
within this special-case setup, Broniatowski \& Keziou~\cite{Bro:09}
also introduced for each fixed $\theta \in \Theta$ the related,
so-called
\textit{dual $\phi-$divergence estimator}
$\widehat{\theta}_{N,\theta,\mathcal{D}_{\phi,\lambda}}(\omega)
:= {} \ 
\argsup_{\tau \in \Theta} \ 
\mathcal{D}^{c}_{\phi,\mathbbm{\overrightharp{Q}}_{\tau},\lambda}\Big(\mathbbm{\overrightharp{P}}_{N}^{\overline{emp}(\omega)},\widetilde{\mathbbm{\overrightharp{Q}}}_{\theta}\Big)$.
The latter four references also work within a nonparametric framework.
Let us also mention that by 
\eqref{brostu2:fo.def.756e} and
\eqref{brostu2:fo.def.756f}, $\widehat{\theta}_{N,\mathcal{D}_{\phi,\lambda}}(\omega)$ can be 
interpreted as 
\textit{maximum sub$-\phi-$divergence estimator}, whereas 
$\widehat{\theta}_{N,sup\mathcal{D}_{\phi,\lambda}}(\omega)$
can be viewed as \textit{minimum super$-\phi-$divergence estimator}
(cf. Vajda~\cite{Vaj:08}, Broniatowski \& Vajda~\cite{Bro:12a} for
the probability-measure-theoretic context of footnote \ref{brostu2:foot1}).

\begin{remark}
Making use of the escort parameter $\tau$
proves to be useful in statistical inference under the model; its use under misspecification
has been considered in Al Mohamad~\cite{AlM:16}, for Csiszar-Ali-Silvey divergences.
\end{remark}

\noindent
As a final example, consider 
$c_{1}= 0$, $h_{2}(x) := \mathbbm{\overrightharp{q}}_{\theta}(x)$,
and $\phi(t) : = t \log t + 1 - t$, for which we can deduce
\begin{eqnarray}
& & \hspace{-0.2cm}   \textstyle 
\widehat{\theta}_{N,sup\mathcal{D}_{\phi,\lambda}}(\omega) = 
\widehat{\theta}_{N,\theta,\mathcal{D}_{\phi,\lambda}}(\omega)
= \argsup_{\xi \in \Theta} \frac{1}{N} \sum_{i=1}^{N} 
\log\Big(\mathbbm{\overrightharp{q}}_{\xi}(Y_{i}(\omega))\Big) 
\nonumber
\end{eqnarray}
for all $\theta \in \Theta$,
i.e. in this case all maximum sub$-\phi-$divergence estimators and
the minimum super$-\phi-$divergence estimator exceptionally
coincide, and 
give the celebrated maximum-likelihood estimator.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{0.4cm}
\noindent
\textbf{Acknowledgement:} W. Stummer wants to thank very much the Sorbonne Universite
Pierre et Marie Curie Paris for their partial financial support. 


%
% ---- Bibliography ----
%
\begin{thebibliography}{}
%


\bibitem{Ama:16} 
Amari, S.-I.:
Information Geometry and Its Applications. 
Springer, Japan (2016).

\bibitem{Ama:00} 
Amari, S.-I., Nagaoka, H.:
Methods of Information Geometry. 
Oxford University Press (2000)

\bibitem{Ali:66}
Ali, M.S., Silvey, D.: 
A general class of coefficients of divergence of one
distribution from another.
J. Roy. Statist. Soc. B-28, 131-140 (1966)

\bibitem{AlM:16}
Al Mohamad, D.: 
Towards a better understanding of the dual
representation of phi divergences.
Stat. Papers (2016). doi:10.1007/s00362-016-0812-5

\bibitem{Avl:16a}
Avlogiaris, G., Micheas, A., Zografos, K.:
On local divergences between two probability measures.
Metrika 79, 303-333 (2016)

\bibitem{Avl:16b}
Avlogiaris, G., Micheas, A., Zografos, K.:
On testing local hypotheses via local divergence.
Statist. Methodol. 31, 20-42 (2016)


\bibitem{Ay:17} 
Ay, N., Jost, J., Le, H.V., Schwachh{\"o}fer, L.:
Information Geometry.
Springer Intern. (2017)

\bibitem{Ban:05}
Banerjee, A., Merugu, S., Dhillon, I.S., Ghosh, J.:
Clustering with Bregman divergences.
J. Mach. Learn. Res. 6, 1705-1749 (2005)

\bibitem{Bas:98} 
Basu, A., Harris, I.R., Hjort, N.L., Jones, M.C.:
Robust and efficient estimation by minimizing a density
power divergence.
Biometrika 85(3), 549--559 (1998)

\bibitem{Bas:15a}
Basu, A., Mandal, A., Martin, N., Pardo, L.:
Robust tests for the equality of two normal means
based on the density power divergence. 
Metrika 78, 611634 (2015) 

\bibitem{Bas:11} 
Basu, A., Shioya, H., Park, C.:   
Statistical Inference: The Minimum Distance Approach. 
CRC Press, Boca Raton (2011)

\bibitem{Bir:32} 
Birkhoff, G.D:
A Set of Postulates for Plane Geometry, Based on Scale and Protractor.
Ann. Math. 33(2) 329--345 (1932) 

\bibitem{Boi:10}
Boissonnat, J.-D., Nielsen, F., Nock, R.:
Bregman Voronoi diagrams.
Discrete Comput. Geometry 44(2), 281-307 (2010)

\bibitem{Bro:06} 
Broniatowski, M., Keziou, A.:
Minimization of $\phi $-divergences on sets of signed measures.
Stud. Scient. Math. Hungar. 43, 403--442 (2006)

\bibitem{Bro:09} 
Broniatowski, M., Keziou, A.:
Parametric estimation and tests through divergences and the duality technique. 
J. Multivariate Anal. 100(1), 16--36 (2009)

\bibitem{Bro:12a} 
Broniatowski, M., Vajda, I.:
Several applications of divergence criteria in continuous families. 
Kybernetika 48(4), 600--636 (2012)

\bibitem{Bro:12b} 
Broniatowski, M., Toma, A., Vajda, I.:
Decomposable pseudodistances in statistical estimation. 
J. Statist. Plan. Inf.  142, 2574--2585 (2012)


\bibitem{Buc:91}
Buckland, M.K.: 
Information as Thing.
J. Amer. Soc. Inform. Science 42(5), 351--360 (1991)

\bibitem{Ces:06} 
Cesa-Bianchi, N., Lugosi, G.:
Prediction, Learning and Games. 
Cambridge University Press (2006)

\bibitem{Chh:15}
Chhogyal, K., Nayak, A., Sattar, A.:
On the KL Divergence of Probability Mixtures
for Belief Contraction.
In: H{\"o}lldobler,S., et al. (eds.) 
KI 2015: Advances in Artificial Intelligence.
Lecture Notes in Artificial Intelligence, vol. 9324, 
pp.\ 249-255. 
Springer Intern. (2015)


\bibitem{Cli:16}
Cliff, O.M., Prokopenko, M., Fitch, R.:
An Information Criterion for Inferring Coupling in Distributed Dynamical Systems. 
Front. Robot. AI 3(71). doi:10.3389/frobt.2016.00071 (2016) 


\bibitem{Cli:18}
Cliff, O.M., Prokopenko, M., Fitch, R.:
Minimising the Kullback-Leibler divergence
for model selection in distributed nonlinear systems.
Entropy 20(51). doi:10.3390/e20020051 (2018)


\bibitem{Col:02}
Collins, M., Schapire, R.E., Singer, Y.:
Logistic regression, AdaBoost and Bregman distances.
Mach. Learn. 48, 253--285 (2002)

\bibitem{Coo:14}
Cooper, V.N., Haddad, H.M., Shahriar, H.:
Android Malware Detection Using Kullback-Leibler Divergence.
Adv. Distrib. Comp. Art. Int. J., Special Issue 3(2) (2014)

\bibitem{Csi:63}
Csiszar, I.: 
Eine informationstheoretische Ungleichung und ihre Anwendung
auf den Beweis der Ergodizit\"at von Markoffschen Ketten. 
Publ. Math. Inst. Hungar. Acad. Sci. A-8, 85-108 (1963)

\bibitem{DeG:62}
De Groot, M.H.:
Uncertainty, information and sequential experiments. 
Ann. Math. Statist. 33 404-419 (1962)

\bibitem{Gho:16a}
Ghosh, A., Basu, A.:
Robust Bayes estimation using the density power
divergence.
Ann. Inst. Stat. Math. 68, 413437 (2016)


\bibitem{Gho:16b}
Ghosh, A., Basu, A.:
Robust estimation in generalized linear models:
the density power divergence approach.
TEST 25, 269-290 (2016) 


\bibitem{Gho:17a}
Ghosh, A., Harris, I.R., Maji, A.,
Basu, A., Pardo, L.:
A generalized divergence for statistical inference.
Bernoulli 23(4A), 2746-2783 (2017) 


\bibitem{Ham:86} 
Hampel, F.R., Ronchetti, E.M., Rousseuw, P.J., Stahel, W.A.: 
Robust Statistics: The Approach Based on Influence Functions.
Wiley, New York (1986)

\bibitem{Kis:13}
Ki{\ss}linger, A.-L., Stummer, W.: 
Some Decision Procedures Based on Scaled Bregman Distance Surfaces. 
In: Nielsen, F., Barbaresco, F. (eds.) Geometric Science of Information GSI 2013. 
Lecture Notes in Computer Science,
vol. 8085, 
pp. 479-486. 
Springer, Berlin (2013)

\bibitem{Kis:15a}
Ki{\ss}linger, A.-L., Stummer, W.: 
New model search for nonlinear recursive models, regressions and autoregressions. 
In: Nielsen, F., Barbaresco, F. (eds.) Geometric Science of Information GSI 2015. 
Lecture Notes in Computer Science, 
vol. 9389, 
pp. 693-701. 
Springer, Berlin (2015)

\bibitem{Kis:16}
Ki{\ss}linger, A.-L., Stummer, W.:
Robust statistical engineering by means of scaled Bregman distances.
In: Agostinelli, C., Basu, A., Filzmoser, P., and Mukherjee, D. (eds.) 
Recent Advances in Robust Statistics -- Theory and Applications, pp. 81--113.
Springer India (2016)

\bibitem{Kis:17b}
Ki{\ss}linger, A.-L., Stummer, W.:
A New Toolkit for Robust Distributional Change Detection.
Submitted preprint (2017)


\bibitem{Lie:08}
Liese, F., Miescke, K.J.: 
Statistical Decision Theory: Estimation, Testing, and Selection.
Springer, New York (2008)

\bibitem{Lie:87}
Liese, F., Vajda, I.: Convex statistical distances. 
Teubner, Leipzig (1987)

\bibitem{Lie:06}
Liese, F., Vajda, I.:  
On divergences and informations in statistics and information theory. 
IEEE Trans. Inf. Theory 52(10): 4394-4412 (2006)

\bibitem{Liu:10}
Liu, M., Vemuri, B.C., Amari, S.-I., Nielsen, F.: 
Total Bregman divergence and its applications to
shape retrieval. 
Proc. 23rd IEEE CVPR, 3463--3468 (2010)

\bibitem{Liu:12}
Liu, M., Vemuri, B.C., Amari S.-I., Nielsen, F.: 
Shape retrieval using hierarchical total Bregman soft
clustering. 
IEEE Trans. Pattern Analysis and Machine Intelligence 34(12),
2407--2419 (2012) 

\bibitem{Liz:14}
Lizier, J.T.: 
JIDT: an information-theoretic toolkit for studying the dynamcis
of compex systems. 
Front. Robot. AI 1(11).
doi:10.3389/frobt.2014.00011 (2014) 

\bibitem{Mil:91}
Millmann, R.S., Parker, G.D.:
Geometry - A Metric Approach With Models, 2nd Ed.
Springer, New York (1991)

\bibitem{Min:05}
Minka, T.:
Divergence measures and message passing.
Technical Report MSR-TR-2005-173, 
Microsoft Research Ltd., Cambridge, UK (2005)


\bibitem{Mur:04}
Murata, N., Takenouchi, T., Kanamori, T., Eguchi, S.: 
Information geometry of U-boost and Bregman divergence. 
Neural Comput. 16(7), 1437-1481 (2004)

\bibitem{Nie:13a}
Nielsen, F., Barbaresco, F. (eds.): 
Geometric Science of Information GSI 2013.
Lecture Notes in Computer Science, vol. 8085. 
Springer, Berlin (2013)

\bibitem{Nie:15a}
Nielsen, F., Barbaresco, F. (eds.): 
Geometric Science of Information GSI 2015.
Lecture Notes in Computer Science, vol. 9389. 
Springer Intern. (2015)

\bibitem{Nie:17a}
Nielsen, F., Barbaresco, F. (eds.): 
Geometric Science of Information GSI 2017.
Lecture Notes in Computer Science, vol. 10589. 
Springer Intern. (2017)

\bibitem{Nie:13b}
Nielsen, F., Bhatia, R. (eds.):
Matrix Information Geometry.
Springer, Berlin (2013)

\bibitem{Nie:17b}
Nielsen, F., Nock, R.: 
Bregman divergences from comparative convexity.
In: Nielsen, F., Barbaresco, F. (eds.) Geometric Science of Information GSI 2017. 
Lecture Notes in Computer Science, 
vol. 10589, 
pp.\ 639-647. 
International: Springer; 2017

\bibitem{Nie:17c}
Nielsen, F., Sun, K., Marchand-Maillet,S.:
On H{\"o}lder projective divergences. 
Entropy 19, 122 (2017)


\bibitem{Nie:17d}
Nielsen, F., Sun, K., Marchand-Maillet,S.: 
K-means clustering with H{\"o}lder divergences.
In: Nielsen, F., Barbaresco, F. (eds.) Geometric Science of Information GSI 2017. 
Lecture Notes in Computer Science, 
vol. 10589,   
pp.\ 856-863. 
International: Springer; 2017

\bibitem{Noc:16a}
Nock, R., Menon, A.K., Ong, C.S.: 
A scaled Bregman theorem with applications. 
Advances in Neural Information Processing Systems 29 (NIPS 2016), 
pages 19--27 (2016) 


\bibitem{Noc:09}
Nock, R., Nielsen, F.: 
Bregman divergences and surrogates for learning. 
IEEE Trans. Pattern Anal. Mach. Intell. 31 (11), 2048--2059 (2009)


\bibitem{Noc:16b}
Nock, R., Nielsen, F., Amari, S.-I.: 
On Conformal Divergences and their
Population Minimizers. 
IEEE Transaction on Information Theory 62 (1), 527--538 (2016)

\bibitem{Oes:93}
{\"O}sterreicher, F., Vajda, I.:
Statistical information and discrimination. 
IEEE Trans. Inform. Theory 39, 1036--1039 (1993)

\bibitem{Par:06} 
Pardo, L.: 
Statistical inference based on divergence measures. 
Chapman \& Hall/CRC 
(2006)


\bibitem{Pat:13}
Patra, S., Maji, A., Basu, A., Pardo, L.:
The power divergence and the density power divergence
families: the mathematical connection.
Sankhya 75-B Part 1, 16--28 (2013) 

\bibitem{Rea:88}
Read, T.R.C., Cressie N.A.C.: 
Goodness-of-Fit Statistics for Discrete Multivariate Data. 
Springer, New York (1988)

\bibitem{Rei:11}
Reid, M.D., Williamson, R.C.:
Information, Divergence and Risk for Binary Experiments
J. Machine Learn. Res. 12, 731--817 (2011)

\bibitem{Roe:17}
Roensch, B., Stummer, W.: 
3D insights to some divergences for robust statistics and machine learning.
In: Nielsen, F., Barbaresco, F. (eds.) Geometric Science of Information GSI 2017. 
Lecture Notes in Computer Science, 
vol. 10589, 
pp.\ 460-469. 
Springer Intern. (2017)

\bibitem{Rue:84}
R{\"u}schendorf, L.:
On the minimum discrimination information system.
Statistics \& Decisions Suppl. Issue 1, 263-283 (1984)


\bibitem{Stu:99a}
Stummer, W: 
On a statistical information measure of diffusion processes.
Statistics \& Decisions 17, 359--376 (1999)

\bibitem{Stu:01a}
Stummer, W: 
On a statistical information measure for a generalized Samuelson-Black-Scholes model. 
Statistics \& Decisions 19, 289--314 (2001)

\bibitem{Stu:04a}
Stummer, W: 
Exponentials, diffusions, finance, entropy and information. 
Shaker, Aachen (2004)

\bibitem{Stu:07} 
Stummer, W.: 
Some Bregman distances between financial diffusion processes.
Proc.\ Appl.\ Math.\ Mech. 7(1), 1050503 -- 1050504 (2007)

\bibitem{Stu:17a}
Stummer, W., Ki{\ss}linger, A-L.: 
Some new flexibilizations of Bregman divergences and their asymptotics. 
In: Nielsen, F., Barbaresco, F. (eds.) Geometric Science of Information GSI 2017. 
Lecture Notes in Computer Science, 
vol. 10589, 
pp.\ 514-522. 
International: Springer; 2017


\bibitem{Stu:10}
Stummer, W., Vajda, I.: 
On divergences of finite measures and their
applicability in statistics and information theory. Statistics 44, 
169-187 (2010)

\bibitem{Stu:12}
Stummer, W., Vajda, I.: 
On Bregman Distances and Divergences of Probability Measures.
IEEE Transaction on Information Theory 58 (3), 1277--1288 (2012)

\bibitem{Sug:12}
Sugiyama, M., Suzuki, T., Kanamori, T.:
Density-ratio matching under the Bregman divergence: a
unified framework of density-ratio estimation.
Ann. Inst. Stat. Math. 64, 1009-1044 (2012)

\bibitem{Tsu:05}
Tsuda, K., R{\"a}tsch, G., Warmuth, M.: 
Matrix exponentiated gradient updates for on-line learning and
Bregman projection. 
J. Mach. Learn. Res. 6, 995-1018 (2005) 

\bibitem{Vaa:96} 
Vaart, A.W. van der, Wellner, J.A.:
Weak Convergence and Empirical Processes.
Springer, Berlin (1996)

\bibitem{Vaj:89} 
Vajda, I.: 
Theory of statistical inference and information. Kluwer, Dordrecht (1989)

\bibitem{Vaj:08} 
Vajda, I.: 
Modifications of divergence criteria for applications in continuous families.
Research Report No. 2230, Institute of Information Theory and Automation, Prague (2008)


\bibitem{Ver:11a}
Vemuri, B.C., Liu, M., Amari, S.-I., Nielsen, F.:  
Total Bregman divergence and its applications to
DTI analysis. 
IEEE Trans. Med. Imag. 30(2), 475--483 (2011)

\bibitem{Wu:12}
Wu, L., Hoi, S.C.H, Jin, R., Zhu, J., Yu, N..: 
Learning Bregman distance functions
for semi-supervised clustering.
IEEE Transaction on Knowledge and Data Engineering 24(3), 
478--491 (2012)

\bibitem{Zha:17}
Zhang, J., Naudts, J.: 
Information geometry under monotone embedding, part I: divergence functions. 
In: Nielsen, F., Barbaresco, F. (eds.) Geometric Science of Information GSI 2017. 
Lecture Notes in Computer Science, 
vol. 10589,  
pp.\ 205-214. 
International: Springer; 2017


\bibitem{Zha:14}
Zhang, J., Wang, X., Yao, L., Li, J., Shen, X.:
Using Kullback-Leibler Divergence to Model Opponents in Poker.
Computer Poker and Imperfect Information: Papers from the AAAI-14 Workshop (2014)


\end{thebibliography}


\end{document}
