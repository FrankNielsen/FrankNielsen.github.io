
 @book{Jeffreys-1998,
  title={The theory of probability},
  author={Jeffreys, Harold},
  year={1998},
  publisher={OUP Oxford}
}

@Article{nielsen2020generalization,
AUTHOR = {Nielsen, Frank},
TITLE = {{On a Generalization of the Jensen–Shannon Divergence and the Jensen–Shannon Centroid}},
JOURNAL = {Entropy},
VOLUME = {22},
YEAR = {2020},
NUMBER = {2},
ARTICLE-NUMBER = {221},
URL = {https://www.mdpi.com/1099-4300/22/2/221},
ISSN = {1099-4300},
ABSTRACT = {The Jensen&ndash;Shannon divergence is a renown bounded symmetrization of the Kullback&ndash;Leibler divergence which does not require probability densities to have matching supports. In this paper, we introduce a vector-skew generalization of the scalar    &alpha;   -Jensen&ndash;Bregman divergences and derive thereof the vector-skew    &alpha;   -Jensen&ndash;Shannon divergences. We prove that the vector-skew    &alpha;   -Jensen&ndash;Shannon divergences are f-divergences and study the properties of these novel divergences. Finally, we report an iterative algorithm to numerically compute the Jensen&ndash;Shannon-type centroids for a set of probability densities belonging to a mixture family: This includes the case of the Jensen&ndash;Shannon centroid of a set of categorical distributions or normalized histograms.},
DOI = {10.3390/e22020221}
}





   title={{On a generalization of the Jensen--Shannon divergence and the Jensen--Shannon centroid}},
  author={Nielsen, Frank},
  journal={Entropy},
  volume={22},
  number={2},
  pages={221},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}


J. Lin and S.K.M. Wong, "Approximation of Discrete Probability Distributions Based on a New Divergence Measure", Congressus Numerantium, (Winnipeg, 1988), 75-80.
@article{JW-1988,
  title={Approximation of discrete probability distributions based on a new divergence measure},
  author={Lin, Jianhua and Wong, SKM},
  journal={Congressus Numerantium (Winnipeg)},
  volume={61},
  pages={75--80},
  year={1988}
}


@article{Jeffreys-1946,
  title={An invariant form for the prior probability in estimation problems},
  author={Jeffreys, Harold},
  journal={Proceedings of the Royal Society of London. Series A. Mathematical and Physical Sciences},
  volume={186},
  number={1007},
  pages={453--461},
  year={1946},
  publisher={The Royal Society London}
}


@article{WongYOU-1985,
  title={Entropy and distance of random graphs with application to structural pattern recognition},
  author={Wong, Andrew KC and You, Manlai},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  number={5},
  pages={599--609},
  year={1985},
  publisher={IEEE}
}

@article{Tsallis-1988,
  title={{Possible generalization of Boltzmann-Gibbs statistics}},
  author={Tsallis, Constantino},
  journal={Journal of statistical physics},
  volume={52},
  number={1},
  pages={479--487},
  year={1988},
  publisher={Springer}
}

@article{VoronoiCauchy-2020,
  title={{On Voronoi diagrams on the information-geometric Cauchy manifolds}},
  author={Nielsen, Frank},
  journal={Entropy},
  volume={22},
  number={7},
  pages={713},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@book{Naudts-2011,
  title={Generalised thermostatistics},
  author={Naudts, Jan},
  year={2011},
  publisher={Springer Science \& Business Media}
}


@article{conformaldiv-2015,
  title={On conformal divergences and their population minimizers},
  author={Nock, Richard and Nielsen, Frank and Amari, Shun-ichi},
  journal={IEEE Transactions on Information Theory},
  volume={62},
  number={1},
  pages={527--538},
  year={2015},
  publisher={IEEE}
}

@article{de2016mean,
  title={Mean, what do you Mean?},
  author={de Carvalho, Miguel},
  journal={The American Statistician},
  volume={70},
  number={3},
  pages={270--274},
  year={2016},
  publisher={Taylor \& Francis}
}

@article{infoproj-2021,
  title={On information projections between multivariate elliptical and location-scale families},
  author={Nielsen, Frank},
  journal={arXiv preprint arXiv:2101.03839},
  year={2021}
}

@article{FenchelYoung-2020,
  title={{Learning with Fenchel-Young losses}},
  author={Blondel, Mathieu and Martins, Andr{\'e} FT and Niculae, Vlad},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={35},
  pages={1--69},
  year={2020}
}


@article{fdivchiorder-2013,
  title={On the chi square and higher-order chi distances for approximating $f$-divergences},
  author={Nielsen, Frank and Nock, Richard},
  journal={IEEE Signal Processing Letters},
  volume={21},
  number={1},
  pages={10--13},
  year={2013},
  publisher={IEEE}
}

@inproceedings{MinkowskiDiv-2019,
  title={{The statistical Minkowski distances: Closed-form formula for Gaussian mixture models}},
  author={Nielsen, Frank},
  booktitle={International Conference on Geometric Science of Information},
  pages={359--367},
  year={2019},
  organization={Springer}
}




@Article{vJSD-2021,
AUTHOR = {Nielsen, Frank},
TITLE = {{On a Variational Definition for the Jensen-Shannon Symmetrization of Distances Based on the Information Radius}},
JOURNAL = {Entropy},
VOLUME = {23},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {464},
URL = {https://www.mdpi.com/1099-4300/23/4/464},
ISSN = {1099-4300},
DOI = {10.3390/e23040464}
}





@article{EF-2009,
  title={Statistical exponential families: A digest with flash cards},
  author={Nielsen, Frank and Garcia, Vincent},
  journal={arXiv:0911.4863},
  year={2009}
}


@article{CauchyJSD-2021,
  title={On $f$-divergences between Cauchy distributions},
  author={Nielsen, Frank and Okamura, Kazuki},
  journal={arXiv:2101.12459},
  year={2021}
}


@article{BregmanManifold-2021,
  title={On Geodesic Triangles with Right Angles in a Dually Flat Space},
  author={Nielsen, Frank},
  journal={Progress in Information Geometry: Theory and Applications},
  pages={153--190},
  year={2021},
  publisher={Springer International Publishing}
}


@article{TransportInfoBD-2021,
  title={{Transport information Bregman divergences}},
  author={Li, Wuchen},
  journal={arXiv:2101.01162},
  year={2021}
}


@book{diffentropy-2013,
  title={Handbook of differential entropy},
  author={Michalowicz, Joseph Victor and Nichols, Jonathan M and Bucholtz, Frank},
  year={2013},
  publisher={CRC Press}
}


@article{KLDWeibull-2013,
  title={{Computing the Kullback-Leibler divergence between two Weibull distributions}},
  author={Bauckhage, Christian},
  journal={arXiv:1310.3713},
  year={2013}
}


 @inproceedings{crossentropyEF-2010,
  title={Entropies and cross-entropies of exponential families},
  author={Nielsen, Frank and Nock, Richard},
  booktitle={2010 IEEE International Conference on Image Processing},
  pages={3621--3624},
  year={2010},
  organization={IEEE}
}

@book{IG-2014,
  title={Geometric Modeling in Probability and Statistics},
  author={Calin, O. and Udriste, C.},
  isbn={9783319077796},
  series={Mathematics and Statistics},
  year={2014},
  publisher={Springer International Publishing}
}

% upper bound on GMMs
@article{AmariOhara-2011,
  title={Geometry of $q$-exponential family of probability distributions},
  author={Amari, Shun-ichi and Ohara, Atsumi},
  journal={Entropy},
  volume={13},
  number={6},
  pages={1170--1185},
  year={2011},
  publisher={Molecular Diversity Preservation International (MDPI)}
}


@article{GenBhat-2014,
  title={{Generalized Bhattacharyya and Chernoff upper bounds on Bayes error using quasi-arithmetic means}},
  author={Nielsen, Frank},
  journal={Pattern Recognition Letters},
  volume={42},
  pages={25--34},
  year={2014},
  publisher={Elsevier}
}


@article{Csiszar-1967,
  title={On topological properties of $f$-divergences},
  author={Csisz{\'a}r, I},
  journal={Studia Math. Hungar.},
  volume={2},
  pages={329--339},
  year={1967}
}


 

@article{verdu2021error,
  title={Error Exponents and $\alpha$-Mutual Information},
  author={Verd{\'u}, Sergio},
  journal={Entropy},
  volume={23},
  number={2},
  pages={199},
  year={2021},
  publisher={Multidisciplinary Digital Publishing Institute}
}
@article{candan2020chebyshev,
  title={Chebyshev Center Computation on Probability Simplex With $\alpha$-Divergence Measure},
  author={Candan, {\c{C}}agatay},
  journal={IEEE Signal Processing Letters},
  volume={27},
  pages={1515--1519},
  year={2020},
  publisher={IEEE}
}

@article{RenyiCenter-2018,
  title={The R{\'e}nyi capacity and center},
  author={Nakibo{\u{g}}lu, Bar{\i}{\c{s}}},
  journal={IEEE Transactions on Information Theory},
  volume={65},
  number={2},
  pages={841--860},
  year={2018},
  publisher={IEEE}
}

@article{Chernoff-2013,
  title={{An information-geometric characterization of Chernoff information}},
  author={Nielsen, Frank},
  journal={IEEE Signal Processing Letters},
  volume={20},
  number={3},
  pages={269--272},
  year={2013},
  publisher={IEEE}
}

@article{Chernoff-2011,
  title={Chernoff information of exponential families},
  author={Nielsen, Frank},
  journal={arXiv preprint arXiv:1102.2684},
  year={2011}
}


@article{LikelihoodRatioEF-2020,
  title={Likelihood Ratio Exponential Families},
  author={Brekelmans, Rob and Nielsen, Frank and Makhzani, Alireza and Galstyan, Aram and Steeg, Greg Ver},
  journal={arXiv preprint arXiv:2012.15480},
  year={2020}
}

@article{Frechet-1948,
  title={Les {\'e}l{\'e}ments al{\'e}atoires de nature quelconque dans un espace distanci{\'e}},
  author={Fr{\'e}chet, Maurice},
  journal={Annales de l'institut Henri Poincar{\'e}},
  volume={10},
  number={4},
  pages={215--310},
  year={1948}
}

@article{Sibson-1981,
  title={A brief description of natural neighbour interpolation},
  author={Sibson, Robin},
  journal={Interpreting multivariate data},
  year={1981},
  publisher={John Wiley \& Sons}
}


@article{JSApp-2009,
  title={{Fisher and Jensen--Shannon divergences: Quantitative comparisons among distributions. application to position and momentum atomic densities}},
  author={Antol{\'\i}n, J and Angulo, JC and L{\'o}pez-Rosa, S},
  journal={The Journal of chemical physics},
  volume={130},
  number={7},
  pages={074110},
  year={2009},
  publisher={American Institute of Physics}
}

@article{Csiszar-2008,
  title={Axiomatic characterizations of information measures},
  author={Csisz{\'a}r, Imre},
  journal={Entropy},
  volume={10},
  number={3},
  pages={261--273},
  year={2008},
  publisher={Molecular Diversity Preservation International}
}


@article{InfProj-2018,
  title={What is an information projection?},
  author={Nielsen, Frank},
  journal={Notices of the AMS},
  volume={65},
  number={3},
  pages={321--324},
  year={2018}
}


@article{Lenzi-2000,
  title={{Statistical mechanics based on R\'enyi entropy}},
  author={Lenzi, EK and Mendes, RS and Da Silva, LR},
  journal={Physica A: Statistical Mechanics and its Applications},
  volume={280},
  number={3-4},
  pages={337--345},
  year={2000},
  publisher={Elsevier}
}

@article{Entropy-1995,
  title={A summary on entropy statistics},
  author={Esteban, Maria Dolores and Morales, Domingo},
  journal={Kybernetika},
  volume={31},
  number={4},
  pages={337--346},
  year={1995},
  publisher={Institute of Information Theory and Automation AS CR}
}

@article{kmeans-1982,
  title={{Least squares quantization in PCM}},
  author={Lloyd, Stuart},
  journal={IEEE transactions on information theory},
  volume={28},
  number={2},
  pages={129--137},
  year={1982},
  publisher={IEEE}
}

@book{Bullen-2013,
  title={Handbook of means and their inequalities},
  author={Bullen, Peter S},
  volume={560},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@book{DL-2016,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  year={2016},
  publisher={MIT press Cambridge}
}

@book{Mixtures-2004,
  title={Finite Mixture Models},
  author={McLachlan, Geoffrey J and Peel, David},
  year={2004},
  publisher={John Wiley \& Sons}
}

@article{fdivMorimoto-1963,
  title={{Markov processes and the $H$-theorem}},
  author={Morimoto, Tetsuzo},
  journal={Journal of the Physical Society of Japan},
  volume={18},
  number={3},
  pages={328--331},
  year={1963},
  publisher={The Physical Society of Japan}
}


@article{fdiv-AliSilvey-1966,
  title={A general class of coefficients of divergence of one distribution from another},
  author={Ali, Syed Mumtaz and Silvey, Samuel D},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={28},
  number={1},
  pages={131--142},
  year={1966},
  publisher={Wiley Online Library},
	nfnote={For MVNs with same covar, the $f$-divergences are increasing function of the squared Mahalanobis distance}
}


@book{Kullback-1997,
  title={Information theory and statistics},
  author={Kullback, Solomon},
  year={1997},
  publisher={Courier Corporation}
}

@article{variationalRenyi-2020,
  title={Variational Representations and Neural Network Estimation for R{\'e}nyi Divergences},
  author={Birrell, Jeremiah and Dupuis, Paul and Katsoulakis, Markos A and Rey-Bellet, Luc and Wang, Jie},
  journal={arXiv preprint arXiv:2007.03814},
  year={2020}
}

@book{EF-2014,
  title={Information and exponential families: in statistical theory},
  author={Barndorff-Nielsen, Ole},
  year={2014},
  publisher={John Wiley \& Sons}
}


@article{SBD-2009,
  title={{Sided and symmetrized Bregman centroids}},
  author={Nielsen, Frank and Nock, Richard},
  journal={IEEE transactions on Information Theory},
  volume={55},
  number={6},
  pages={2882--2904},
  year={2009},
  publisher={IEEE}
}

@inproceedings{Grosse-2013,
  title={Annealing between distributions by averaging moments},
  author={Grosse, Roger and Maddison, Chris J and Salakhutdinov, Ruslan},
  booktitle={Proceedings of the 26th International Conference on Neural Information Processing Systems},
  pages={2769--2777},
  year={2013}
}

@article{AISqpath-2020,
  title={Annealed Importance Sampling with $q$-Paths},
  author={Brekelmans, Rob and Masrani, Vaden and Bui, Thang and Wood, Frank and Galstyan, Aram and Steeg, Greg Ver and Nielsen, Frank},
  journal={arXiv preprint arXiv:2012.07823},
  year={2020}
}


@article{KLLSE-2016,
  title={Guaranteed bounds on information-theoretic measures of univariate mixtures using piecewise log-sum-exp inequalities},
  author={Nielsen, Frank and Sun, Ke},
  journal={Entropy},
  volume={18},
  number={12},
  pages={442},
  year={2016},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{RenyiDiv-2014,
  title={{R{\'e}nyi divergence and Kullback-Leibler divergence}},
  author={Van Erven, Tim and Harremos, Peter},
  journal={IEEE Transactions on Information Theory},
  volume={60},
  number={7},
  pages={3797--3820},
  year={2014},
  publisher={IEEE}
}


@article{minmax-2013,
  title={{On approximating the Riemannian $1$-center}},
  author={Arnaudon, Marc and Nielsen, Frank},
  journal={Computational Geometry},
  volume={46},
  number={1},
  pages={93--104},
  year={2013},
  publisher={Elsevier}
}


@article{ChebyshevAlphaDiv-2020,
  title={Chebyshev Center Computation on Probability Simplex With $\alpha$-Divergence Measure},
  author={Candan, {\c{C}}agatay},
  journal={IEEE Signal Processing Letters},
  volume={27},
  pages={1515--1519},
  year={2020},
  publisher={IEEE}
}


 


@article{EN-PhD-Csiszar-1967,
  title={Information-type measures of difference of probability distributions and indirect observation},
  author={Csisz{\'a}r, Imre},
  journal={studia scientiarum Mathematicarum Hungarica},
  volume={2},
  pages={229--318},
  year={1967}
}

@article{JScentroid-2020,
  title={{On a generalization of the Jensen--Shannon divergence and the Jensen--Shannon centroid}},
  author={Nielsen, Frank},
  journal={Entropy},
  volume={22},
  number={2},
  pages={221},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{BR-2011,
  title={{The Burbea-Rao and Bhattacharyya centroids}},
  author={Nielsen, Frank and Boltz, Sylvain},
  journal={IEEE Transactions on Information Theory},
  volume={57},
  number={8},
  pages={5455--5466},
  year={2011},
  publisher={IEEE}
}

@inproceedings{VIGJSD-2020,
  title={{Constraining Variational Inference with Geometric Jensen-Shannon Divergence}},
  author={Jacob Deasy and Nikola Simidjievski and Pietro Li{\`o}},
  booktitle = {Advances in Neural Information Processing Systems},
  year={2020}
}

@article{JensenComparative-2017,
  title={{Generalizing skew Jensen divergences and Bregman divergences with comparative convexity}},
  author={Nielsen, Frank and Nock, Richard},
  journal={IEEE Signal Processing Letters},
  volume={24},
  number={8},
  pages={1123--1127},
  year={2017},
  publisher={IEEE}
}
@inproceedings{Nagumo-1930,
  title={{\"U}ber eine klasse der mittelwerte},
  author={Nagumo, Mitio},
  booktitle={Japanese journal of mathematics: transactions and abstracts},
  volume={7},
  pages={71--79},
  year={1930},
  organization={The Mathematical Society of Japan}
}
@book{WeightedMean-2018,
  title={{Convex Functions and Their Applications: A Contemporary Approach}},
  author={Niculescu, Constantin P and Persson, Lars-Erik},
  year={2018},
  publisher={Springer}
}

@article{nielsen2010family,
  title={{A family of statistical symmetric divergences based on Jensen's inequality}},
  author={Nielsen, Frank},
  journal={arXiv preprint arXiv:1009.4004},
	url={https://arxiv.org/abs/1009.4004},
  year={2010}
}


@article{GAN-2014,
  title={Generative adversarial networks},
  author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.2661},
  year={2014}
}



@Article{JSsym-2019,
AUTHOR = {Nielsen, Frank},
TITLE = {{On the Jensen–Shannon Symmetrization of Distances Relying on Abstract Means}},
JOURNAL = {Entropy},
VOLUME = {21},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {485},
URL = {https://www.mdpi.com/1099-4300/21/5/485},
ISSN = {1099-4300},
ABSTRACT = {The Jensen&ndash;Shannon divergence is a renowned bounded symmetrization of the unbounded Kullback&ndash;Leibler divergence which measures the total Kullback&ndash;Leibler divergence to the average mixture distribution. However, the Jensen&ndash;Shannon divergence between Gaussian distributions is not available in closed form. To bypass this problem, we present a generalization of the Jensen&ndash;Shannon (JS) divergence using abstract means which yields closed-form expressions when the mean is chosen according to the parametric family of distributions. More generally, we define the JS-symmetrizations of any distance using parameter mixtures derived from abstract means. In particular, we first show that the geometric mean is well-suited for exponential families, and report two closed-form formula for (i) the geometric Jensen&ndash;Shannon divergence between probability densities of the same exponential family; and (ii) the geometric JS-symmetrization of the reverse Kullback&ndash;Leibler divergence between probability densities of the same exponential family. As a second illustrating example, we show that the harmonic mean is well-suited for the scale Cauchy distributions, and report a closed-form formula for the harmonic Jensen&ndash;Shannon divergence between scale Cauchy distributions. Applications to clustering with respect to these novel Jensen&ndash;Shannon divergences are touched upon.},
DOI = {10.3390/e21050485}
}



 

@book{Billingsley-2008,
  title={Probability and measure},
  author={Billingsley, Patrick},
  year={2008},
  publisher={John Wiley \& Sons}
}

@article{Nielsen-1998,
  title={An output-sensitive convex hull algorithm for planar objects},
  author={Nielsen, Frank and Yvinec, Mariette},
  journal={International Journal of Computational Geometry \& Applications},
  volume={8},
  number={01},
  pages={39--65},
  year={1998},
  publisher={World Scientific}
}

@book{ConvexOptim-2004,
  title={Convex optimization},
  author={Boyd, Stephen and Boyd, Stephen P and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@article{JS-1991,
  title={{Divergence measures based on the Shannon entropy}},
  author={Lin, Jianhua},
  journal={IEEE Transactions on Information theory},
  volume={37},
  number={1},
  pages={145--151},
  year={1991},
  publisher={IEEE}
}

@inproceedings{JSmetric-2004,
  title={{Jensen-Shannon divergence and Hilbert space embedding}},
  author={Fuglede, Bent and Topsoe, Flemming},
  booktitle={International Symposium onInformation Theory, 2004. ISIT 2004. Proceedings.},
  pages={31},
  year={2004},
  organization={IEEE}
}

@article{JSmetric-2003,
  title={A new metric for probability distributions},
  author={Endres, Dominik Maria and Schindelin, Johannes E},
  journal={IEEE Transactions on Information theory},
  volume={49},
  number={7},
  pages={1858--1860},
  year={2003},
  publisher={IEEE}
}


@article{QuantumJSD-2021,
title = {{The metric property of the quantum Jensen-Shannon divergence}},
journal = "Advances in Mathematics",
volume = "380",
pages = "107595",
year = "2021",
issn = "0001-8708",
doi = "https://doi.org/10.1016/j.aim.2021.107595",
url = "http://www.sciencedirect.com/science/article/pii/S0001870821000335",
author = "Dániel Virosztek"}

@article{Sibson-1969,
  title={Information radius},
  author={Sibson, Robin},
  journal={Zeitschrift f{\"u}r Wahrscheinlichkeitstheorie und verwandte Gebiete},
  volume={14},
  number={2},
  pages={149--160},
  year={1969},
  publisher={Springer}
}

@book{MathematicalTaxonomy-1971,
  title={Mathematical Taxonomy},
  author={Jardine, N. and Jardine, P.H.P.S.N. and Sibson, R.},
  isbn={9780471440505},
  lccn={lc70149578},
  series={Wiley series in probability and mathematical statistics},
  year={1971},
  publisher={Wiley}
}

@article{Chen-BD1-2008,
  title={{Metrics defined by Bregman divergences}},
  author={Chen, Pengwen and Chen, Yunmei and Rao, Murali},
  journal={Communications in Mathematical Sciences},
  volume={6},
  number={4},
  pages={915--926},
  year={2008},
  publisher={International Press of Boston}
}

@article{Csiszar-1964,
  title={Eine informationstheoretische ungleichung und ihre anwendung auf beweis der ergodizitaet von markoffschen ketten},
  author={Csisz{\'a}r, Imre},
  journal={Magyer Tud. Akad. Mat. Kutato Int. Koezl.},
  volume={8},
  pages={85--108},
  year={1964}
}

@book{CoverThomasIT-2012,
  title={Elements of information theory},
  author={Cover, Thomas M. and Thomas, Joy A.},
  year={2012},
  publisher={John Wiley \& Sons}
}

	@book{IG-2016,
  title={Information Geometry and Its Applications},
  author={Amari, Shun-ichi},
  isbn={9784431559771},
  series={Applied Mathematical Sciences},
  year={2016},
  publisher={Springer Japan}
}

@article{Bregman-1967,
  title={The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming},
  author={Bregman, Lev M.},
  journal={USSR computational mathematics and mathematical physics},
  volume={7},
  number={3},
  pages={200--217},
  year={1967},
  publisher={Elsevier}
}

@article{Pelletier-2005,
  title={Informative barycentres in statistics},
  author={Pelletier, Bruno},
  journal={Annals of the Institute of Statistical Mathematics},
  volume={57},
  number={4},
  pages={767--780},
  year={2005},
  publisher={Springer}
}

@article{Chen-BD2-2008,
  title={{Metrics defined by Bregman divergences: Part 2}},
  author={Chen, Pengwen and Chen, Yunmei and Rao, Murali},
  journal={Communications in Mathematical Sciences},
  volume={6},
  number={4},
  pages={927--948},
  year={2008},
  publisher={International Press of Boston}
}

@incollection{LearningMixtureKde-2013,
  title={Learning mixtures by simplifying kernel density estimators},
  author={Schwander, Olivier and Nielsen, Frank},
  booktitle={Matrix Information Geometry},
  pages={403--426},
  year={2013},
  publisher={Springer}
}

@article{BregmanKmeans-2005,
  title={Clustering with {B}regman divergences},
  author={Banerjee, Arindam and Merugu, Srujana and Dhillon, Inderjit S and Ghosh, Joydeep},
  journal={Journal of machine learning research},
  volume={6},
  number={Oct},
  pages={1705--1749},
  year={2005}
}

@article{MusicGMM-2015,
  title={{Modeling the affective content of music with a Gaussian mixture model}},
  author={Wang, Ju-Chiang and Yang, Yi-Hsuan and Wang, Hsin-Min and Jeng, Shyh-Kang},
  journal={IEEE Transactions on Affective Computing},
  volume={6},
  number={1},
  pages={56--68},
  year={2015},
  publisher={IEEE}
}

@inproceedings{ClusteringGaussian-2016,
  title={{Clustering of Gaussian distributions}},
  author={Spurek, Przemys{\l}aw and Pa{\l}ka, Wies{\l}aw},
  booktitle={2016 International Joint Conference on Neural Networks (IJCNN)},
  pages={3346--3353},
  year={2016},
  organization={IEEE}
}
 
@inproceedings{ClusteringGMM-2013,
  title={{Information-Theoretic Clustering for Gaussian Mixture Model via Divergence Factorization}},
  author={Duan, Jiuding and Wang, Yan},
  booktitle={Proceedings of 2013 Chinese Intelligent Automation Conference},
  pages={565--573},
  year={2013},
  organization={Springer}
}

@inproceedings{ClusteringGaussian-2008,
  title={Clustering multivariate normal distributions},
  author={Nielsen, Frank and Nock, Richard},
  booktitle={Emerging Trends in Visual Computing},
  pages={164--174},
  year={2008},
  organization={Springer}
}

@article{SimplifyingMixtures-2010,
  title={Simplifying mixture models through function approximation},
  author={Zhang, Kai and Kwok, James T},
  journal={IEEE Transactions on Neural Networks},
  volume={21},
  number={4},
  pages={644--658},
  year={2010},
  publisher={IEEE}
}

@inproceedings{EntropicClusteringGaussians-2006,
  title={{Differential entropic clustering of multivariate Gaussians}},
  author={Davis, Jason V and Dhillon, Inderjit},
  booktitle={Proceedings of the 19th International Conference on Neural Information Processing Systems},
  pages={337--344},
  year={2006}
}


@article{QuantizationBregman-2010,
  title={{Quantization and clustering with Bregman divergences}},
  author={Fischer, Aur{\'e}lie},
  journal={Journal of Multivariate Analysis},
  volume={101},
  number={9},
  pages={2207--2221},
  year={2010},
  publisher={Elsevier}
}

@article{Amari-2007,
  title={Integration of stochastic models by minimizing $\alpha$-divergence},
  author={Amari, Shun-ichi},
  journal={Neural computation},
  volume={19},
  number={10},
  pages={2780--2796},
  year={2007},
  publisher={MIT Press}
}

	@book{Finetti-1931,
  title={Sul concetto di media},
  author={De Finetti, Bruno},
  year={1931},
  publisher={Istituto italiano degli attuari}
}

@book{Kolmogorov-1930,
  title={Sur la notion de la moyenne},
  author={Kolmogorov, Andre{\u\i} Nikolaevich and Castelnuovo, Guido},
  year={1930},
  publisher={G. Bardi, tip. della R. Accad. dei Lincei}
}


@inproceedings{skewJS-2001,
  title={On the effectiveness of the skew divergence for statistical language analysis},
  author={Lee, Lillian},
  booktitle={Artificial Intelligence and Statistics (AISTATS)},
	pages={65–72},
  year={2001} 
}

@article{Fadeev-1957,
  title={{Zum Begriff der Entropie einer endlichen Wahrscheinlichkeitsschemas}},
  author={Dmitry Konstantinovich Faddeev},
  journal={Arbeiten zur Informationstheorie I. Deutscher Verlag der Wissenschaften},
  pages={85--90},
  year={1957}
}

@inproceedings{Renyi-1961,
  title={On measures of entropy and information},
  author={R{\'e}nyi, Alfr{\'e}d and others},
  booktitle={Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Contributions to the Theory of Statistics},
  year={1961},
  organization={The Regents of the University of California}
}
